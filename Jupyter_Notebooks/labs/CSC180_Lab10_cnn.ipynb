{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJk3bSGZ2vRD"
      },
      "source": [
        "## Lab 9: Convolutional Neural Networks\n",
        "\n",
        " For this lab, We will use **Google Colab GPU to speed up training time**.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcZQOmBq2vQ-"
      },
      "source": [
        "#### CSC 180 Intelligent Systems\n",
        "\n",
        "#### California State University, Sacramento\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iUOzhkZ2vRE"
      },
      "source": [
        "# Helpful Functions for Tensorflow (Little Gems)\n",
        "\n",
        "The following functions will be used with TensorFlow to help preprocess the data.  They allow you to build the feature vector for a neural network.\n",
        "\n",
        "* Predictors/Inputs\n",
        "    * Fill any missing inputs with the median for that column.  Use **missing_median**.\n",
        "    * Encode textual/categorical values with **encode_text_dummy**.\n",
        "    * Encode numeric values with **encode_numeric_zscore**.\n",
        "* Output\n",
        "    * Discard rows with missing outputs.\n",
        "    * Encode textual/categorical values with **encode_text_index**.\n",
        "    * Do not encode output numeric values.\n",
        "* Produce final feature vectors (x) and expected output (y) with **to_xy**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4kZDbVzz2vRE"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Sequence\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
        "def encode_text_dummy(df, name):\n",
        "    dummies = pd.get_dummies(df[name])\n",
        "    for x in dummies.columns:\n",
        "        dummy_name = \"{}-{}\".format(name, x)\n",
        "        df[dummy_name] = dummies[x]\n",
        "    df.drop(name, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
        "def encode_text_index(df, name):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    df[name] = le.fit_transform(df[name])\n",
        "    return le.classes_\n",
        "\n",
        "\n",
        "# Encode a numeric column as zscores\n",
        "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
        "    if mean is None:\n",
        "        mean = df[name].mean()\n",
        "\n",
        "    if sd is None:\n",
        "        sd = df[name].std()\n",
        "\n",
        "    df[name] = (df[name] - mean) / sd\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the median\n",
        "def missing_median(df, name):\n",
        "    med = df[name].median()\n",
        "    df[name] = df[name].fillna(med)\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the default\n",
        "def missing_default(df, name, default_value):\n",
        "    df[name] = df[name].fillna(default_value)\n",
        "\n",
        "\n",
        "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
        "def to_xy(df, target):\n",
        "    result = []\n",
        "    for x in df.columns:\n",
        "        if x != target:\n",
        "            result.append(x)\n",
        "    # find out the type of the target column.\n",
        "    target_type = df[target].dtypes\n",
        "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
        "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
        "    if target_type in (np.int64, np.int32):\n",
        "        # Classification\n",
        "        dummies = pd.get_dummies(df[target])\n",
        "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
        "    else:\n",
        "        # Regression\n",
        "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
        "\n",
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "\n",
        "# Regression chart.\n",
        "def chart_regression(pred,y,sort=True):\n",
        "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
        "    if sort:\n",
        "        t.sort_values(by=['y'],inplace=True)\n",
        "    a = plt.plot(t['y'].tolist(),label='expected')\n",
        "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
        "    plt.ylabel('output')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Remove all rows where the specified column is +/- sd standard deviations\n",
        "def remove_outliers(df, name, sd):\n",
        "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
        "    df.drop(drop_rows, axis=0, inplace=True)\n",
        "\n",
        "\n",
        "# Encode a column to a range between normalized_low and normalized_high.\n",
        "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
        "                         data_low=None, data_high=None):\n",
        "    if data_low is None:\n",
        "        data_low = min(df[name])\n",
        "        data_high = max(df[name])\n",
        "\n",
        "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
        "               * (normalized_high - normalized_low) + normalized_low\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "j58LXYU62vRG"
      },
      "source": [
        "\n",
        "# Computer Vision Data Sets\n",
        "\n",
        "There are many data sets for computer vision.  Two of the most popular are the MNIST digits data set and the CIFAR image data sets.\n",
        "\n",
        "## MNIST Digits Data Set\n",
        "\n",
        "The [MNIST Digits Data Set](http://yann.lecun.com/exdb/mnist/) is very popular in the neural network research community.  A sample of it can be seen here:\n",
        "\n",
        "![MNIST Data Set](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_8_mnist.png \"MNIST Data Set\")\n",
        "\n",
        "\n",
        "\n",
        "## CIFAR Data Set\n",
        "\n",
        "The [CIFAR-10 and CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html) datasets are also frequently used by the neural network research community.\n",
        "\n",
        "![cifar-10](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_8_cifar.png \"cifar-10\")\n",
        "\n",
        "The CIFAR-10 data set contains images that are divided into 10 classes.  The CIFAR-100 data set contains 100 classes in a hierarchy.\n",
        "\n",
        "\n",
        "\n",
        "# Convolutional Neural Networks (CNNs)\n",
        "\n",
        "The convolutional neural network (CNN) is a neural network technology that has profoundly impacted the area of computer vision (CV). In CNN, we use the following layer types:\n",
        "\n",
        "* **Dense Layers** - Fully connected layers.  \n",
        "* **Convolution Layers** - Used to scan across images.\n",
        "* **Max Pooling Layers** - Used to downsample images.\n",
        "* **Dropout Layer** - Prevent overfitting\n",
        "* **Flatten Layer** - Transform data of any shape into one dimensional  \n",
        "\n",
        "## Convolution Layers\n",
        "\n",
        "For the convolutional layer, We must specify the following hyper-parameters :\n",
        "\n",
        "* Number of filters\n",
        "* Filter Size\n",
        "* Stride\n",
        "* Padding\n",
        "* Activation Function/Non-Linearity\n",
        "\n",
        "\n",
        "A filter is a square-shaped object that scans over the image. The more filters that we give to a convolutional layer, the more features it can detect.\n",
        "\n",
        "\n",
        "## Max Pooling Layers\n",
        "\n",
        "Max-pool layers downsample the data.  This technique can avoid overfitting.\n",
        "\n",
        "*** Typically, you can always place a max-pool layer immediately following convolutional layer.***\n",
        "\n",
        "\n",
        "\n",
        "# Example of Training CNNs with Tensorflow\n",
        "\n",
        "The following sections describe how to use TensorFlow/Keras with CNNs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sea3aoja2vRH"
      },
      "source": [
        "# Access to Data Sets\n",
        "\n",
        "Keras provides built in access classes for MNIST which is already separated into two sets:\n",
        "\n",
        "* **train** - Neural network will be trained with this.\n",
        "* **test** - Used for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADGcS3qd2vRH",
        "outputId": "33a9a0e6-7984-429c-fb7c-156584b58ed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "Shape of x_train: (60000, 28, 28)\n",
            "Shape of y_train: (60000,)\n",
            "\n",
            "Shape of x_test: (10000, 28, 28)\n",
            "Shape of y_test: (10000,)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(\"Shape of x_train: {}\".format(x_train.shape))\n",
        "print(\"Shape of y_train: {}\".format(y_train.shape))\n",
        "print()\n",
        "print(\"Shape of x_test: {}\".format(x_test.shape))\n",
        "print(\"Shape of y_test: {}\".format(y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWPkffFs2vRI",
        "outputId": "85bae68c-40f8-4915-ed4e-6444e9718a5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_train: [5 0 4 ... 5 6 8]\n"
          ]
        }
      ],
      "source": [
        "print(\"y_train: {}\".format(y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-qMNB-E2vRJ"
      },
      "source": [
        "# Display the Digits\n",
        "\n",
        "The following code shows what the MNIST files contain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "id": "zQ_DQ2Rw2vRJ",
        "outputId": "e026a72f-dfdb-4e8e-ff2f-caa7feb25e9c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>159</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>252</td>\n",
              "      <td>237</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>233</td>\n",
              "      <td>252</td>\n",
              "      <td>57</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>84</td>\n",
              "      <td>252</td>\n",
              "      <td>253</td>\n",
              "      <td>122</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>96</td>\n",
              "      <td>189</td>\n",
              "      <td>253</td>\n",
              "      <td>167</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>47</td>\n",
              "      <td>79</td>\n",
              "      <td>255</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>253</td>\n",
              "      <td>243</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>165</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>253</td>\n",
              "      <td>252</td>\n",
              "      <td>165</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>178</td>\n",
              "      <td>252</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>253</td>\n",
              "      <td>252</td>\n",
              "      <td>195</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "      <td>252</td>\n",
              "      <td>252</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>253</td>\n",
              "      <td>252</td>\n",
              "      <td>195</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>198</td>\n",
              "      <td>253</td>\n",
              "      <td>190</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>253</td>\n",
              "      <td>196</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>246</td>\n",
              "      <td>252</td>\n",
              "      <td>112</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>253</td>\n",
              "      <td>252</td>\n",
              "      <td>148</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>252</td>\n",
              "      <td>230</td>\n",
              "      <td>25</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>135</td>\n",
              "      <td>253</td>\n",
              "      <td>186</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>252</td>\n",
              "      <td>223</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>131</td>\n",
              "      <td>252</td>\n",
              "      <td>225</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>252</td>\n",
              "      <td>145</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>252</td>\n",
              "      <td>173</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "      <td>253</td>\n",
              "      <td>225</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>162</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>252</td>\n",
              "      <td>249</td>\n",
              "      <td>146</td>\n",
              "      <td>...</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>252</td>\n",
              "      <td>252</td>\n",
              "      <td>252</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>199</td>\n",
              "      <td>252</td>\n",
              "      <td>252</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>128</td>\n",
              "      <td>252</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    0   1   2   3   4   5   6    7    8    9   ...   18   19   20   21   22  \\\n",
              "0    0   0   0   0   0   0   0    0    0    0  ...    0    0    0    0    0   \n",
              "1    0   0   0   0   0   0   0    0    0    0  ...    0    0    0    0    0   \n",
              "2    0   0   0   0   0   0   0    0    0    0  ...    0    0    0    0    0   \n",
              "3    0   0   0   0   0   0   0    0    0    0  ...    0    0    0    0    0   \n",
              "4    0   0   0   0   0   0   0    0    0    0  ...  159   50    0    0    0   \n",
              "5    0   0   0   0   0   0   0    0    0    0  ...  252  237    0    0    0   \n",
              "6    0   0   0   0   0   0   0    0    0    0  ...  233  252   57    6    0   \n",
              "7    0   0   0   0   0   0   0    0    0    0  ...   84  252  253  122    0   \n",
              "8    0   0   0   0   0   0   0    0    0    0  ...   96  189  253  167    0   \n",
              "9    0   0   0   0   0   0   0    0    0    0  ...   47   79  255  168    0   \n",
              "10   0   0   0   0   0   0   0    0    0   48  ...    0    0  253  243   50   \n",
              "11   0   0   0   0   0   0   0    0   38  165  ...    0    0  253  252  165   \n",
              "12   0   0   0   0   0   0   0    7  178  252  ...    0    0  253  252  195   \n",
              "13   0   0   0   0   0   0   0   57  252  252  ...    0    0  253  252  195   \n",
              "14   0   0   0   0   0   0   0  198  253  190  ...    0    0  255  253  196   \n",
              "15   0   0   0   0   0   0  76  246  252  112  ...    0    0  253  252  148   \n",
              "16   0   0   0   0   0   0  85  252  230   25  ...    7  135  253  186   12   \n",
              "17   0   0   0   0   0   0  85  252  223    0  ...  131  252  225   71    0   \n",
              "18   0   0   0   0   0   0  85  252  145    0  ...  252  173    0    0    0   \n",
              "19   0   0   0   0   0   0  86  253  225    0  ...  162    0    0    0    0   \n",
              "20   0   0   0   0   0   0  85  252  249  146  ...   56    0    0    0    0   \n",
              "21   0   0   0   0   0   0  85  252  252  252  ...    0    0    0    0    0   \n",
              "22   0   0   0   0   0   0  28  199  252  252  ...    0    0    0    0    0   \n",
              "23   0   0   0   0   0   0   0   25  128  252  ...    0    0    0    0    0   \n",
              "24   0   0   0   0   0   0   0    0    0    0  ...    0    0    0    0    0   \n",
              "25   0   0   0   0   0   0   0    0    0    0  ...    0    0    0    0    0   \n",
              "26   0   0   0   0   0   0   0    0    0    0  ...    0    0    0    0    0   \n",
              "27   0   0   0   0   0   0   0    0    0    0  ...    0    0    0    0    0   \n",
              "\n",
              "    23  24  25  26  27  \n",
              "0    0   0   0   0   0  \n",
              "1    0   0   0   0   0  \n",
              "2    0   0   0   0   0  \n",
              "3    0   0   0   0   0  \n",
              "4    0   0   0   0   0  \n",
              "5    0   0   0   0   0  \n",
              "6    0   0   0   0   0  \n",
              "7    0   0   0   0   0  \n",
              "8    0   0   0   0   0  \n",
              "9    0   0   0   0   0  \n",
              "10   0   0   0   0   0  \n",
              "11   0   0   0   0   0  \n",
              "12   0   0   0   0   0  \n",
              "13   0   0   0   0   0  \n",
              "14   0   0   0   0   0  \n",
              "15   0   0   0   0   0  \n",
              "16   0   0   0   0   0  \n",
              "17   0   0   0   0   0  \n",
              "18   0   0   0   0   0  \n",
              "19   0   0   0   0   0  \n",
              "20   0   0   0   0   0  \n",
              "21   0   0   0   0   0  \n",
              "22   0   0   0   0   0  \n",
              "23   0   0   0   0   0  \n",
              "24   0   0   0   0   0  \n",
              "25   0   0   0   0   0  \n",
              "26   0   0   0   0   0  \n",
              "27   0   0   0   0   0  \n",
              "\n",
              "[28 rows x 28 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Single MNIST digit\n",
        "first = x_train[1]\n",
        "\n",
        "pd.DataFrame(first)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "3ulCk7x72vRJ",
        "outputId": "1665487e-597a-43f7-d5f2-b782375d7c09",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image (#1): Which is digit '0'"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaiElEQVR4nO3de2xT5/3H8Y+h4AJNLGWQ2BkhiirQpkJhXMpFlJtERLYiKN0EdCrhH0THRWVph8agI5smUqGCui2Dbd3GQIWBtFLKVFaaKSSwUaaUi4pYhUCEkYpkGRGzQ6BGwPP7A+FfTULgGJtv7Lxf0iPhc86X883hIZ88sX3sc845AQBgoId1AwCA7osQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgJnHrBu4261bt3Tx4kVlZWXJ5/NZtwMA8Mg5p9bWVuXn56tHj87XOl0uhC5evKiCggLrNgAAD6mhoUEDBw7s9Jgu9+u4rKws6xYAAEnwIN/PUxZCmzZtUlFRkR5//HGNGjVKhw4deqA6fgUHAJnhQb6fpySEdu3apRUrVmj16tU6fvy4nn32WZWUlOjChQupOB0AIE35UnEX7bFjx2rkyJHavHlzbNvXv/51zZ49WxUVFZ3WRiIRBQKBZLcEAHjEwuGwsrOzOz0m6Suh69ev6+jRoyouLo7bXlxcrMOHD7c7PhqNKhKJxA0AQPeQ9BC6dOmSbt68qby8vLjteXl5ampqand8RUWFAoFAbPDKOADoPlL2woS7n5ByznX4JNWqVasUDodjo6GhIVUtAQC6mKS/T6h///7q2bNnu1VPc3Nzu9WRJPn9fvn9/mS3AQBIA0lfCfXu3VujRo1SVVVV3PaqqipNmDAh2acDAKSxlNwxoaysTC+99JJGjx6t8ePH67e//a0uXLigl19+ORWnAwCkqZSE0Ny5c9XS0qKf/vSnamxs1NChQ7Vv3z4VFham4nQAgDSVkvcJPQzeJwQAmcHkfUIAADwoQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYecy6AQAPZtSoUZ5rli1bltC5FixY4Llm27Ztnmt++ctfeq45duyY5xp0XayEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmPE555x1E18WiUQUCASs2wBSasSIEZ5rqqurPddkZ2d7rnmUwuGw55qvfOUrKegEqRAOh+87B1kJAQDMEEIAADNJD6Hy8nL5fL64EQwGk30aAEAGSMmH2j311FP629/+Fnvcs2fPVJwGAJDmUhJCjz32GKsfAMB9peQ5oTNnzig/P19FRUWaN2+ezp07d89jo9GoIpFI3AAAdA9JD6GxY8dq27Zt2r9/v95++201NTVpwoQJamlp6fD4iooKBQKB2CgoKEh2SwCALirl7xNqa2vTk08+qZUrV6qsrKzd/mg0qmg0GnsciUQIImQ83id0G+8TymwP8j6hlDwn9GX9+vXTsGHDdObMmQ73+/1++f3+VLcBAOiCUv4+oWg0qs8++0yhUCjVpwIApJmkh9Brr72m2tpa1dfX65///Ke+/e1vKxKJqLS0NNmnAgCkuaT/Ou7zzz/X/PnzdenSJQ0YMEDjxo3TkSNHVFhYmOxTAQDSHDcwBR7SM88847nm3Xff9VyTn5/vuSbR/96tra2ea65fv+65JpEXGUycONFzzbFjxzzXSIl9Tfh/3MAUANClEUIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMJPyD7UDLPTt2zehupEjR3queeeddzzXdPXP17rXh1B2Zv369Z5rdu7c6bnmH//4h+eaNWvWeK6RpIqKioTq8OBYCQEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzHAXbWSk3/zmNwnVzZ8/P8mdpKdE7ib+xBNPeK6pra31XDNlyhTPNU8//bTnGjwarIQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCY4Qam6PJGjRrlueZb3/pWQufy+XwJ1XmVyI07//KXv3iuefPNNz3XSNLFixc91xw/ftxzzeXLlz3XTJs2zXPNo/p3hXeshAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJjxOeecdRNfFolEFAgErNtAiowYMcJzTXV1teea7OxszzWJ+utf/+q5Zv78+Z5rJk+e7Lnm6aef9lwjSb/73e881/z3v/9N6Fxe3bx503PN1atXEzpXItf82LFjCZ0rE4XD4fv+X2QlBAAwQwgBAMx4DqGDBw9q5syZys/Pl8/n0549e+L2O+dUXl6u/Px89enTR1OmTNGpU6eS1S8AIIN4DqG2tjYNHz5clZWVHe5fv369Nm7cqMrKStXV1SkYDGr69OlqbW196GYBAJnF8yerlpSUqKSkpMN9zjm99dZbWr16tebMmSNJ2rp1q/Ly8rRjxw4tXrz44boFAGSUpD4nVF9fr6amJhUXF8e2+f1+TZ48WYcPH+6wJhqNKhKJxA0AQPeQ1BBqamqSJOXl5cVtz8vLi+27W0VFhQKBQGwUFBQksyUAQBeWklfH+Xy+uMfOuXbb7li1apXC4XBsNDQ0pKIlAEAX5Pk5oc4Eg0FJt1dEoVAotr25ubnd6ugOv98vv9+fzDYAAGkiqSuhoqIiBYNBVVVVxbZdv35dtbW1mjBhQjJPBQDIAJ5XQleuXNHZs2djj+vr63XixAnl5ORo0KBBWrFihdatW6fBgwdr8ODBWrdunfr27asXX3wxqY0DANKf5xD65JNPNHXq1NjjsrIySVJpaan++Mc/auXKlbp27ZqWLFmiy5cva+zYsfroo4+UlZWVvK4BABmBG5giYUOGDPFcs3btWs818+bN81xz6dIlzzWS1NjY6LnmZz/7meeaP//5z55rcFsiNzBN9Nvcrl27PNd897vfTehcmYgbmAIAujRCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgJmkfrIq0lOin2z75ptveq755je/6bmmtbXVc82CBQs810i3P6rEqz59+iR0LnR9gwYNsm4h47ESAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYbmELf+MY3EqpL5GakiZg1a5bnmtra2hR0AiDZWAkBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwww1MoY0bNyZU5/P5PNckcmNRbkaKL+vRw/vPzrdu3UpBJ0gGVkIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMcAPTDPPcc895rhkxYkRC53LOea7Zu3dvQucC7kjkZqSJzFVJOnHiREJ1eHCshAAAZgghAIAZzyF08OBBzZw5U/n5+fL5fNqzZ0/c/oULF8rn88WNcePGJatfAEAG8RxCbW1tGj58uCorK+95zIwZM9TY2Bgb+/bte6gmAQCZyfMLE0pKSlRSUtLpMX6/X8FgMOGmAADdQ0qeE6qpqVFubq6GDBmiRYsWqbm5+Z7HRqNRRSKRuAEA6B6SHkIlJSXavn27qqurtWHDBtXV1WnatGmKRqMdHl9RUaFAIBAbBQUFyW4JANBFJf19QnPnzo39eejQoRo9erQKCwv1wQcfaM6cOe2OX7VqlcrKymKPI5EIQQQA3UTK36waCoVUWFioM2fOdLjf7/fL7/enug0AQBeU8vcJtbS0qKGhQaFQKNWnAgCkGc8roStXrujs2bOxx/X19Tpx4oRycnKUk5Oj8vJyvfDCCwqFQjp//rx+9KMfqX///nr++eeT2jgAIP15DqFPPvlEU6dOjT2+83xOaWmpNm/erJMnT2rbtm363//+p1AopKlTp2rXrl3KyspKXtcAgIzgOYSmTJnS6c0A9+/f/1AN4eH06dPHc03v3r0TOldnL72/l127diV0LnR9iTy3W15envxGOlBdXZ1Q3apVq5LcCe7GveMAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGZS/smqyFzRaNRzTWNjYwo6QbIlckfsNWvWeK75wQ9+4Lnm888/91yzYcMGzzXS7c9PQ2qxEgIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGG5giYXv37rVuAfcxYsSIhOoSubHo3LlzPde8//77nmteeOEFzzXoulgJAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMMMNTDOMz+d7JDWSNHv2bM81r7zySkLngvT973/fc83rr7+e0LkCgYDnmu3bt3uuWbBggecaZBZWQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMxwA9MM45x7JDWSFAwGPdf84he/8Fzzhz/8wXNNS0uL5xpJGjdunOeal156yXPN8OHDPdcMHDjQc82FCxc810jS/v37Pdds2rQpoXOhe2MlBAAwQwgBAMx4CqGKigqNGTNGWVlZys3N1ezZs3X69Om4Y5xzKi8vV35+vvr06aMpU6bo1KlTSW0aAJAZPIVQbW2tli5dqiNHjqiqqko3btxQcXGx2traYsesX79eGzduVGVlperq6hQMBjV9+nS1trYmvXkAQHrz9MKEDz/8MO7xli1blJubq6NHj2rSpElyzumtt97S6tWrNWfOHEnS1q1blZeXpx07dmjx4sXJ6xwAkPYe6jmhcDgsScrJyZEk1dfXq6mpScXFxbFj/H6/Jk+erMOHD3f4d0SjUUUikbgBAOgeEg4h55zKyso0ceJEDR06VJLU1NQkScrLy4s7Ni8vL7bvbhUVFQoEArFRUFCQaEsAgDSTcAgtW7ZMn376qf70pz+12+fz+eIeO+fabbtj1apVCofDsdHQ0JBoSwCANJPQm1WXL1+uvXv36uDBg3FvoLvz5sWmpiaFQqHY9ubm5narozv8fr/8fn8ibQAA0pynlZBzTsuWLdPu3btVXV2toqKiuP1FRUUKBoOqqqqKbbt+/bpqa2s1YcKE5HQMAMgYnlZCS5cu1Y4dO/T+++8rKysr9jxPIBBQnz595PP5tGLFCq1bt06DBw/W4MGDtW7dOvXt21cvvvhiSr4AAED68hRCmzdvliRNmTIlbvuWLVu0cOFCSdLKlSt17do1LVmyRJcvX9bYsWP10UcfKSsrKykNAwAyh88levfKFIlEIgoEAtZtpK3vfOc7nms6enFJV/Kf//zHc02iL/UfPHhwQnWPwscff+y55sCBAwmd68c//nFCdcCXhcNhZWdnd3oM944DAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJhJ6JNV0XUlcqflurq6hM41ZsyYhOq8uvOJvV7c65N8U6GlpcVzzc6dOz3XvPLKK55rgK6OlRAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzPuecs27iyyKRiAKBgHUb3UooFEqobvHixZ5r1qxZ47nG5/N5rkl0Wv/85z/3XLN582bPNWfPnvVcA6SbcDis7OzsTo9hJQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMNzAFAKQENzAFAHRphBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAw4ymEKioqNGbMGGVlZSk3N1ezZ8/W6dOn445ZuHChfD5f3Bg3blxSmwYAZAZPIVRbW6ulS5fqyJEjqqqq0o0bN1RcXKy2tra442bMmKHGxsbY2LdvX1KbBgBkhse8HPzhhx/GPd6yZYtyc3N19OhRTZo0Kbbd7/crGAwmp0MAQMZ6qOeEwuGwJCknJydue01NjXJzczVkyBAtWrRIzc3N9/w7otGoIpFI3AAAdA8+55xLpNA5p1mzZuny5cs6dOhQbPuuXbv0xBNPqLCwUPX19Xr99dd148YNHT16VH6/v93fU15erp/85CeJfwUAgC4pHA4rOzu784NcgpYsWeIKCwtdQ0NDp8ddvHjR9erVy7377rsd7v/iiy9cOByOjYaGBieJwWAwGGk+wuHwfbPE03NCdyxfvlx79+7VwYMHNXDgwE6PDYVCKiws1JkzZzrc7/f7O1whAQAyn6cQcs5p+fLleu+991RTU6OioqL71rS0tKihoUGhUCjhJgEAmcnTCxOWLl2qd955Rzt27FBWVpaamprU1NSka9euSZKuXLmi1157TR9//LHOnz+vmpoazZw5U/3799fzzz+fki8AAJDGvDwPpHv83m/Lli3OOeeuXr3qiouL3YABA1yvXr3coEGDXGlpqbtw4cIDnyMcDpv/HpPBYDAYDz8e5DmhhF8dlyqRSESBQMC6DQDAQ3qQV8dx7zgAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgJkuF0LOOesWAABJ8CDfz7tcCLW2tlq3AABIggf5fu5zXWzpcevWLV28eFFZWVny+Xxx+yKRiAoKCtTQ0KDs7GyjDu1xHW7jOtzGdbiN63BbV7gOzjm1trYqPz9fPXp0vtZ57BH19MB69OihgQMHdnpMdnZ2t55kd3AdbuM63MZ1uI3rcJv1dQgEAg90XJf7dRwAoPsghAAAZtIqhPx+v9auXSu/32/diimuw21ch9u4DrdxHW5Lt+vQ5V6YAADoPtJqJQQAyCyEEADADCEEADBDCAEAzKRVCG3atElFRUV6/PHHNWrUKB06dMi6pUeqvLxcPp8vbgSDQeu2Uu7gwYOaOXOm8vPz5fP5tGfPnrj9zjmVl5crPz9fffr00ZQpU3Tq1CmbZlPoftdh4cKF7ebHuHHjbJpNkYqKCo0ZM0ZZWVnKzc3V7Nmzdfr06bhjusN8eJDrkC7zIW1CaNeuXVqxYoVWr16t48eP69lnn1VJSYkuXLhg3doj9dRTT6mxsTE2Tp48ad1SyrW1tWn48OGqrKzscP/69eu1ceNGVVZWqq6uTsFgUNOnT8+4+xDe7zpI0owZM+Lmx759+x5hh6lXW1urpUuX6siRI6qqqtKNGzdUXFystra22DHdYT48yHWQ0mQ+uDTxzDPPuJdffjlu29e+9jX3wx/+0KijR2/t2rVu+PDh1m2YkuTee++92ONbt265YDDo3njjjdi2L774wgUCAffrX//aoMNH4+7r4JxzpaWlbtasWSb9WGlubnaSXG1trXOu+86Hu6+Dc+kzH9JiJXT9+nUdPXpUxcXFcduLi4t1+PBho65snDlzRvn5+SoqKtK8efN07tw565ZM1dfXq6mpKW5u+P1+TZ48udvNDUmqqalRbm6uhgwZokWLFqm5udm6pZQKh8OSpJycHEnddz7cfR3uSIf5kBYhdOnSJd28eVN5eXlx2/Py8tTU1GTU1aM3duxYbdu2Tfv379fbb7+tpqYmTZgwQS0tLdatmbnz79/d54YklZSUaPv27aqurtaGDRtUV1enadOmKRqNWreWEs45lZWVaeLEiRo6dKik7jkfOroOUvrMhy53F+3O3P3RDs65dtsyWUlJSezPw4YN0/jx4/Xkk09q69atKisrM+zMXnefG5I0d+7c2J+HDh2q0aNHq7CwUB988IHmzJlj2FlqLFu2TJ9++qn+/ve/t9vXnebDva5DusyHtFgJ9e/fXz179mz3k0xzc3O7n3i6k379+mnYsGE6c+aMdStm7rw6kLnRXigUUmFhYUbOj+XLl2vv3r06cOBA3Ee/dLf5cK/r0JGuOh/SIoR69+6tUaNGqaqqKm57VVWVJkyYYNSVvWg0qs8++0yhUMi6FTNFRUUKBoNxc+P69euqra3t1nNDklpaWtTQ0JBR88M5p2XLlmn37t2qrq5WUVFR3P7uMh/udx060mXng+GLIjzZuXOn69Wrl/v973/v/vWvf7kVK1a4fv36ufPnz1u39si8+uqrrqamxp07d84dOXLEPffccy4rKyvjr0Fra6s7fvy4O378uJPkNm7c6I4fP+7+/e9/O+ece+ONN1wgEHC7d+92J0+edPPnz3ehUMhFIhHjzpOrs+vQ2trqXn31VXf48GFXX1/vDhw44MaPH++++tWvZtR1+N73vucCgYCrqalxjY2NsXH16tXYMd1hPtzvOqTTfEibEHLOuV/96leusLDQ9e7d240cOTLu5Yjdwdy5c10oFHK9evVy+fn5bs6cOe7UqVPWbaXcgQMHnKR2o7S01Dl3+2W5a9eudcFg0Pn9fjdp0iR38uRJ26ZToLPrcPXqVVdcXOwGDBjgevXq5QYNGuRKS0vdhQsXrNtOqo6+fkluy5YtsWO6w3y433VIp/nARzkAAMykxXNCAIDMRAgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwMz/AdDDJYtBgQkJAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sample = 1    #  change this number to select another sample\n",
        "digit = x_train[sample]\n",
        "#print(type(digit))\n",
        "#print(digit.shape)\n",
        "\n",
        "\n",
        "plt.imshow(digit, cmap='gray')\n",
        "print(\"Image (#{}): Which is digit '{}'\".format(sample,y_train[sample]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxkhVujm2vRK"
      },
      "source": [
        "# Define CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TSzuLIp02vRK"
      },
      "outputs": [],
      "source": [
        "# Load modules\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iJzXmtza2vRK"
      },
      "outputs": [],
      "source": [
        "# Define batch_size and # of epochs\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CJrWIRKZ2vRL"
      },
      "outputs": [],
      "source": [
        "# define input image dimensions\n",
        "img_rows, img_cols = 28, 28"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGJM-ZEt2vRL"
      },
      "source": [
        "### Let's create x (images) first.        \n",
        "\n",
        "### x must be 4D array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PpARN0L2vRL"
      },
      "source": [
        "#### You must explicitly declare the depth of the input image. For example, a full-color image with all 3 RGB channels will have a depth of 3.\n",
        "\n",
        "In other words, we need to transform our dataset from the shape (n, rows, cols) to (n, rows, cols, depth).\n",
        "\n",
        "#### Our MNIST images only have a depth of 1, but we must explicitly declare that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "luG1vuDU2vRL"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDPG719-2vRM",
        "outputId": "1b23bb82-e4f8-4c13-d82d-2c89f66c0ab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRREPw-l2vRM",
        "outputId": "b8f66ee5-7c60-49e8-ad9d-7193e2fa6e33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2yOmEL1H2vRM"
      },
      "outputs": [],
      "source": [
        "# convert to float32 for normalization\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HdaQ5yj02vRM"
      },
      "outputs": [],
      "source": [
        "# normalize the data values to the range [0, 1]\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDmS2BHt2vRM",
        "outputId": "0e6d4723-6404-4917-c68a-f793135165ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "x_test shape: (10000, 28, 28, 1)\n",
            "Training samples: 60000\n",
            "Test samples: 10000\n"
          ]
        }
      ],
      "source": [
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print(\"Training samples: {}\".format(x_train.shape[0]))\n",
        "print(\"Test samples: {}\".format(x_test.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0PfVIh02vRN"
      },
      "source": [
        "### Now we have x ready. Let's create y (class labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_acHGMaB2vRN",
        "outputId": "e702cf27-ba87-4fe3-9844-43fd985a23c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000,)\n",
            "[5 0 4 1 9 2 1 3 1 4]\n"
          ]
        }
      ],
      "source": [
        "print(y_train.shape)\n",
        "print(y_train[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSFlLvrU2vRN"
      },
      "source": [
        "### For classification, TensorFlow requires y in one hot-encoded format.  \n",
        "\n",
        "### Let's use function ***tf.keras.utils.to_categorical()***  to converts a class vector (numpy array) to its one hot-encoded format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oA6AcrDH2vRN"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "\n",
        "# Converts a class vector (integers) to binary class matrix.   One-hot encoding!  Use with categorical_crossentropy.\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "xFvGhQYy2vRN",
        "outputId": "ff8556d6-e749-4065-d812-d2be8faa091d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0    1    2    3    4    5    6    7    8    9\n",
              "0      0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
              "1      1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "2      0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
              "3      0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
              "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
              "59995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
              "59996  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "59997  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
              "59998  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
              "59999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
              "\n",
              "[60000 rows x 10 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ufaFF4Zv2vRO",
        "outputId": "b240344b-1d66-4328-8892-5fd6d5b05578"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0    1    2    3    4    5    6    7    8    9\n",
              "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
              "1     0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "2     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "3     1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "4     0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
              "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
              "9995  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "9996  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "9997  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
              "9998  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
              "9999  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
              "\n",
              "[10000 rows x 10 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQAvCJ4w2vRO",
        "outputId": "6f306f10-e98a-40be-e553-92ea1dbb4377"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 10), (10000, 10))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khpVO2B32vRO"
      },
      "source": [
        "### We are ready to define the CNN architecture now!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__puAzxl2vRO"
      },
      "source": [
        "Let's start by declaring a sequential model format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8BYvusO92vRO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDyTIw992vRO"
      },
      "source": [
        "Next, we add the input layer.\n",
        "\n",
        "The Conv2D layer creates a convolution kernel that is convolved with the layer input to produce outputs. Provide the following:\n",
        "\n",
        "*  The number of convolution filters (neurons) to use\n",
        "\n",
        "* kernel_size specifies the height and width of the 2D convolution window\n",
        "\n",
        "* strides: An tuple of 2 integers, specifying the strides of the convolution along the height and width\n",
        "\n",
        "* padding: one of \"valid\" or \"same\".  ***valid***: no padding. ***same***: zero padding.\n",
        "\n",
        "\n",
        "* ***input_shape: should be the shape of 1 sample.*** In this case, it should (28, 28, 1) that corresponds to  the (rows, cols, depth) of each digit image.  When using Conv2D layer as the first layer in a model, you must provide input_shape, e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HmKDzanm2vRP"
      },
      "outputs": [],
      "source": [
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='valid',\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))    #  in this case, input_shape = (img_rows, img_cols, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvbG7PmC2vRP",
        "outputId": "3d2d9bab-e47a-4f36-b368-ef2cc64f8df9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320 (1.25 KB)\n",
            "Trainable params: 320 (1.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq5X4sn42vRP"
      },
      "source": [
        "## Reflection:  \n",
        "\n",
        "\n",
        "### Why the output shape is (None, 26, 26, 32) ?\n",
        "\n",
        "The first dimension in a keras model is always the batch size.\n",
        "\n",
        "### Why the depth is 32?\n",
        "\n",
        "\n",
        "Note that number of filters from previous layer become the number of channels for current layer's input image.\n",
        "\n",
        "\n",
        "### How 320 was calculated?\n",
        "\n",
        "***total_params = filter_height $*$ filter_width $*$ input_image_channels $*$ number_of_filters + number_of_filters***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC3e0JxM2vRQ"
      },
      "source": [
        "Next, we can simply add more layers to our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "u_alIWj12vRQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Note that number of filters from previous layer become the number of channels for current layer's input image.\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=None))\n",
        "model.add(Dropout(0.25))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUTE265U2vRQ"
      },
      "source": [
        "#### MaxPooling2D is a way to reduce the number of parameters in our model.   \n",
        "Here we slide a 2x2 pooling filter across the previous layer and taking the max of the 4 values in the 2x2 filter.  \n",
        "\n",
        "strides: Integer, or None. Factor by which to downscale. E.g. 2 will halve the input. If None, it will default to pool_size.\n",
        "\n",
        "#### Dropout layer is a method for regularizing our model in order to prevent overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w--W2NaJ2vRQ"
      },
      "source": [
        "So far, for model parameters, we've added two Convolution layers. To complete our model architecture, let's add a fully connected layer and then the output layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "e7PnhQ4v2vRQ"
      },
      "outputs": [],
      "source": [
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Oi0ACzQ2vRQ"
      },
      "source": [
        "For Dense layers, the first parameter is the output size of the layer.\n",
        "\n",
        "Note that the final layer has an output size of 10, corresponding to the 10 classes of digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9zeaAaM2vRR"
      },
      "source": [
        "Why use flatten layer here?\n",
        "\n",
        "#### Also note that  Convolution layers must be flattened (made 1-dimensional) before passing them to the fully connected Dense layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJaNqZ3i2vRR",
        "outputId": "24fd33dd-776e-4b9c-cf72-904089546287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 12, 12, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1179776   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1199882 (4.58 MB)\n",
            "Trainable params: 1199882 (4.58 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ec3Dj2o2vRR"
      },
      "source": [
        "### Now all we need to do is to compile the model by defining the loss function and the optimizer, and then we'll be ready to train it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAf7gcUQ2vRS"
      },
      "source": [
        "#### Here for each epoch, we show not only \"log loss\" but also \"accuracy\" by using metrics=['accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2NaWDan2vRS",
        "outputId": "a9c894e3-a2c8-49c7-e4fd-521cda4d40bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# show not only log loss but also accuracy for each epoch using metrics=['accuracy']\n",
        "\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=Adam(lr=0.001), metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xJCdTSC2vRS",
        "outputId": "b2a9f75d-b2e7-470e-912b-2a4c1a9f6235"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpnDmdzm2vRT"
      },
      "source": [
        "## Training/Fitting CNN\n",
        "\n",
        "To fit the model, declare the batch size and number of epochs to train for, then pass in our training data.\n",
        "\n",
        "This can take a while.  You can also use a variety of callbacks to set early-stopping rules.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7dPdf-22vRT",
        "outputId": "f29a26e0-8270-4d88-81d4-444fb3cd32df",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:From c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 - 17s - loss: 0.2450 - accuracy: 0.9258 - val_loss: 0.0605 - val_accuracy: 0.9794 - 17s/epoch - 36ms/step\n",
            "Epoch 2/10\n",
            "469/469 - 17s - loss: 0.0854 - accuracy: 0.9746 - val_loss: 0.0413 - val_accuracy: 0.9868 - 17s/epoch - 36ms/step\n",
            "Epoch 3/10\n",
            "469/469 - 16s - loss: 0.0656 - accuracy: 0.9802 - val_loss: 0.0368 - val_accuracy: 0.9875 - 16s/epoch - 34ms/step\n",
            "Epoch 4/10\n",
            "469/469 - 16s - loss: 0.0535 - accuracy: 0.9837 - val_loss: 0.0307 - val_accuracy: 0.9897 - 16s/epoch - 35ms/step\n",
            "Epoch 5/10\n",
            "469/469 - 16s - loss: 0.0448 - accuracy: 0.9857 - val_loss: 0.0296 - val_accuracy: 0.9908 - 16s/epoch - 34ms/step\n",
            "Epoch 6/10\n",
            "469/469 - 16s - loss: 0.0410 - accuracy: 0.9873 - val_loss: 0.0316 - val_accuracy: 0.9902 - 16s/epoch - 35ms/step\n",
            "Epoch 7/10\n",
            "469/469 - 16s - loss: 0.0365 - accuracy: 0.9882 - val_loss: 0.0286 - val_accuracy: 0.9919 - 16s/epoch - 35ms/step\n",
            "Epoch 8/10\n",
            "469/469 - 16s - loss: 0.0293 - accuracy: 0.9905 - val_loss: 0.0296 - val_accuracy: 0.9906 - 16s/epoch - 34ms/step\n",
            "Epoch 9/10\n",
            "469/469 - 16s - loss: 0.0280 - accuracy: 0.9907 - val_loss: 0.0309 - val_accuracy: 0.9917 - 16s/epoch - 33ms/step\n",
            "Epoch 10/10\n",
            "469/469 - 16s - loss: 0.0248 - accuracy: 0.9921 - val_loss: 0.0296 - val_accuracy: 0.9913 - 16s/epoch - 33ms/step\n",
            "Elapsed time: 0:02:41.15\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=10,\n",
        "          verbose=2,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "print(\"Elapsed time: {}\".format(hms_string(elapsed_time)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRVzoO1m2vRT"
      },
      "source": [
        "## Evaluate Accuracy in Tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA4sBHiP2vRT",
        "outputId": "7f36a4fe-4488-4423-bb1e-f4bdddf3776a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.02964433841407299, 0.9912999868392944]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate() computes the loss and accuracy\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU-W2fKp2vRU",
        "outputId": "3c255a18-e8a4-42cc-ab17-acf182154012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.02964433841407299\n",
            "Test accuracy: 0.9912999868392944\n"
          ]
        }
      ],
      "source": [
        "print('Test loss: {}'.format(score[0]))\n",
        "print('Test accuracy: {}'.format(score[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQzmDWxA2vRU"
      },
      "source": [
        "## Evaluate Other Metrics using Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G2ozAc02vRU",
        "outputId": "ce2bc4bf-a0b7-4e7f-90d4-2d885bd74499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "Accuracy: 0.9913\n",
            "Averaged F1: 0.9912948810325278\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       980\n",
            "           1       0.99      1.00      1.00      1135\n",
            "           2       0.99      0.99      0.99      1032\n",
            "           3       0.99      1.00      0.99      1010\n",
            "           4       0.99      0.99      0.99       982\n",
            "           5       1.00      0.99      0.99       892\n",
            "           6       0.99      0.99      0.99       958\n",
            "           7       0.99      0.99      0.99      1028\n",
            "           8       0.99      0.99      0.99       974\n",
            "           9       0.99      0.98      0.99      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "y_true = np.argmax(y_test,axis=1)\n",
        "pred = model.predict(x_test)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "\n",
        "\n",
        "score = metrics.accuracy_score(y_true, pred)\n",
        "print('Accuracy: {}'.format(score))\n",
        "\n",
        "\n",
        "f1 = metrics.f1_score(y_true, pred, average='weighted')\n",
        "print('Averaged F1: {}'.format(f1))\n",
        "\n",
        "\n",
        "print(metrics.classification_report(y_true, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wqmy9rM2vRU"
      },
      "source": [
        "## How to choose network archectures (# of layers, type of each layer, etc..)?\n",
        "\n",
        "When you're just starting out, you should replicate proven architectures from academic papers or use existing examples. Here's a link to many example implementations in Keras.\n",
        "\n",
        "https://keras.io/examples/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3THag1q2vRU"
      },
      "source": [
        "# CNN can handle ANY data types other than images!  The key is how you would view each sample as an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMt7P4R92vRU",
        "outputId": "ee72bf98-2fbe-4d23-d527-4e3abb0f2897"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.56536543, 0.97473264, 0.7198658 , ..., 0.7453521 , 0.95641375,\n",
              "        0.17244469],\n",
              "       [0.13689311, 0.55935067, 0.31616327, ..., 0.4182077 , 0.79328054,\n",
              "        0.50564337],\n",
              "       [0.71242785, 0.5428981 , 0.7547049 , ..., 0.5059148 , 0.20683959,\n",
              "        0.2518875 ],\n",
              "       ...,\n",
              "       [0.9961895 , 0.9022146 , 0.51584333, ..., 0.09444116, 0.7348191 ,\n",
              "        0.5510336 ],\n",
              "       [0.68263966, 0.42805567, 0.5447042 , ..., 0.7496053 , 0.98503804,\n",
              "        0.4309681 ],\n",
              "       [0.00447403, 0.58668363, 0.38394424, ..., 0.11670893, 0.2398934 ,\n",
              "        0.15299556]], dtype=float32)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# x - inputs, 10000 samples of 128-dimensional vectors\n",
        "# y - labels, 10000 samples of scalars from the set {0, 1, 2}\n",
        "\n",
        "x = np.random.rand(10000, 128).astype(\"float32\")\n",
        "y = np.random.randint(3, size=(10000,1))\n",
        "\n",
        "\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "oMy5O9tA2vRV"
      },
      "outputs": [],
      "source": [
        "# process the data to fit in a keras CNN properly， input data needs to be (N, X, Y, C) - shaped where\n",
        "# N - number of samples\n",
        "# C - number of channels per sample\n",
        "# (X, Y) - sample size\n",
        "\n",
        "\n",
        "x = x.reshape((10000, 1, 128, 1))\n",
        "\n",
        "# output labels should be one-hot vectors - ie,\n",
        "# 0 -> [0, 0, 1]\n",
        "# 1 -> [0, 1, 0]\n",
        "# 2 -> [1, 0, 0]\n",
        "# this operation changes the shape of y from (10000,1) to (10000, 3)\n",
        "\n",
        "y_one_hot = tf.keras.utils.to_categorical(y, 3)\n",
        "\n",
        "\n",
        "# split your data to training and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGvrUHto2vRV",
        "outputId": "7c64a7ae-7aaf-435f-a9eb-89782a6ba8c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[0.56536543],\n",
              "         [0.97473264],\n",
              "         [0.7198658 ],\n",
              "         ...,\n",
              "         [0.7453521 ],\n",
              "         [0.95641375],\n",
              "         [0.17244469]]],\n",
              "\n",
              "\n",
              "       [[[0.13689311],\n",
              "         [0.55935067],\n",
              "         [0.31616327],\n",
              "         ...,\n",
              "         [0.4182077 ],\n",
              "         [0.79328054],\n",
              "         [0.50564337]]],\n",
              "\n",
              "\n",
              "       [[[0.71242785],\n",
              "         [0.5428981 ],\n",
              "         [0.7547049 ],\n",
              "         ...,\n",
              "         [0.5059148 ],\n",
              "         [0.20683959],\n",
              "         [0.2518875 ]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.9961895 ],\n",
              "         [0.9022146 ],\n",
              "         [0.51584333],\n",
              "         ...,\n",
              "         [0.09444116],\n",
              "         [0.7348191 ],\n",
              "         [0.5510336 ]]],\n",
              "\n",
              "\n",
              "       [[[0.68263966],\n",
              "         [0.42805567],\n",
              "         [0.5447042 ],\n",
              "         ...,\n",
              "         [0.7496053 ],\n",
              "         [0.98503804],\n",
              "         [0.4309681 ]]],\n",
              "\n",
              "\n",
              "       [[[0.00447403],\n",
              "         [0.58668363],\n",
              "         [0.38394424],\n",
              "         ...,\n",
              "         [0.11670893],\n",
              "         [0.2398934 ],\n",
              "         [0.15299556]]]], dtype=float32)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adJ3MDEr2vRV",
        "outputId": "7ca10fed-e6f2-4b64-8264-0b906f4d541c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "aKBDx4mV2vRW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# define a CNN\n",
        "\n",
        "cnn = Sequential()\n",
        "cnn.add(Conv2D(64, kernel_size=(1, 3), strides=(1, 1),\n",
        "                 activation='relu',\n",
        "                 input_shape=(1, 128, 1)))\n",
        "\n",
        "# the above code is equivalent to\n",
        "# model.add(Conv1D(64, kernel_size=3, strides=1, activation='relu', input_shape=(128, 1)))\n",
        "\n",
        "cnn.add(MaxPooling2D(pool_size=(1,2)))\n",
        "\n",
        "cnn.add(Conv2D(128, kernel_size=(1, 3), strides=(1, 1),\n",
        "                 activation='relu'))\n",
        "cnn.add(MaxPooling2D(pool_size=(1,2)))\n",
        "\n",
        "\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(1024, activation=\"relu\"))\n",
        "cnn.add(Dropout(0.5))\n",
        "cnn.add(Dense(3, activation=\"softmax\"))\n",
        "\n",
        "# define optimizer and objective, compile cnn\n",
        "\n",
        "cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "TdvMmkvU2vRW"
      },
      "source": [
        "# Use CNN to handle color (RGB) images (cifar10)\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWIG1w_R2vRW",
        "outputId": "6348e90f-adee-4ee9-d5b9-911d24089ad6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 125s 1us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEjZRAUv2vRW",
        "outputId": "7751207e-9637-4525-a980-9949701942c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAdKoSVi2vRX",
        "outputId": "a0f4eb32-e0ab-43db-8e5d-9ad87b5a7afc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[ 59,  62,  63],\n",
              "         [ 43,  46,  45],\n",
              "         [ 50,  48,  43],\n",
              "         ...,\n",
              "         [158, 132, 108],\n",
              "         [152, 125, 102],\n",
              "         [148, 124, 103]],\n",
              "\n",
              "        [[ 16,  20,  20],\n",
              "         [  0,   0,   0],\n",
              "         [ 18,   8,   0],\n",
              "         ...,\n",
              "         [123,  88,  55],\n",
              "         [119,  83,  50],\n",
              "         [122,  87,  57]],\n",
              "\n",
              "        [[ 25,  24,  21],\n",
              "         [ 16,   7,   0],\n",
              "         [ 49,  27,   8],\n",
              "         ...,\n",
              "         [118,  84,  50],\n",
              "         [120,  84,  50],\n",
              "         [109,  73,  42]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[208, 170,  96],\n",
              "         [201, 153,  34],\n",
              "         [198, 161,  26],\n",
              "         ...,\n",
              "         [160, 133,  70],\n",
              "         [ 56,  31,   7],\n",
              "         [ 53,  34,  20]],\n",
              "\n",
              "        [[180, 139,  96],\n",
              "         [173, 123,  42],\n",
              "         [186, 144,  30],\n",
              "         ...,\n",
              "         [184, 148,  94],\n",
              "         [ 97,  62,  34],\n",
              "         [ 83,  53,  34]],\n",
              "\n",
              "        [[177, 144, 116],\n",
              "         [168, 129,  94],\n",
              "         [179, 142,  87],\n",
              "         ...,\n",
              "         [216, 184, 140],\n",
              "         [151, 118,  84],\n",
              "         [123,  92,  72]]],\n",
              "\n",
              "\n",
              "       [[[154, 177, 187],\n",
              "         [126, 137, 136],\n",
              "         [105, 104,  95],\n",
              "         ...,\n",
              "         [ 91,  95,  71],\n",
              "         [ 87,  90,  71],\n",
              "         [ 79,  81,  70]],\n",
              "\n",
              "        [[140, 160, 169],\n",
              "         [145, 153, 154],\n",
              "         [125, 125, 118],\n",
              "         ...,\n",
              "         [ 96,  99,  78],\n",
              "         [ 77,  80,  62],\n",
              "         [ 71,  73,  61]],\n",
              "\n",
              "        [[140, 155, 164],\n",
              "         [139, 146, 149],\n",
              "         [115, 115, 112],\n",
              "         ...,\n",
              "         [ 79,  82,  64],\n",
              "         [ 68,  70,  55],\n",
              "         [ 67,  69,  55]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[175, 167, 166],\n",
              "         [156, 154, 160],\n",
              "         [154, 160, 170],\n",
              "         ...,\n",
              "         [ 42,  34,  36],\n",
              "         [ 61,  53,  57],\n",
              "         [ 93,  83,  91]],\n",
              "\n",
              "        [[165, 154, 128],\n",
              "         [156, 152, 130],\n",
              "         [159, 161, 142],\n",
              "         ...,\n",
              "         [103,  93,  96],\n",
              "         [123, 114, 120],\n",
              "         [131, 121, 131]],\n",
              "\n",
              "        [[163, 148, 120],\n",
              "         [158, 148, 122],\n",
              "         [163, 156, 133],\n",
              "         ...,\n",
              "         [143, 133, 139],\n",
              "         [143, 134, 142],\n",
              "         [143, 133, 144]]],\n",
              "\n",
              "\n",
              "       [[[255, 255, 255],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         ...,\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[113, 120, 112],\n",
              "         [111, 118, 111],\n",
              "         [105, 112, 106],\n",
              "         ...,\n",
              "         [ 72,  81,  80],\n",
              "         [ 72,  80,  79],\n",
              "         [ 72,  80,  79]],\n",
              "\n",
              "        [[111, 118, 110],\n",
              "         [104, 111, 104],\n",
              "         [ 99, 106,  98],\n",
              "         ...,\n",
              "         [ 68,  75,  73],\n",
              "         [ 70,  76,  75],\n",
              "         [ 78,  84,  82]],\n",
              "\n",
              "        [[106, 113, 105],\n",
              "         [ 99, 106,  98],\n",
              "         [ 95, 102,  94],\n",
              "         ...,\n",
              "         [ 78,  85,  83],\n",
              "         [ 79,  85,  83],\n",
              "         [ 80,  86,  84]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 35, 178, 235],\n",
              "         [ 40, 176, 239],\n",
              "         [ 42, 176, 241],\n",
              "         ...,\n",
              "         [ 99, 177, 219],\n",
              "         [ 79, 147, 197],\n",
              "         [ 89, 148, 189]],\n",
              "\n",
              "        [[ 57, 182, 234],\n",
              "         [ 44, 184, 250],\n",
              "         [ 50, 183, 240],\n",
              "         ...,\n",
              "         [156, 182, 200],\n",
              "         [141, 177, 206],\n",
              "         [116, 149, 175]],\n",
              "\n",
              "        [[ 98, 197, 237],\n",
              "         [ 64, 189, 252],\n",
              "         [ 69, 192, 245],\n",
              "         ...,\n",
              "         [188, 195, 206],\n",
              "         [119, 135, 147],\n",
              "         [ 61,  79,  90]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 73,  79,  77],\n",
              "         [ 53,  63,  68],\n",
              "         [ 54,  68,  80],\n",
              "         ...,\n",
              "         [ 17,  40,  64],\n",
              "         [ 21,  36,  51],\n",
              "         [ 33,  48,  49]],\n",
              "\n",
              "        [[ 61,  68,  75],\n",
              "         [ 55,  70,  86],\n",
              "         [ 57,  79, 103],\n",
              "         ...,\n",
              "         [ 24,  48,  72],\n",
              "         [ 17,  35,  53],\n",
              "         [  7,  23,  32]],\n",
              "\n",
              "        [[ 44,  56,  73],\n",
              "         [ 46,  66,  88],\n",
              "         [ 49,  77, 105],\n",
              "         ...,\n",
              "         [ 27,  52,  77],\n",
              "         [ 21,  43,  66],\n",
              "         [ 12,  31,  50]]],\n",
              "\n",
              "\n",
              "       [[[189, 211, 240],\n",
              "         [186, 208, 236],\n",
              "         [185, 207, 235],\n",
              "         ...,\n",
              "         [175, 195, 224],\n",
              "         [172, 194, 222],\n",
              "         [169, 194, 220]],\n",
              "\n",
              "        [[194, 210, 239],\n",
              "         [191, 207, 236],\n",
              "         [190, 206, 235],\n",
              "         ...,\n",
              "         [173, 192, 220],\n",
              "         [171, 191, 218],\n",
              "         [167, 190, 216]],\n",
              "\n",
              "        [[208, 219, 244],\n",
              "         [205, 216, 240],\n",
              "         [204, 215, 239],\n",
              "         ...,\n",
              "         [175, 191, 217],\n",
              "         [172, 190, 216],\n",
              "         [169, 191, 215]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[207, 199, 181],\n",
              "         [203, 195, 175],\n",
              "         [203, 196, 173],\n",
              "         ...,\n",
              "         [135, 132, 127],\n",
              "         [162, 158, 150],\n",
              "         [168, 163, 151]],\n",
              "\n",
              "        [[198, 190, 170],\n",
              "         [189, 181, 159],\n",
              "         [180, 172, 147],\n",
              "         ...,\n",
              "         [178, 171, 160],\n",
              "         [175, 169, 156],\n",
              "         [175, 169, 154]],\n",
              "\n",
              "        [[198, 189, 173],\n",
              "         [189, 181, 162],\n",
              "         [178, 170, 149],\n",
              "         ...,\n",
              "         [195, 184, 169],\n",
              "         [196, 189, 171],\n",
              "         [195, 190, 171]]],\n",
              "\n",
              "\n",
              "       [[[229, 229, 239],\n",
              "         [236, 237, 247],\n",
              "         [234, 236, 247],\n",
              "         ...,\n",
              "         [217, 219, 233],\n",
              "         [221, 223, 234],\n",
              "         [222, 223, 233]],\n",
              "\n",
              "        [[222, 221, 229],\n",
              "         [239, 239, 249],\n",
              "         [233, 234, 246],\n",
              "         ...,\n",
              "         [223, 223, 236],\n",
              "         [227, 228, 238],\n",
              "         [210, 211, 220]],\n",
              "\n",
              "        [[213, 206, 211],\n",
              "         [234, 232, 239],\n",
              "         [231, 233, 244],\n",
              "         ...,\n",
              "         [220, 220, 232],\n",
              "         [220, 219, 232],\n",
              "         [202, 203, 215]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[150, 143, 135],\n",
              "         [140, 135, 127],\n",
              "         [132, 127, 120],\n",
              "         ...,\n",
              "         [224, 222, 218],\n",
              "         [230, 228, 225],\n",
              "         [241, 241, 238]],\n",
              "\n",
              "        [[137, 132, 126],\n",
              "         [130, 127, 120],\n",
              "         [125, 121, 115],\n",
              "         ...,\n",
              "         [181, 180, 178],\n",
              "         [202, 201, 198],\n",
              "         [212, 211, 207]],\n",
              "\n",
              "        [[122, 119, 114],\n",
              "         [118, 116, 110],\n",
              "         [120, 116, 111],\n",
              "         ...,\n",
              "         [179, 177, 173],\n",
              "         [164, 164, 162],\n",
              "         [163, 163, 161]]]], dtype=uint8)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "odG2hHDY2vRX"
      },
      "outputs": [],
      "source": [
        "# Convert class vectors to one hot format\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "FxqAAjP42vRX"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "5X4aV8gp2vRY"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At2kac0J2vRY",
        "outputId": "1aed05c4-f4b9-4e5c-a15c-a1ad5941b5f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               2097664   \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2122186 (8.10 MB)\n",
            "Trainable params: 2122186 (8.10 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N_L7jVY2vRY"
      },
      "source": [
        "### References:\n",
        "\n",
        "* [Google Colab](https://colab.research.google.com/) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow with free GPU support.  No setup needed.\n",
        "* [IBM Cognitive Class Labs](https://www.datascientistworkbench.com) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow.  No setup needed.\n",
        "* [Python Anaconda](https://www.continuum.io/downloads) - Python distribution that includes many data science packages, such as Numpy, Scipy, Scikit-Learn, Pandas, and much more.\n",
        "* [TensorFlow](https://www.tensorflow.org/) - Google's mathematics package for deep learning.\n",
        "* [Kaggle](https://www.kaggle.com/) - Competitive data science.  Good source of sample data.\n",
        "* T81-558: Applications of Deep Neural Networks. Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
