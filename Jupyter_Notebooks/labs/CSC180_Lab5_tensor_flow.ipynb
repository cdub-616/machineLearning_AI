{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ksna70NzRbHh"
      },
      "source": [
        "## Lab 5: Tensorflow Introduction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxStzmR3RbHd"
      },
      "source": [
        "#### CSC 180 Intelligent Systems\n",
        "\n",
        "#### California State University, Sacramento\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGXHHC1CRbHi"
      },
      "source": [
        "# Helpful Functions for Tensorflow (little gems)\n",
        "\n",
        "The following functions will be used with TensorFlow to help preprocess the data.  They allow you to build the feature vector for a neural network.\n",
        "\n",
        "* Predictors/Inputs\n",
        "    * Fill any missing inputs with the median for that column.  Use **missing_median**.\n",
        "    * Encode textual/categorical values with **encode_text_dummy**.\n",
        "    * Encode numeric values with **encode_numeric_zscore**.\n",
        "* Output\n",
        "    * Discard rows with missing outputs.\n",
        "    * Encode textual/categorical values with **encode_text_index**.\n",
        "    * Do not encode output numeric values.\n",
        "* Produce final feature vectors (x) and expected output (y) with **to_xy**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-daOZ9RWRbHk"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Sequence\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
        "def encode_text_dummy(df, name):\n",
        "    dummies = pd.get_dummies(df[name])\n",
        "    for x in dummies.columns:\n",
        "        dummy_name = \"{}-{}\".format(name, x)\n",
        "        df[dummy_name] = dummies[x]\n",
        "    df.drop(name, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
        "def encode_text_index(df, name):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    df[name] = le.fit_transform(df[name])\n",
        "    return le.classes_\n",
        "\n",
        "\n",
        "# Encode a numeric column as zscores\n",
        "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
        "    if mean is None:\n",
        "        mean = df[name].mean()\n",
        "\n",
        "    if sd is None:\n",
        "        sd = df[name].std()\n",
        "\n",
        "    df[name] = (df[name] - mean) / sd\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the median\n",
        "def missing_median(df, name):\n",
        "    med = df[name].median()\n",
        "    df[name] = df[name].fillna(med)\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the default\n",
        "def missing_default(df, name, default_value):\n",
        "    df[name] = df[name].fillna(default_value)\n",
        "\n",
        "\n",
        "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
        "def to_xy(df, target):\n",
        "    result = []\n",
        "    for x in df.columns:\n",
        "        if x != target:\n",
        "            result.append(x)\n",
        "    # find out the type of the target column.\n",
        "    target_type = df[target].dtypes\n",
        "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
        "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
        "    if target_type in (np.int64, np.int32):\n",
        "        # Classification\n",
        "        dummies = pd.get_dummies(df[target])\n",
        "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
        "    else:\n",
        "        # Regression\n",
        "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
        "\n",
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "\n",
        "# Regression chart.\n",
        "def chart_regression(pred,y,sort=True):\n",
        "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
        "    if sort:\n",
        "        t.sort_values(by=['y'],inplace=True)\n",
        "    a = plt.plot(t['y'].tolist(),label='expected')\n",
        "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
        "    plt.ylabel('output')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Remove all rows where the specified column is +/- sd standard deviations\n",
        "def remove_outliers(df, name, sd):\n",
        "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
        "    df.drop(drop_rows, axis=0, inplace=True)\n",
        "\n",
        "\n",
        "# Encode a column to a range between normalized_low and normalized_high.\n",
        "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
        "                         data_low=None, data_high=None):\n",
        "    if data_low is None:\n",
        "        data_low = min(df[name])\n",
        "        data_high = max(df[name])\n",
        "\n",
        "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
        "               * (normalized_high - normalized_low) + normalized_low\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj0LiOULRbHm"
      },
      "source": [
        "# Classification or Regression\n",
        "\n",
        "Neural networks can function in *** classification or regression***:\n",
        "\n",
        "* **Regression** - You expect a number as your neural network's prediction.\n",
        "* **Classification** - You expect a class/category as your neural network's prediction.\n",
        "\n",
        "Regression networks always have a single output neuron.  Classification neural networks have an output neuron for each class.\n",
        "\n",
        "These neurons are grouped into layers:\n",
        "\n",
        "* **Input Layer** - The input layer accepts feature vectors from the dataset.  Input layers usually have a bias neuron.\n",
        "* **Output Layer** - The output from the neural network.  The output layer does not have a bias neuron.\n",
        "* **Hidden Layers** - Layers that occur between the input and output layers.  Each hidden layer will usually have a bias neuron.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AihrYLwERbHm"
      },
      "source": [
        "# What version of TensorFlow do you have?\n",
        "\n",
        "TensorFlow is very new and changing rapidly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WqEBeNJBRbHn",
        "outputId": "8d2dfeb9-bc38-441c-b589-ad5ca5640554"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor Flow Version: 2.12.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensor Flow Version: {}\".format(tf.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_L_-phiRbHo"
      },
      "source": [
        "# Why TensorFlow\n",
        "\n",
        "* Supported by Google\n",
        "* Works well on Linux/Mac\n",
        "* Excellent GPU support\n",
        "* Most popular today"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_JqloZERbHp"
      },
      "source": [
        "# Example of TensorFlow Regression: MPG Prediction\n",
        "\n",
        "This example shows how to encode the MPG dataset for regression.  Notice that:\n",
        "\n",
        "* Input has both numeric and categorical\n",
        "* Input has missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YvyXVPPqRbHp",
        "outputId": "c5f40255-5986-4b3f-f7bf-da21198bdf3e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>year</th>\n",
              "      <th>origin</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>307.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>3504</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>chevrolet chevelle malibu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>3693</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>buick skylark 320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>318.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3436</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>plymouth satellite</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0</td>\n",
              "      <td>8</td>\n",
              "      <td>304.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3433</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>amc rebel sst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>3449</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>ford torino</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
              "0  18.0          8         307.0       130.0    3504          12.0    70   \n",
              "1  15.0          8         350.0       165.0    3693          11.5    70   \n",
              "2  18.0          8         318.0       150.0    3436          11.0    70   \n",
              "3  16.0          8         304.0       150.0    3433          12.0    70   \n",
              "4  17.0          8         302.0       140.0    3449          10.5    70   \n",
              "\n",
              "   origin                       name  \n",
              "0       1  chevrolet chevelle malibu  \n",
              "1       1          buick skylark 320  \n",
              "2       1         plymouth satellite  \n",
              "3       1              amc rebel sst  \n",
              "4       1                ford torino  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "path = \"./data/\"\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "\n",
        "df[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4jcKgegnRbHp"
      },
      "outputs": [],
      "source": [
        "cars = df['name']\n",
        "\n",
        "df.drop('name',axis=1,inplace=True)\n",
        "\n",
        "missing_median(df, 'horsepower')\n",
        "\n",
        "encode_text_dummy(df, 'origin')\n",
        "\n",
        "x,y = to_xy(df,\"mpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XJ1IocJmRbHq",
        "outputId": "5e24b888-aed3-4c3b-b4d8-8b8020a43042"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(398, 9)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4N85aX57RbHq",
        "outputId": "387c7125-853f-418c-f16d-54953ecca93c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(398,)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WPS3uv9wRbHr",
        "outputId": "2c2e8080-411a-43da-ad71-112e313352a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  8., 307., 130., ...,   1.,   0.,   0.],\n",
              "       [  8., 350., 165., ...,   1.,   0.,   0.],\n",
              "       [  8., 318., 150., ...,   1.,   0.,   0.],\n",
              "       ...,\n",
              "       [  4., 135.,  84., ...,   1.,   0.,   0.],\n",
              "       [  4., 120.,  79., ...,   1.,   0.,   0.],\n",
              "       [  4., 119.,  82., ...,   1.,   0.,   0.]], dtype=float32)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rN3a746zRbHr",
        "outputId": "a3c42e1c-3b74-4285-b348-cdf2e8f99bed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([18. , 15. , 18. , 16. , 17. , 15. , 14. , 14. , 14. , 15. , 15. ,\n",
              "       14. , 15. , 14. , 24. , 22. , 18. , 21. , 27. , 26. , 25. , 24. ,\n",
              "       25. , 26. , 21. , 10. , 10. , 11. ,  9. , 27. , 28. , 25. , 25. ,\n",
              "       19. , 16. , 17. , 19. , 18. , 14. , 14. , 14. , 14. , 12. , 13. ,\n",
              "       13. , 18. , 22. , 19. , 18. , 23. , 28. , 30. , 30. , 31. , 35. ,\n",
              "       27. , 26. , 24. , 25. , 23. , 20. , 21. , 13. , 14. , 15. , 14. ,\n",
              "       17. , 11. , 13. , 12. , 13. , 19. , 15. , 13. , 13. , 14. , 18. ,\n",
              "       22. , 21. , 26. , 22. , 28. , 23. , 28. , 27. , 13. , 14. , 13. ,\n",
              "       14. , 15. , 12. , 13. , 13. , 14. , 13. , 12. , 13. , 18. , 16. ,\n",
              "       18. , 18. , 23. , 26. , 11. , 12. , 13. , 12. , 18. , 20. , 21. ,\n",
              "       22. , 18. , 19. , 21. , 26. , 15. , 16. , 29. , 24. , 20. , 19. ,\n",
              "       15. , 24. , 20. , 11. , 20. , 21. , 19. , 15. , 31. , 26. , 32. ,\n",
              "       25. , 16. , 16. , 18. , 16. , 13. , 14. , 14. , 14. , 29. , 26. ,\n",
              "       26. , 31. , 32. , 28. , 24. , 26. , 24. , 26. , 31. , 19. , 18. ,\n",
              "       15. , 15. , 16. , 15. , 16. , 14. , 17. , 16. , 15. , 18. , 21. ,\n",
              "       20. , 13. , 29. , 23. , 20. , 23. , 24. , 25. , 24. , 18. , 29. ,\n",
              "       19. , 23. , 23. , 22. , 25. , 33. , 28. , 25. , 25. , 26. , 27. ,\n",
              "       17.5, 16. , 15.5, 14.5, 22. , 22. , 24. , 22.5, 29. , 24.5, 29. ,\n",
              "       33. , 20. , 18. , 18.5, 17.5, 29.5, 32. , 28. , 26.5, 20. , 13. ,\n",
              "       19. , 19. , 16.5, 16.5, 13. , 13. , 13. , 31.5, 30. , 36. , 25.5,\n",
              "       33.5, 17.5, 17. , 15.5, 15. , 17.5, 20.5, 19. , 18.5, 16. , 15.5,\n",
              "       15.5, 16. , 29. , 24.5, 26. , 25.5, 30.5, 33.5, 30. , 30.5, 22. ,\n",
              "       21.5, 21.5, 43.1, 36.1, 32.8, 39.4, 36.1, 19.9, 19.4, 20.2, 19.2,\n",
              "       20.5, 20.2, 25.1, 20.5, 19.4, 20.6, 20.8, 18.6, 18.1, 19.2, 17.7,\n",
              "       18.1, 17.5, 30. , 27.5, 27.2, 30.9, 21.1, 23.2, 23.8, 23.9, 20.3,\n",
              "       17. , 21.6, 16.2, 31.5, 29.5, 21.5, 19.8, 22.3, 20.2, 20.6, 17. ,\n",
              "       17.6, 16.5, 18.2, 16.9, 15.5, 19.2, 18.5, 31.9, 34.1, 35.7, 27.4,\n",
              "       25.4, 23. , 27.2, 23.9, 34.2, 34.5, 31.8, 37.3, 28.4, 28.8, 26.8,\n",
              "       33.5, 41.5, 38.1, 32.1, 37.2, 28. , 26.4, 24.3, 19.1, 34.3, 29.8,\n",
              "       31.3, 37. , 32.2, 46.6, 27.9, 40.8, 44.3, 43.4, 36.4, 30. , 44.6,\n",
              "       40.9, 33.8, 29.8, 32.7, 23.7, 35. , 23.6, 32.4, 27.2, 26.6, 25.8,\n",
              "       23.5, 30. , 39.1, 39. , 35.1, 32.3, 37. , 37.7, 34.1, 34.7, 34.4,\n",
              "       29.9, 33. , 34.5, 33.7, 32.4, 32.9, 31.6, 28.1, 30.7, 25.4, 24.2,\n",
              "       22.4, 26.6, 20.2, 17.6, 28. , 27. , 34. , 31. , 29. , 27. , 24. ,\n",
              "       23. , 36. , 37. , 31. , 38. , 36. , 36. , 36. , 34. , 38. , 32. ,\n",
              "       38. , 25. , 38. , 26. , 22. , 32. , 36. , 27. , 27. , 44. , 32. ,\n",
              "       28. , 31. ], dtype=float32)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TwsF2z7HRbHs",
        "outputId": "e0fa2ca2-a300-4604-e974-c959c83ed482"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13/13 - 0s - loss: 207549.2812 - 129ms/epoch - 10ms/step\n",
            "Epoch 2/100\n",
            "13/13 - 0s - loss: 63437.7578 - 6ms/epoch - 475us/step\n",
            "Epoch 3/100\n",
            "13/13 - 0s - loss: 10089.8193 - 6ms/epoch - 471us/step\n",
            "Epoch 4/100\n",
            "13/13 - 0s - loss: 497.7652 - 6ms/epoch - 427us/step\n",
            "Epoch 5/100\n",
            "13/13 - 0s - loss: 766.6637 - 6ms/epoch - 448us/step\n",
            "Epoch 6/100\n",
            "13/13 - 0s - loss: 498.1923 - 6ms/epoch - 474us/step\n",
            "Epoch 7/100\n",
            "13/13 - 0s - loss: 239.7750 - 6ms/epoch - 453us/step\n",
            "Epoch 8/100\n",
            "13/13 - 0s - loss: 228.4013 - 6ms/epoch - 436us/step\n",
            "Epoch 9/100\n",
            "13/13 - 0s - loss: 223.2844 - 5ms/epoch - 415us/step\n",
            "Epoch 10/100\n",
            "13/13 - 0s - loss: 218.7287 - 6ms/epoch - 428us/step\n",
            "Epoch 11/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-14 10:04:48.703625: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 - 0s - loss: 218.1397 - 6ms/epoch - 476us/step\n",
            "Epoch 12/100\n",
            "13/13 - 0s - loss: 217.1381 - 6ms/epoch - 441us/step\n",
            "Epoch 13/100\n",
            "13/13 - 0s - loss: 215.7037 - 6ms/epoch - 429us/step\n",
            "Epoch 14/100\n",
            "13/13 - 0s - loss: 214.8366 - 6ms/epoch - 447us/step\n",
            "Epoch 15/100\n",
            "13/13 - 0s - loss: 213.4424 - 6ms/epoch - 450us/step\n",
            "Epoch 16/100\n",
            "13/13 - 0s - loss: 212.4042 - 6ms/epoch - 426us/step\n",
            "Epoch 17/100\n",
            "13/13 - 0s - loss: 211.1549 - 6ms/epoch - 445us/step\n",
            "Epoch 18/100\n",
            "13/13 - 0s - loss: 209.9386 - 6ms/epoch - 426us/step\n",
            "Epoch 19/100\n",
            "13/13 - 0s - loss: 208.3658 - 6ms/epoch - 428us/step\n",
            "Epoch 20/100\n",
            "13/13 - 0s - loss: 207.4611 - 6ms/epoch - 456us/step\n",
            "Epoch 21/100\n",
            "13/13 - 0s - loss: 205.8401 - 6ms/epoch - 447us/step\n",
            "Epoch 22/100\n",
            "13/13 - 0s - loss: 204.3690 - 6ms/epoch - 468us/step\n",
            "Epoch 23/100\n",
            "13/13 - 0s - loss: 203.0090 - 6ms/epoch - 460us/step\n",
            "Epoch 24/100\n",
            "13/13 - 0s - loss: 201.5507 - 5ms/epoch - 422us/step\n",
            "Epoch 25/100\n",
            "13/13 - 0s - loss: 200.5516 - 5ms/epoch - 414us/step\n",
            "Epoch 26/100\n",
            "13/13 - 0s - loss: 198.6328 - 6ms/epoch - 462us/step\n",
            "Epoch 27/100\n",
            "13/13 - 0s - loss: 197.0450 - 6ms/epoch - 464us/step\n",
            "Epoch 28/100\n",
            "13/13 - 0s - loss: 196.1391 - 6ms/epoch - 450us/step\n",
            "Epoch 29/100\n",
            "13/13 - 0s - loss: 193.9676 - 6ms/epoch - 430us/step\n",
            "Epoch 30/100\n",
            "13/13 - 0s - loss: 193.0130 - 6ms/epoch - 447us/step\n",
            "Epoch 31/100\n",
            "13/13 - 0s - loss: 191.1820 - 6ms/epoch - 456us/step\n",
            "Epoch 32/100\n",
            "13/13 - 0s - loss: 189.3407 - 6ms/epoch - 448us/step\n",
            "Epoch 33/100\n",
            "13/13 - 0s - loss: 188.0284 - 5ms/epoch - 411us/step\n",
            "Epoch 34/100\n",
            "13/13 - 0s - loss: 186.4341 - 6ms/epoch - 425us/step\n",
            "Epoch 35/100\n",
            "13/13 - 0s - loss: 184.8714 - 5ms/epoch - 422us/step\n",
            "Epoch 36/100\n",
            "13/13 - 0s - loss: 183.0857 - 6ms/epoch - 433us/step\n",
            "Epoch 37/100\n",
            "13/13 - 0s - loss: 181.6430 - 5ms/epoch - 421us/step\n",
            "Epoch 38/100\n",
            "13/13 - 0s - loss: 180.0799 - 5ms/epoch - 416us/step\n",
            "Epoch 39/100\n",
            "13/13 - 0s - loss: 178.6783 - 5ms/epoch - 417us/step\n",
            "Epoch 40/100\n",
            "13/13 - 0s - loss: 177.2497 - 5ms/epoch - 410us/step\n",
            "Epoch 41/100\n",
            "13/13 - 0s - loss: 175.7472 - 6ms/epoch - 444us/step\n",
            "Epoch 42/100\n",
            "13/13 - 0s - loss: 174.7741 - 6ms/epoch - 423us/step\n",
            "Epoch 43/100\n",
            "13/13 - 0s - loss: 172.2085 - 6ms/epoch - 442us/step\n",
            "Epoch 44/100\n",
            "13/13 - 0s - loss: 170.4196 - 10ms/epoch - 736us/step\n",
            "Epoch 45/100\n",
            "13/13 - 0s - loss: 169.2153 - 10ms/epoch - 777us/step\n",
            "Epoch 46/100\n",
            "13/13 - 0s - loss: 167.4348 - 9ms/epoch - 677us/step\n",
            "Epoch 47/100\n",
            "13/13 - 0s - loss: 165.8926 - 6ms/epoch - 495us/step\n",
            "Epoch 48/100\n",
            "13/13 - 0s - loss: 164.0963 - 6ms/epoch - 499us/step\n",
            "Epoch 49/100\n",
            "13/13 - 0s - loss: 164.2988 - 6ms/epoch - 443us/step\n",
            "Epoch 50/100\n",
            "13/13 - 0s - loss: 160.3815 - 5ms/epoch - 406us/step\n",
            "Epoch 51/100\n",
            "13/13 - 0s - loss: 158.9183 - 5ms/epoch - 422us/step\n",
            "Epoch 52/100\n",
            "13/13 - 0s - loss: 157.3233 - 5ms/epoch - 405us/step\n",
            "Epoch 53/100\n",
            "13/13 - 0s - loss: 155.9764 - 6ms/epoch - 428us/step\n",
            "Epoch 54/100\n",
            "13/13 - 0s - loss: 155.0763 - 5ms/epoch - 408us/step\n",
            "Epoch 55/100\n",
            "13/13 - 0s - loss: 152.3532 - 6ms/epoch - 439us/step\n",
            "Epoch 56/100\n",
            "13/13 - 0s - loss: 150.9697 - 6ms/epoch - 431us/step\n",
            "Epoch 57/100\n",
            "13/13 - 0s - loss: 149.6829 - 6ms/epoch - 433us/step\n",
            "Epoch 58/100\n",
            "13/13 - 0s - loss: 148.6158 - 5ms/epoch - 406us/step\n",
            "Epoch 59/100\n",
            "13/13 - 0s - loss: 146.0918 - 5ms/epoch - 404us/step\n",
            "Epoch 60/100\n",
            "13/13 - 0s - loss: 144.5553 - 5ms/epoch - 415us/step\n",
            "Epoch 61/100\n",
            "13/13 - 0s - loss: 143.4727 - 5ms/epoch - 418us/step\n",
            "Epoch 62/100\n",
            "13/13 - 0s - loss: 141.5060 - 6ms/epoch - 455us/step\n",
            "Epoch 63/100\n",
            "13/13 - 0s - loss: 140.0793 - 6ms/epoch - 432us/step\n",
            "Epoch 64/100\n",
            "13/13 - 0s - loss: 138.0781 - 6ms/epoch - 425us/step\n",
            "Epoch 65/100\n",
            "13/13 - 0s - loss: 137.4531 - 6ms/epoch - 448us/step\n",
            "Epoch 66/100\n",
            "13/13 - 0s - loss: 135.5270 - 5ms/epoch - 400us/step\n",
            "Epoch 67/100\n",
            "13/13 - 0s - loss: 134.6702 - 5ms/epoch - 417us/step\n",
            "Epoch 68/100\n",
            "13/13 - 0s - loss: 132.3621 - 6ms/epoch - 424us/step\n",
            "Epoch 69/100\n",
            "13/13 - 0s - loss: 130.5722 - 5ms/epoch - 406us/step\n",
            "Epoch 70/100\n",
            "13/13 - 0s - loss: 129.2229 - 5ms/epoch - 423us/step\n",
            "Epoch 71/100\n",
            "13/13 - 0s - loss: 128.0025 - 6ms/epoch - 426us/step\n",
            "Epoch 72/100\n",
            "13/13 - 0s - loss: 126.5459 - 5ms/epoch - 422us/step\n",
            "Epoch 73/100\n",
            "13/13 - 0s - loss: 125.2677 - 5ms/epoch - 405us/step\n",
            "Epoch 74/100\n",
            "13/13 - 0s - loss: 123.4427 - 6ms/epoch - 427us/step\n",
            "Epoch 75/100\n",
            "13/13 - 0s - loss: 122.0309 - 5ms/epoch - 415us/step\n",
            "Epoch 76/100\n",
            "13/13 - 0s - loss: 120.7398 - 5ms/epoch - 411us/step\n",
            "Epoch 77/100\n",
            "13/13 - 0s - loss: 119.1675 - 5ms/epoch - 387us/step\n",
            "Epoch 78/100\n",
            "13/13 - 0s - loss: 118.1978 - 5ms/epoch - 411us/step\n",
            "Epoch 79/100\n",
            "13/13 - 0s - loss: 116.7122 - 6ms/epoch - 426us/step\n",
            "Epoch 80/100\n",
            "13/13 - 0s - loss: 116.3808 - 6ms/epoch - 434us/step\n",
            "Epoch 81/100\n",
            "13/13 - 0s - loss: 114.1933 - 5ms/epoch - 389us/step\n",
            "Epoch 82/100\n",
            "13/13 - 0s - loss: 112.8230 - 6ms/epoch - 435us/step\n",
            "Epoch 83/100\n",
            "13/13 - 0s - loss: 111.7350 - 5ms/epoch - 403us/step\n",
            "Epoch 84/100\n",
            "13/13 - 0s - loss: 110.1669 - 5ms/epoch - 421us/step\n",
            "Epoch 85/100\n",
            "13/13 - 0s - loss: 108.9373 - 5ms/epoch - 398us/step\n",
            "Epoch 86/100\n",
            "13/13 - 0s - loss: 107.5351 - 5ms/epoch - 399us/step\n",
            "Epoch 87/100\n",
            "13/13 - 0s - loss: 106.5155 - 5ms/epoch - 421us/step\n",
            "Epoch 88/100\n",
            "13/13 - 0s - loss: 104.9714 - 6ms/epoch - 429us/step\n",
            "Epoch 89/100\n",
            "13/13 - 0s - loss: 103.7999 - 5ms/epoch - 403us/step\n",
            "Epoch 90/100\n",
            "13/13 - 0s - loss: 102.7947 - 6ms/epoch - 424us/step\n",
            "Epoch 91/100\n",
            "13/13 - 0s - loss: 102.0102 - 5ms/epoch - 417us/step\n",
            "Epoch 92/100\n",
            "13/13 - 0s - loss: 100.3180 - 5ms/epoch - 409us/step\n",
            "Epoch 93/100\n",
            "13/13 - 0s - loss: 99.3829 - 6ms/epoch - 432us/step\n",
            "Epoch 94/100\n",
            "13/13 - 0s - loss: 98.1800 - 5ms/epoch - 417us/step\n",
            "Epoch 95/100\n",
            "13/13 - 0s - loss: 96.8192 - 5ms/epoch - 399us/step\n",
            "Epoch 96/100\n",
            "13/13 - 0s - loss: 95.8465 - 6ms/epoch - 440us/step\n",
            "Epoch 97/100\n",
            "13/13 - 0s - loss: 94.7430 - 5ms/epoch - 420us/step\n",
            "Epoch 98/100\n",
            "13/13 - 0s - loss: 93.9726 - 10ms/epoch - 782us/step\n",
            "Epoch 99/100\n",
            "13/13 - 0s - loss: 92.7850 - 12ms/epoch - 887us/step\n",
            "Epoch 100/100\n",
            "13/13 - 0s - loss: 91.9718 - 8ms/epoch - 652us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x29ed13290>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(25, input_dim=x.shape[1], activation='relu')) # Hidden 1     #  why input_dim=x.shape[1]?\n",
        "model.add(Dense(10, activation='relu')) # Hidden 2\n",
        "model.add(Dense(1)) # Output\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "model.fit(x,y,verbose=2,epochs=100)    # Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1UzvBhERbHt"
      },
      "source": [
        "### Monitor the loss at each epoch\n",
        "\n",
        "One line is produced for each training epoch.  You can eliminate this output by setting the verbose setting of the fit command:\n",
        "\n",
        "* **verbose=0** - No progress output (use with Juputer if you do not want output)\n",
        "* **verbose=1** - Display progress bar, does not work well with Jupyter\n",
        "* **verbose=2** - Summary progress output (use with Jupyter if you want to know the loss at each epoch)\n",
        "\n",
        "\n",
        "## Use Trained Model to Make Regression Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_H7WQHmRbHt"
      },
      "source": [
        "Next we will perform actual predictions.  These predictions are assigned to the **pred** variable. These are all MPG predictions from the neural network.  \n",
        "\n",
        "***Notice that the data to predict should be a 2D array!***  \n",
        "\n",
        "***Notice that the prediction result is also a 2D array!***\n",
        "\n",
        "Neural networks can return multiple values, so the result is always an array.  Here the neural network only returns 1 value per prediction (there are 398 cars, so 398 predictions).  However, a 2D array is needed because the neural network has the potential of returning more than one value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sdrY44nkRbHt",
        "outputId": "2c30eff9-6c85-49ef-f7f0-1e9e19fecb32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 0s 379us/step\n",
            "Shape: (398, 1)\n",
            "[[17.451992  ]\n",
            " [13.535798  ]\n",
            " [13.57647   ]\n",
            " [14.402844  ]\n",
            " [15.772935  ]\n",
            " [13.904958  ]\n",
            " [10.090627  ]\n",
            " [10.864251  ]\n",
            " [10.486577  ]\n",
            " [10.3378725 ]\n",
            " [ 9.225991  ]\n",
            " [13.327462  ]\n",
            " [13.152219  ]\n",
            " [-0.92008126]\n",
            " [19.6802    ]\n",
            " [19.47593   ]\n",
            " [18.396244  ]\n",
            " [17.205793  ]\n",
            " [18.097584  ]\n",
            " [19.041002  ]\n",
            " [24.75649   ]\n",
            " [21.139774  ]\n",
            " [20.189955  ]\n",
            " [14.963874  ]\n",
            " [17.458221  ]\n",
            " [19.89138   ]\n",
            " [21.475151  ]\n",
            " [19.698975  ]\n",
            " [27.458366  ]\n",
            " [18.16037   ]\n",
            " [16.393467  ]\n",
            " [17.73883   ]\n",
            " [15.688348  ]\n",
            " [14.1789465 ]\n",
            " [25.028065  ]\n",
            " [22.672783  ]\n",
            " [23.666935  ]\n",
            " [23.154785  ]\n",
            " [20.589413  ]\n",
            " [19.990788  ]\n",
            " [21.241234  ]\n",
            " [22.665192  ]\n",
            " [27.025177  ]\n",
            " [24.391407  ]\n",
            " [29.139801  ]\n",
            " [16.006844  ]\n",
            " [20.589705  ]\n",
            " [22.00795   ]\n",
            " [21.406551  ]\n",
            " [17.195066  ]\n",
            " [16.51323   ]\n",
            " [20.583979  ]\n",
            " [18.956707  ]\n",
            " [17.72194   ]\n",
            " [14.991729  ]\n",
            " [17.41281   ]\n",
            " [17.616348  ]\n",
            " [18.568783  ]\n",
            " [18.263489  ]\n",
            " [24.09814   ]\n",
            " [18.645853  ]\n",
            " [17.493368  ]\n",
            " [21.528889  ]\n",
            " [19.018929  ]\n",
            " [23.284927  ]\n",
            " [20.935825  ]\n",
            " [17.721256  ]\n",
            " [16.898933  ]\n",
            " [25.828926  ]\n",
            " [24.642536  ]\n",
            " [17.850906  ]\n",
            " [21.706936  ]\n",
            " [20.75042   ]\n",
            " [25.713188  ]\n",
            " [27.636093  ]\n",
            " [22.533451  ]\n",
            " [24.754513  ]\n",
            " [23.353996  ]\n",
            " [28.571547  ]\n",
            " [21.24082   ]\n",
            " [19.741976  ]\n",
            " [20.056091  ]\n",
            " [20.953327  ]\n",
            " [18.623697  ]\n",
            " [17.94216   ]\n",
            " [18.174625  ]\n",
            " [17.784035  ]\n",
            " [20.059967  ]\n",
            " [24.546753  ]\n",
            " [18.457039  ]\n",
            " [22.427513  ]\n",
            " [22.977318  ]\n",
            " [23.588924  ]\n",
            " [24.785385  ]\n",
            " [16.912678  ]\n",
            " [17.831524  ]\n",
            " [13.712697  ]\n",
            " [20.926193  ]\n",
            " [22.265068  ]\n",
            " [18.68486   ]\n",
            " [20.064133  ]\n",
            " [20.652977  ]\n",
            " [20.81152   ]\n",
            " [30.29012   ]\n",
            " [27.045662  ]\n",
            " [25.638046  ]\n",
            " [22.959469  ]\n",
            " [16.518864  ]\n",
            " [20.573942  ]\n",
            " [20.65181   ]\n",
            " [20.456455  ]\n",
            " [19.78355   ]\n",
            " [18.926054  ]\n",
            " [15.816628  ]\n",
            " [19.681961  ]\n",
            " [21.327904  ]\n",
            " [11.258027  ]\n",
            " [20.927216  ]\n",
            " [18.901693  ]\n",
            " [22.831703  ]\n",
            " [24.002392  ]\n",
            " [13.265882  ]\n",
            " [21.330482  ]\n",
            " [19.485878  ]\n",
            " [11.604074  ]\n",
            " [23.417252  ]\n",
            " [20.441093  ]\n",
            " [18.154121  ]\n",
            " [23.048313  ]\n",
            " [19.611319  ]\n",
            " [21.332947  ]\n",
            " [18.883734  ]\n",
            " [22.12224   ]\n",
            " [29.050556  ]\n",
            " [25.51059   ]\n",
            " [27.62519   ]\n",
            " [25.574375  ]\n",
            " [29.239563  ]\n",
            " [27.75373   ]\n",
            " [32.401665  ]\n",
            " [25.984818  ]\n",
            " [19.978483  ]\n",
            " [19.36743   ]\n",
            " [21.570889  ]\n",
            " [17.267298  ]\n",
            " [20.775368  ]\n",
            " [19.21827   ]\n",
            " [19.785107  ]\n",
            " [20.05867   ]\n",
            " [20.880537  ]\n",
            " [20.732454  ]\n",
            " [19.897457  ]\n",
            " [24.08173   ]\n",
            " [24.142319  ]\n",
            " [27.822819  ]\n",
            " [24.034313  ]\n",
            " [23.559673  ]\n",
            " [26.344032  ]\n",
            " [28.431328  ]\n",
            " [28.842842  ]\n",
            " [31.020737  ]\n",
            " [30.204742  ]\n",
            " [26.957123  ]\n",
            " [31.294594  ]\n",
            " [18.941978  ]\n",
            " [18.893288  ]\n",
            " [13.648202  ]\n",
            " [20.528913  ]\n",
            " [22.587826  ]\n",
            " [18.392319  ]\n",
            " [22.612608  ]\n",
            " [23.031725  ]\n",
            " [21.913675  ]\n",
            " [21.879795  ]\n",
            " [23.091015  ]\n",
            " [18.014683  ]\n",
            " [23.59209   ]\n",
            " [24.019545  ]\n",
            " [28.195442  ]\n",
            " [26.689507  ]\n",
            " [21.007519  ]\n",
            " [18.385485  ]\n",
            " [22.48977   ]\n",
            " [19.333712  ]\n",
            " [20.598316  ]\n",
            " [20.382395  ]\n",
            " [19.628086  ]\n",
            " [26.463787  ]\n",
            " [24.247124  ]\n",
            " [25.428467  ]\n",
            " [22.447945  ]\n",
            " [23.123295  ]\n",
            " [22.682663  ]\n",
            " [23.866726  ]\n",
            " [21.992496  ]\n",
            " [21.497124  ]\n",
            " [21.577805  ]\n",
            " [18.08983   ]\n",
            " [18.44211   ]\n",
            " [28.903515  ]\n",
            " [29.121784  ]\n",
            " [26.160286  ]\n",
            " [21.400455  ]\n",
            " [15.939839  ]\n",
            " [19.468166  ]\n",
            " [20.400621  ]\n",
            " [22.687494  ]\n",
            " [28.621319  ]\n",
            " [20.887379  ]\n",
            " [32.782978  ]\n",
            " [23.041773  ]\n",
            " [32.869144  ]\n",
            " [21.518158  ]\n",
            " [21.09018   ]\n",
            " [23.238499  ]\n",
            " [18.44149   ]\n",
            " [19.84444   ]\n",
            " [18.05637   ]\n",
            " [18.904966  ]\n",
            " [17.611666  ]\n",
            " [18.91167   ]\n",
            " [21.411137  ]\n",
            " [30.79052   ]\n",
            " [24.244755  ]\n",
            " [29.027607  ]\n",
            " [24.549416  ]\n",
            " [24.95758   ]\n",
            " [28.683067  ]\n",
            " [26.136047  ]\n",
            " [16.485844  ]\n",
            " [19.769714  ]\n",
            " [16.838009  ]\n",
            " [24.574009  ]\n",
            " [16.903559  ]\n",
            " [22.815416  ]\n",
            " [22.058413  ]\n",
            " [23.524635  ]\n",
            " [19.4615    ]\n",
            " [17.453236  ]\n",
            " [19.076027  ]\n",
            " [20.250887  ]\n",
            " [23.311821  ]\n",
            " [20.69822   ]\n",
            " [25.234629  ]\n",
            " [21.80459   ]\n",
            " [15.638413  ]\n",
            " [22.114824  ]\n",
            " [20.771753  ]\n",
            " [17.7809    ]\n",
            " [21.262634  ]\n",
            " [19.37984   ]\n",
            " [18.162884  ]\n",
            " [26.646168  ]\n",
            " [24.373447  ]\n",
            " [22.794262  ]\n",
            " [23.203852  ]\n",
            " [26.017288  ]\n",
            " [23.779354  ]\n",
            " [24.345215  ]\n",
            " [24.266197  ]\n",
            " [27.54081   ]\n",
            " [21.456127  ]\n",
            " [15.380124  ]\n",
            " [18.28173   ]\n",
            " [13.140714  ]\n",
            " [24.064243  ]\n",
            " [20.330105  ]\n",
            " [21.461275  ]\n",
            " [18.621435  ]\n",
            " [20.023222  ]\n",
            " [20.89141   ]\n",
            " [20.77701   ]\n",
            " [24.867838  ]\n",
            " [20.050049  ]\n",
            " [23.958153  ]\n",
            " [23.352684  ]\n",
            " [23.00449   ]\n",
            " [26.224796  ]\n",
            " [18.917917  ]\n",
            " [21.0037    ]\n",
            " [21.43047   ]\n",
            " [23.342678  ]\n",
            " [25.67708   ]\n",
            " [24.64581   ]\n",
            " [23.9669    ]\n",
            " [22.874516  ]\n",
            " [21.485332  ]\n",
            " [20.738884  ]\n",
            " [21.41373   ]\n",
            " [24.439827  ]\n",
            " [21.689373  ]\n",
            " [22.43121   ]\n",
            " [18.648388  ]\n",
            " [18.048315  ]\n",
            " [19.85144   ]\n",
            " [15.667577  ]\n",
            " [24.565674  ]\n",
            " [33.675278  ]\n",
            " [21.785912  ]\n",
            " [32.78847   ]\n",
            " [24.745548  ]\n",
            " [20.167013  ]\n",
            " [19.597672  ]\n",
            " [20.763258  ]\n",
            " [20.96814   ]\n",
            " [21.770382  ]\n",
            " [15.7449255 ]\n",
            " [17.260054  ]\n",
            " [20.059608  ]\n",
            " [20.024801  ]\n",
            " [20.43586   ]\n",
            " [19.695442  ]\n",
            " [20.581982  ]\n",
            " [21.97203   ]\n",
            " [25.51956   ]\n",
            " [26.578247  ]\n",
            " [26.70673   ]\n",
            " [20.51745   ]\n",
            " [24.26996   ]\n",
            " [24.617197  ]\n",
            " [21.13902   ]\n",
            " [21.428802  ]\n",
            " [21.902107  ]\n",
            " [21.50225   ]\n",
            " [22.039997  ]\n",
            " [23.2914    ]\n",
            " [26.787117  ]\n",
            " [30.59988   ]\n",
            " [33.640293  ]\n",
            " [17.627817  ]\n",
            " [14.78428   ]\n",
            " [21.521435  ]\n",
            " [18.131245  ]\n",
            " [19.362885  ]\n",
            " [23.021921  ]\n",
            " [22.11289   ]\n",
            " [25.13414   ]\n",
            " [22.27438   ]\n",
            " [21.048845  ]\n",
            " [22.127817  ]\n",
            " [20.608738  ]\n",
            " [18.270288  ]\n",
            " [19.459469  ]\n",
            " [18.309687  ]\n",
            " [17.878511  ]\n",
            " [17.986303  ]\n",
            " [20.492832  ]\n",
            " [20.294228  ]\n",
            " [21.285612  ]\n",
            " [19.534332  ]\n",
            " [21.39241   ]\n",
            " [19.35589   ]\n",
            " [24.152672  ]\n",
            " [20.501043  ]\n",
            " [20.433558  ]\n",
            " [20.75776   ]\n",
            " [22.737022  ]\n",
            " [22.725273  ]\n",
            " [26.09705   ]\n",
            " [32.162716  ]\n",
            " [30.763618  ]\n",
            " [21.176231  ]\n",
            " [22.467323  ]\n",
            " [24.439774  ]\n",
            " [21.913864  ]\n",
            " [24.004875  ]\n",
            " [28.338795  ]\n",
            " [23.773674  ]\n",
            " [24.183949  ]\n",
            " [20.842237  ]\n",
            " [23.498432  ]\n",
            " [21.602264  ]\n",
            " [22.95918   ]\n",
            " [25.019829  ]\n",
            " [26.764053  ]\n",
            " [17.799328  ]\n",
            " [20.27263   ]\n",
            " [19.493685  ]\n",
            " [20.228895  ]\n",
            " [19.999733  ]\n",
            " [17.933237  ]\n",
            " [20.759329  ]\n",
            " [21.955744  ]\n",
            " [19.37877   ]\n",
            " [19.422003  ]\n",
            " [19.857552  ]\n",
            " [21.075409  ]\n",
            " [20.228859  ]\n",
            " [20.205603  ]\n",
            " [16.327515  ]\n",
            " [22.42202   ]\n",
            " [19.326118  ]\n",
            " [25.815857  ]\n",
            " [24.637959  ]\n",
            " [23.347927  ]\n",
            " [18.227978  ]\n",
            " [24.540398  ]\n",
            " [25.589106  ]]\n"
          ]
        }
      ],
      "source": [
        "pred = model.predict(x)\n",
        "print(\"Shape: {}\".format(pred.shape))\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXV416NaRbHu"
      },
      "source": [
        "We would like to see how good these predictions are.  We know what the correct MPG is for each car, so we can measure how close the neural network was."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IcEXD-wwRbHu",
        "outputId": "cb987b03-9891-4c49-eb85-d9426be12b32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final score (RMSE): 9.52828598022461\n"
          ]
        }
      ],
      "source": [
        "# Measure RMSE error.  RMSE is common for regression.\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
        "print(\"Final score (RMSE): {}\".format(score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIm7EhhTRbHu"
      },
      "source": [
        "We can also print out the first 10 cars, with predictions and actual MPG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6Xt0BiXWRbHv",
        "outputId": "84885482-9e84-4e6b-e3a4-0972599a1edf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Car name: chevrolet chevelle malibu, MPG: 18.0, predicted MPG: [17.451992]\n",
            "2. Car name: buick skylark 320, MPG: 15.0, predicted MPG: [13.535798]\n",
            "3. Car name: plymouth satellite, MPG: 18.0, predicted MPG: [13.57647]\n",
            "4. Car name: amc rebel sst, MPG: 16.0, predicted MPG: [14.402844]\n",
            "5. Car name: ford torino, MPG: 17.0, predicted MPG: [15.772935]\n",
            "6. Car name: ford galaxie 500, MPG: 15.0, predicted MPG: [13.904958]\n",
            "7. Car name: chevrolet impala, MPG: 14.0, predicted MPG: [10.090627]\n",
            "8. Car name: plymouth fury iii, MPG: 14.0, predicted MPG: [10.864251]\n",
            "9. Car name: pontiac catalina, MPG: 14.0, predicted MPG: [10.486577]\n",
            "10. Car name: amc ambassador dpl, MPG: 15.0, predicted MPG: [10.3378725]\n"
          ]
        }
      ],
      "source": [
        "# Sample predictions\n",
        "for i in range(10):\n",
        "    print(\"{}. Car name: {}, MPG: {}, predicted MPG: {}\".format(i+1,cars[i],y[i],pred[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_DNYSnBRbHv"
      },
      "source": [
        "# Example of TensorFlow Classification: Iris\n",
        "\n",
        "This is a very simple example of how to perform the Iris classification using TensorFlow. The iris.csv file is used.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jEJcv0YCRbHv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "df=pd.read_csv(\"data/iris.csv\",na_values=['NA','?'])\n",
        "\n",
        "species = encode_text_index(df,\"species\")\n",
        "\n",
        "x,y = to_xy(df,\"species\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "X6A6pIU4RbHw",
        "outputId": "ff9c3ae1-579e-4f5e-eddd-e65705d77ab1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]], dtype=float32)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "RkPBgt_1RbHw",
        "outputId": "0ba6c63d-dce5-44bb-e3a9-921bc82b24f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rUU2dZ2dRbHw",
        "outputId": "ebf1ff2f-a97d-4c5b-ae1f-6da79a801e61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y  #  This is one-hot encoding.  Only one value is 1.0 (hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzupSu4-RbHx",
        "outputId": "64c88411-c852-4a84-b833-85a0209a2bda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VosGucWWRbHx",
        "outputId": "8e37b565-658f-411d-f53d-4672cfabea84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5/5 - 0s - loss: 1.1790 - 106ms/epoch - 21ms/step\n",
            "Epoch 2/100\n",
            "5/5 - 0s - loss: 1.0825 - 3ms/epoch - 573us/step\n",
            "Epoch 3/100\n",
            "5/5 - 0s - loss: 1.0181 - 3ms/epoch - 561us/step\n",
            "Epoch 4/100\n",
            "5/5 - 0s - loss: 0.9641 - 3ms/epoch - 557us/step\n",
            "Epoch 5/100\n",
            "5/5 - 0s - loss: 0.9108 - 3ms/epoch - 555us/step\n",
            "Epoch 6/100\n",
            "5/5 - 0s - loss: 0.8621 - 3ms/epoch - 565us/step\n",
            "Epoch 7/100\n",
            "5/5 - 0s - loss: 0.8105 - 3ms/epoch - 524us/step\n",
            "Epoch 8/100\n",
            "5/5 - 0s - loss: 0.7613 - 3ms/epoch - 560us/step\n",
            "Epoch 9/100\n",
            "5/5 - 0s - loss: 0.7153 - 3ms/epoch - 580us/step\n",
            "Epoch 10/100\n",
            "5/5 - 0s - loss: 0.6726 - 3ms/epoch - 581us/step\n",
            "Epoch 11/100\n",
            "5/5 - 0s - loss: 0.6331 - 3ms/epoch - 552us/step\n",
            "Epoch 12/100\n",
            "5/5 - 0s - loss: 0.5973 - 4ms/epoch - 899us/step\n",
            "Epoch 13/100\n",
            "5/5 - 0s - loss: 0.5638 - 5ms/epoch - 913us/step\n",
            "Epoch 14/100\n",
            "5/5 - 0s - loss: 0.5335 - 5ms/epoch - 920us/step\n",
            "Epoch 15/100\n",
            "5/5 - 0s - loss: 0.5059 - 4ms/epoch - 815us/step\n",
            "Epoch 16/100\n",
            "5/5 - 0s - loss: 0.4801 - 4ms/epoch - 788us/step\n",
            "Epoch 17/100\n",
            "5/5 - 0s - loss: 0.4597 - 3ms/epoch - 575us/step\n",
            "Epoch 18/100\n",
            "5/5 - 0s - loss: 0.4382 - 3ms/epoch - 677us/step\n",
            "Epoch 19/100\n",
            "5/5 - 0s - loss: 0.4197 - 3ms/epoch - 590us/step\n",
            "Epoch 20/100\n",
            "5/5 - 0s - loss: 0.4034 - 2ms/epoch - 497us/step\n",
            "Epoch 21/100\n",
            "5/5 - 0s - loss: 0.3878 - 3ms/epoch - 510us/step\n",
            "Epoch 22/100\n",
            "5/5 - 0s - loss: 0.3729 - 3ms/epoch - 500us/step\n",
            "Epoch 23/100\n",
            "5/5 - 0s - loss: 0.3599 - 2ms/epoch - 483us/step\n",
            "Epoch 24/100\n",
            "5/5 - 0s - loss: 0.3483 - 2ms/epoch - 432us/step\n",
            "Epoch 25/100\n",
            "5/5 - 0s - loss: 0.3356 - 2ms/epoch - 475us/step\n",
            "Epoch 26/100\n",
            "5/5 - 0s - loss: 0.3242 - 2ms/epoch - 410us/step\n",
            "Epoch 27/100\n",
            "5/5 - 0s - loss: 0.3151 - 2ms/epoch - 494us/step\n",
            "Epoch 28/100\n",
            "5/5 - 0s - loss: 0.3032 - 3ms/epoch - 510us/step\n",
            "Epoch 29/100\n",
            "5/5 - 0s - loss: 0.2949 - 2ms/epoch - 480us/step\n",
            "Epoch 30/100\n",
            "5/5 - 0s - loss: 0.2852 - 2ms/epoch - 430us/step\n",
            "Epoch 31/100\n",
            "5/5 - 0s - loss: 0.2742 - 2ms/epoch - 486us/step\n",
            "Epoch 32/100\n",
            "5/5 - 0s - loss: 0.2655 - 3ms/epoch - 508us/step\n",
            "Epoch 33/100\n",
            "5/5 - 0s - loss: 0.2576 - 2ms/epoch - 484us/step\n",
            "Epoch 34/100\n",
            "5/5 - 0s - loss: 0.2484 - 2ms/epoch - 452us/step\n",
            "Epoch 35/100\n",
            "5/5 - 0s - loss: 0.2430 - 7ms/epoch - 1ms/step\n",
            "Epoch 36/100\n",
            "5/5 - 0s - loss: 0.2344 - 4ms/epoch - 829us/step\n",
            "Epoch 37/100\n",
            "5/5 - 0s - loss: 0.2276 - 4ms/epoch - 828us/step\n",
            "Epoch 38/100\n",
            "5/5 - 0s - loss: 0.2205 - 4ms/epoch - 807us/step\n",
            "Epoch 39/100\n",
            "5/5 - 0s - loss: 0.2161 - 4ms/epoch - 831us/step\n",
            "Epoch 40/100\n",
            "5/5 - 0s - loss: 0.2078 - 3ms/epoch - 664us/step\n",
            "Epoch 41/100\n",
            "5/5 - 0s - loss: 0.2023 - 3ms/epoch - 533us/step\n",
            "Epoch 42/100\n",
            "5/5 - 0s - loss: 0.1946 - 3ms/epoch - 549us/step\n",
            "Epoch 43/100\n",
            "5/5 - 0s - loss: 0.1924 - 4ms/epoch - 727us/step\n",
            "Epoch 44/100\n",
            "5/5 - 0s - loss: 0.1892 - 3ms/epoch - 569us/step\n",
            "Epoch 45/100\n",
            "5/5 - 0s - loss: 0.1819 - 3ms/epoch - 506us/step\n",
            "Epoch 46/100\n",
            "5/5 - 0s - loss: 0.1807 - 2ms/epoch - 458us/step\n",
            "Epoch 47/100\n",
            "5/5 - 0s - loss: 0.1705 - 2ms/epoch - 495us/step\n",
            "Epoch 48/100\n",
            "5/5 - 0s - loss: 0.1695 - 3ms/epoch - 503us/step\n",
            "Epoch 49/100\n",
            "5/5 - 0s - loss: 0.1624 - 2ms/epoch - 487us/step\n",
            "Epoch 50/100\n",
            "5/5 - 0s - loss: 0.1575 - 2ms/epoch - 475us/step\n",
            "Epoch 51/100\n",
            "5/5 - 0s - loss: 0.1541 - 2ms/epoch - 481us/step\n",
            "Epoch 52/100\n",
            "5/5 - 0s - loss: 0.1496 - 2ms/epoch - 469us/step\n",
            "Epoch 53/100\n",
            "5/5 - 0s - loss: 0.1468 - 2ms/epoch - 461us/step\n",
            "Epoch 54/100\n",
            "5/5 - 0s - loss: 0.1420 - 2ms/epoch - 472us/step\n",
            "Epoch 55/100\n",
            "5/5 - 0s - loss: 0.1393 - 2ms/epoch - 439us/step\n",
            "Epoch 56/100\n",
            "5/5 - 0s - loss: 0.1395 - 2ms/epoch - 435us/step\n",
            "Epoch 57/100\n",
            "5/5 - 0s - loss: 0.1346 - 2ms/epoch - 494us/step\n",
            "Epoch 58/100\n",
            "5/5 - 0s - loss: 0.1318 - 3ms/epoch - 521us/step\n",
            "Epoch 59/100\n",
            "5/5 - 0s - loss: 0.1282 - 2ms/epoch - 437us/step\n",
            "Epoch 60/100\n",
            "5/5 - 0s - loss: 0.1253 - 2ms/epoch - 474us/step\n",
            "Epoch 61/100\n",
            "5/5 - 0s - loss: 0.1231 - 2ms/epoch - 468us/step\n",
            "Epoch 62/100\n",
            "5/5 - 0s - loss: 0.1208 - 2ms/epoch - 447us/step\n",
            "Epoch 63/100\n",
            "5/5 - 0s - loss: 0.1200 - 2ms/epoch - 447us/step\n",
            "Epoch 64/100\n",
            "5/5 - 0s - loss: 0.1172 - 3ms/epoch - 512us/step\n",
            "Epoch 65/100\n",
            "5/5 - 0s - loss: 0.1154 - 3ms/epoch - 548us/step\n",
            "Epoch 66/100\n",
            "5/5 - 0s - loss: 0.1163 - 2ms/epoch - 467us/step\n",
            "Epoch 67/100\n",
            "5/5 - 0s - loss: 0.1116 - 2ms/epoch - 500us/step\n",
            "Epoch 68/100\n",
            "5/5 - 0s - loss: 0.1095 - 2ms/epoch - 451us/step\n",
            "Epoch 69/100\n",
            "5/5 - 0s - loss: 0.1080 - 2ms/epoch - 485us/step\n",
            "Epoch 70/100\n",
            "5/5 - 0s - loss: 0.1159 - 2ms/epoch - 472us/step\n",
            "Epoch 71/100\n",
            "5/5 - 0s - loss: 0.1103 - 2ms/epoch - 459us/step\n",
            "Epoch 72/100\n",
            "5/5 - 0s - loss: 0.1065 - 2ms/epoch - 455us/step\n",
            "Epoch 73/100\n",
            "5/5 - 0s - loss: 0.1019 - 3ms/epoch - 544us/step\n",
            "Epoch 74/100\n",
            "5/5 - 0s - loss: 0.1013 - 2ms/epoch - 464us/step\n",
            "Epoch 75/100\n",
            "5/5 - 0s - loss: 0.0991 - 2ms/epoch - 485us/step\n",
            "Epoch 76/100\n",
            "5/5 - 0s - loss: 0.0997 - 3ms/epoch - 513us/step\n",
            "Epoch 77/100\n",
            "5/5 - 0s - loss: 0.0994 - 2ms/epoch - 483us/step\n",
            "Epoch 78/100\n",
            "5/5 - 0s - loss: 0.0978 - 2ms/epoch - 441us/step\n",
            "Epoch 79/100\n",
            "5/5 - 0s - loss: 0.0956 - 2ms/epoch - 493us/step\n",
            "Epoch 80/100\n",
            "5/5 - 0s - loss: 0.0945 - 2ms/epoch - 447us/step\n",
            "Epoch 81/100\n",
            "5/5 - 0s - loss: 0.0925 - 2ms/epoch - 472us/step\n",
            "Epoch 82/100\n",
            "5/5 - 0s - loss: 0.0958 - 3ms/epoch - 512us/step\n",
            "Epoch 83/100\n",
            "5/5 - 0s - loss: 0.0936 - 2ms/epoch - 439us/step\n",
            "Epoch 84/100\n",
            "5/5 - 0s - loss: 0.0919 - 2ms/epoch - 470us/step\n",
            "Epoch 85/100\n",
            "5/5 - 0s - loss: 0.0913 - 2ms/epoch - 452us/step\n",
            "Epoch 86/100\n",
            "5/5 - 0s - loss: 0.0957 - 2ms/epoch - 482us/step\n",
            "Epoch 87/100\n",
            "5/5 - 0s - loss: 0.0898 - 2ms/epoch - 469us/step\n",
            "Epoch 88/100\n",
            "5/5 - 0s - loss: 0.0875 - 2ms/epoch - 463us/step\n",
            "Epoch 89/100\n",
            "5/5 - 0s - loss: 0.0926 - 3ms/epoch - 513us/step\n",
            "Epoch 90/100\n",
            "5/5 - 0s - loss: 0.0854 - 2ms/epoch - 474us/step\n",
            "Epoch 91/100\n",
            "5/5 - 0s - loss: 0.0866 - 2ms/epoch - 469us/step\n",
            "Epoch 92/100\n",
            "5/5 - 0s - loss: 0.0937 - 2ms/epoch - 460us/step\n",
            "Epoch 93/100\n",
            "5/5 - 0s - loss: 0.0905 - 2ms/epoch - 483us/step\n",
            "Epoch 94/100\n",
            "5/5 - 0s - loss: 0.0868 - 2ms/epoch - 421us/step\n",
            "Epoch 95/100\n",
            "5/5 - 0s - loss: 0.0855 - 2ms/epoch - 445us/step\n",
            "Epoch 96/100\n",
            "5/5 - 0s - loss: 0.0812 - 2ms/epoch - 475us/step\n",
            "Epoch 97/100\n",
            "5/5 - 0s - loss: 0.0825 - 2ms/epoch - 480us/step\n",
            "Epoch 98/100\n",
            "5/5 - 0s - loss: 0.0804 - 2ms/epoch - 454us/step\n",
            "Epoch 99/100\n",
            "5/5 - 0s - loss: 0.0793 - 2ms/epoch - 440us/step\n",
            "Epoch 100/100\n",
            "5/5 - 0s - loss: 0.0820 - 2ms/epoch - 466us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x29eda4c90>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
        "model.add(Dense(25, activation='relu')) # Hidden 2\n",
        "model.add(Dense(y.shape[1], activation='softmax')) # Output\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model.fit(x,y,verbose=2,epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAUdHKKxRbHx",
        "outputId": "e058907e-d662-4d07-a80f-58936ead9815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
          ]
        }
      ],
      "source": [
        "# Print out number of species found:\n",
        "print(species)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_OpnSADRbHy"
      },
      "source": [
        "Now that you have a neural network trained, we would like to be able to use it. There were 3 types of iris (Iris-setosa, Iris-versicolor, and Iris-virginica).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gVKEzSRORbHy",
        "outputId": "c1af99ef-fdaa-489e-b22e-e4f0d4504a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 542us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred = model.predict(x)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "dgRw2QDMRbHy",
        "outputId": "27fc346c-ba88-4e67-e72a-bcfa5f0971ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[9.99752223e-01, 2.45776406e-04, 2.06477307e-06],\n",
              "       [9.99107659e-01, 8.83875997e-04, 8.42896134e-06],\n",
              "       [9.99528885e-01, 4.65611549e-04, 5.46667252e-06],\n",
              "       [9.98897433e-01, 1.08987442e-03, 1.26328287e-05],\n",
              "       [9.99782622e-01, 2.15413282e-04, 1.97183658e-06],\n",
              "       [9.99716341e-01, 2.81829271e-04, 1.82094220e-06],\n",
              "       [9.99483109e-01, 5.10361162e-04, 6.57344617e-06],\n",
              "       [9.99588668e-01, 4.07720887e-04, 3.57397084e-06],\n",
              "       [9.98504162e-01, 1.47527549e-03, 2.05562865e-05],\n",
              "       [9.99225736e-01, 7.67329533e-04, 6.87961574e-06],\n",
              "       [9.99828458e-01, 1.70414074e-04, 1.10387668e-06],\n",
              "       [9.99370754e-01, 6.23250904e-04, 6.09135941e-06],\n",
              "       [9.99221087e-01, 7.71147315e-04, 7.73756528e-06],\n",
              "       [9.99503016e-01, 4.88860300e-04, 8.05330092e-06],\n",
              "       [9.99964356e-01, 3.53556024e-05, 1.86415051e-07],\n",
              "       [9.99949098e-01, 5.07022633e-05, 2.90952073e-07],\n",
              "       [9.99902368e-01, 9.69522152e-05, 7.24522579e-07],\n",
              "       [9.99710739e-01, 2.86728406e-04, 2.49149093e-06],\n",
              "       [9.99766052e-01, 2.32724720e-04, 1.14208535e-06],\n",
              "       [9.99794424e-01, 2.03771779e-04, 1.75017283e-06],\n",
              "       [9.99352634e-01, 6.43701002e-04, 3.72852628e-06],\n",
              "       [9.99692798e-01, 3.04587535e-04, 2.66818961e-06],\n",
              "       [9.99876976e-01, 1.21174249e-04, 1.73066803e-06],\n",
              "       [9.98067200e-01, 1.91809156e-03, 1.47949313e-05],\n",
              "       [9.98266280e-01, 1.71932706e-03, 1.43911839e-05],\n",
              "       [9.98334944e-01, 1.65204785e-03, 1.31263241e-05],\n",
              "       [9.99124587e-01, 8.67899216e-04, 7.55153496e-06],\n",
              "       [9.99703586e-01, 2.94087949e-04, 2.21202436e-06],\n",
              "       [9.99707878e-01, 2.89859658e-04, 2.24344899e-06],\n",
              "       [9.98879969e-01, 1.10855489e-03, 1.14180966e-05],\n",
              "       [9.98600662e-01, 1.38627086e-03, 1.30415756e-05],\n",
              "       [9.99492645e-01, 5.03986084e-04, 3.37130609e-06],\n",
              "       [9.99916553e-01, 8.28054326e-05, 6.18824572e-07],\n",
              "       [9.99951839e-01, 4.77433750e-05, 3.03916124e-07],\n",
              "       [9.99047935e-01, 9.43355728e-04, 8.64525828e-06],\n",
              "       [9.99683380e-01, 3.13646917e-04, 3.00644501e-06],\n",
              "       [9.99842167e-01, 1.56857714e-04, 9.94775519e-07],\n",
              "       [9.99798477e-01, 1.99584829e-04, 1.91555023e-06],\n",
              "       [9.99139667e-01, 8.47819669e-04, 1.25004753e-05],\n",
              "       [9.99610603e-01, 3.86322354e-04, 3.13120199e-06],\n",
              "       [9.99757111e-01, 2.40499183e-04, 2.33510059e-06],\n",
              "       [9.93587971e-01, 6.33067451e-03, 8.14132291e-05],\n",
              "       [9.99419212e-01, 5.72256395e-04, 8.54284917e-06],\n",
              "       [9.98858094e-01, 1.13141129e-03, 1.05161052e-05],\n",
              "       [9.99092698e-01, 9.00683983e-04, 6.64364370e-06],\n",
              "       [9.98838484e-01, 1.14941760e-03, 1.20921532e-05],\n",
              "       [9.99781311e-01, 2.16879023e-04, 1.74000468e-06],\n",
              "       [9.99371231e-01, 6.21170213e-04, 7.63826120e-06],\n",
              "       [9.99818861e-01, 1.79855691e-04, 1.25998520e-06],\n",
              "       [9.99594629e-01, 4.01859870e-04, 3.62474589e-06],\n",
              "       [5.96844999e-04, 9.95663345e-01, 3.73980636e-03],\n",
              "       [1.01718330e-03, 9.89118695e-01, 9.86410864e-03],\n",
              "       [5.00010094e-04, 9.79007840e-01, 2.04921663e-02],\n",
              "       [1.92903890e-03, 9.04678345e-01, 9.33926851e-02],\n",
              "       [7.33271765e-04, 9.55539346e-01, 4.37274650e-02],\n",
              "       [1.67276966e-03, 8.94405603e-01, 1.03921600e-01],\n",
              "       [1.14799989e-03, 9.58345950e-01, 4.05059904e-02],\n",
              "       [8.54535867e-03, 9.81548369e-01, 9.90631245e-03],\n",
              "       [6.58147386e-04, 9.90763724e-01, 8.57822131e-03],\n",
              "       [3.48134642e-03, 9.32166338e-01, 6.43522218e-02],\n",
              "       [3.29134194e-03, 9.72272873e-01, 2.44357977e-02],\n",
              "       [1.76650111e-03, 9.77587759e-01, 2.06458196e-02],\n",
              "       [1.16729690e-03, 9.90382135e-01, 8.45052209e-03],\n",
              "       [1.09313789e-03, 9.02085721e-01, 9.68211666e-02],\n",
              "       [6.11762516e-03, 9.87946451e-01, 5.93594043e-03],\n",
              "       [9.99688054e-04, 9.95050728e-01, 3.94957280e-03],\n",
              "       [1.98206329e-03, 8.15542936e-01, 1.82474986e-01],\n",
              "       [2.19907635e-03, 9.91019547e-01, 6.78144675e-03],\n",
              "       [5.73412166e-04, 6.52786195e-01, 3.46640378e-01],\n",
              "       [2.20726174e-03, 9.87105727e-01, 1.06869480e-02],\n",
              "       [1.01421517e-03, 5.25104940e-01, 4.73880887e-01],\n",
              "       [1.88030407e-03, 9.92186308e-01, 5.93343843e-03],\n",
              "       [4.11689456e-04, 5.04540741e-01, 4.95047629e-01],\n",
              "       [1.03361218e-03, 9.47796464e-01, 5.11700027e-02],\n",
              "       [1.12311856e-03, 9.93255973e-01, 5.62091032e-03],\n",
              "       [8.86021706e-04, 9.93757129e-01, 5.35685942e-03],\n",
              "       [4.88817052e-04, 9.71495390e-01, 2.80158184e-02],\n",
              "       [5.23681520e-04, 8.04096103e-01, 1.95380256e-01],\n",
              "       [1.33597490e-03, 9.14025187e-01, 8.46387818e-02],\n",
              "       [8.29793233e-03, 9.87588465e-01, 4.11359593e-03],\n",
              "       [2.36618402e-03, 9.85652089e-01, 1.19816819e-02],\n",
              "       [3.28442897e-03, 9.88797128e-01, 7.91846029e-03],\n",
              "       [2.45813653e-03, 9.90247011e-01, 7.29497615e-03],\n",
              "       [1.93357089e-04, 1.54697940e-01, 8.45108688e-01],\n",
              "       [2.17235112e-03, 7.06907928e-01, 2.90919721e-01],\n",
              "       [1.78369693e-03, 9.70354259e-01, 2.78620552e-02],\n",
              "       [6.60030171e-04, 9.84881938e-01, 1.44580062e-02],\n",
              "       [7.28819985e-04, 9.40898836e-01, 5.83722964e-02],\n",
              "       [2.46623741e-03, 9.85619545e-01, 1.19141741e-02],\n",
              "       [2.18614261e-03, 9.47896600e-01, 4.99172248e-02],\n",
              "       [1.86202570e-03, 8.64145100e-01, 1.33992970e-01],\n",
              "       [1.22430315e-03, 9.53634322e-01, 4.51413617e-02],\n",
              "       [1.74211385e-03, 9.88068163e-01, 1.01896916e-02],\n",
              "       [7.06088776e-03, 9.83391166e-01, 9.54794791e-03],\n",
              "       [2.02802778e-03, 9.48689997e-01, 4.92820852e-02],\n",
              "       [2.25540204e-03, 9.87996280e-01, 9.74832755e-03],\n",
              "       [2.01276154e-03, 9.78861034e-01, 1.91262495e-02],\n",
              "       [1.19544461e-03, 9.91082072e-01, 7.72252306e-03],\n",
              "       [2.63171606e-02, 9.66174006e-01, 7.50881759e-03],\n",
              "       [1.97672471e-03, 9.81443763e-01, 1.65795702e-02],\n",
              "       [1.22846438e-06, 8.66895076e-04, 9.99131858e-01],\n",
              "       [3.66192653e-05, 2.09803525e-02, 9.78983045e-01],\n",
              "       [9.02103693e-06, 2.29190663e-02, 9.77071941e-01],\n",
              "       [2.59847984e-05, 2.80604642e-02, 9.71913517e-01],\n",
              "       [3.26839086e-06, 3.78954341e-03, 9.96207118e-01],\n",
              "       [8.52418623e-07, 4.09987709e-03, 9.95899260e-01],\n",
              "       [1.65678066e-04, 3.41492034e-02, 9.65685070e-01],\n",
              "       [5.23658264e-06, 2.05776673e-02, 9.79417145e-01],\n",
              "       [5.40561268e-06, 1.05331484e-02, 9.89461482e-01],\n",
              "       [5.67956886e-06, 1.16569316e-02, 9.88337338e-01],\n",
              "       [3.55596974e-04, 3.68257910e-01, 6.31386459e-01],\n",
              "       [4.02555597e-05, 4.83850762e-02, 9.51574624e-01],\n",
              "       [3.66103304e-05, 6.07462004e-02, 9.39217210e-01],\n",
              "       [1.59538449e-05, 8.12376849e-03, 9.91860330e-01],\n",
              "       [6.51877644e-06, 2.95439526e-03, 9.97039080e-01],\n",
              "       [3.94110357e-05, 3.41058969e-02, 9.65854645e-01],\n",
              "       [8.33769736e-05, 1.07458085e-01, 8.92458558e-01],\n",
              "       [6.31379180e-06, 2.65842397e-02, 9.73409474e-01],\n",
              "       [7.76869342e-08, 4.08044492e-04, 9.99591887e-01],\n",
              "       [8.52218291e-05, 8.41746852e-02, 9.15740132e-01],\n",
              "       [1.37353572e-05, 2.30130013e-02, 9.76973236e-01],\n",
              "       [6.15538665e-05, 2.50012502e-02, 9.74937141e-01],\n",
              "       [6.01922238e-07, 3.51070892e-03, 9.96488690e-01],\n",
              "       [2.93111807e-04, 3.00722480e-01, 6.98984444e-01],\n",
              "       [3.49196926e-05, 4.75357324e-02, 9.52429354e-01],\n",
              "       [5.10481732e-05, 1.51693657e-01, 8.48255336e-01],\n",
              "       [4.85554716e-04, 4.18159246e-01, 5.81355214e-01],\n",
              "       [5.41749410e-04, 3.90775710e-01, 6.08682513e-01],\n",
              "       [5.50657114e-06, 6.14662562e-03, 9.93847907e-01],\n",
              "       [1.20782162e-04, 3.99686903e-01, 6.00192308e-01],\n",
              "       [7.08818061e-06, 3.07065248e-02, 9.69286442e-01],\n",
              "       [6.92383037e-05, 3.72557938e-01, 6.27372801e-01],\n",
              "       [3.77224114e-06, 3.98763176e-03, 9.96008635e-01],\n",
              "       [4.56290058e-04, 5.15883505e-01, 4.83660251e-01],\n",
              "       [3.86869433e-05, 4.24273312e-02, 9.57534015e-01],\n",
              "       [3.92954735e-06, 1.96026880e-02, 9.80393410e-01],\n",
              "       [1.07134028e-05, 7.73691619e-03, 9.92252409e-01],\n",
              "       [1.00311699e-04, 1.10550456e-01, 8.89349222e-01],\n",
              "       [6.88651460e-04, 4.33645606e-01, 5.65665722e-01],\n",
              "       [9.41903927e-05, 1.65878579e-01, 8.34027171e-01],\n",
              "       [6.72434180e-06, 8.80039111e-03, 9.91192877e-01],\n",
              "       [1.49297746e-04, 2.32784465e-01, 7.67066240e-01],\n",
              "       [3.66192653e-05, 2.09803525e-02, 9.78983045e-01],\n",
              "       [4.25488406e-06, 6.57905173e-03, 9.93416667e-01],\n",
              "       [5.36749258e-06, 6.40062615e-03, 9.93593991e-01],\n",
              "       [5.19188507e-05, 6.78278580e-02, 9.32120144e-01],\n",
              "       [6.86894709e-05, 7.51213282e-02, 9.24809933e-01],\n",
              "       [1.36001443e-04, 1.55186206e-01, 8.44677746e-01],\n",
              "       [3.52327443e-05, 2.27108765e-02, 9.77253914e-01],\n",
              "       [1.98371432e-04, 1.17435731e-01, 8.82365823e-01]], dtype=float32)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pVFVnoIJRbHy",
        "outputId": "1a95108f-0637-48ab-b2d2-e0c79437d52d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "# print y.\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcTE1KhARbHz"
      },
      "source": [
        "#### The column (pred) with the highest probability is  the prediction of the neural network.  \n",
        "\n",
        "#### Use argmax function to find the index of the maximum prediction for each row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "NcpkLMSCRbHz",
        "outputId": "d072577d-cadb-47fc-a87f-b0b6a7786087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "True: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ]
        }
      ],
      "source": [
        "# Usually the column (pred) with the highest prediction is considered to be the prediction of the neural network.  It is easy\n",
        "# to convert the predictions to the expected iris species.  The argmax function finds the index of the maximum prediction\n",
        "# for each row.\n",
        "\n",
        "predict_classes = np.argmax(pred,axis=1)\n",
        "\n",
        "true_classes = np.argmax(y,axis=1)\n",
        "\n",
        "print(\"Predictions: {}\".format(predict_classes))\n",
        "print(\"True: {}\".format(true_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "mmuzgbyeRbHz",
        "outputId": "bcff9af9-3ac2-40e1-bddb-c5b326eb2e97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
            " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa']\n"
          ]
        }
      ],
      "source": [
        "# Of course it is very easy to turn these indexes back into iris species.  We just use the species list that we created earlier.\n",
        "print(species[predict_classes[0:10]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6Vg-NCOVRbH0",
        "outputId": "db4d263e-0b1c-4390-ebe6-93ab8e02c89a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9866666666666667\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#For all of the iris predictions, what percent were correct?\n",
        "\n",
        "correct = metrics.accuracy_score(true_classes, predict_classes)\n",
        "print(\"Accuracy: {}\".format(correct))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YIaXdavRbIL"
      },
      "source": [
        "The code below performs two ad hoc predictions.  \n",
        "\n",
        "*** Remember x should be a 2D array! ***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-dEfKwMqRbIM",
        "outputId": "87154f53-79f8-4e81-e019-92a79a2322d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 12ms/step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.0024256  0.38138175 0.6161927 ]]\n"
          ]
        }
      ],
      "source": [
        "# ad hoc prediction\n",
        "sample_flower = np.array( [[5.0,3.0,4.0,2.0]], dtype=float)\n",
        "pred = model.predict(sample_flower)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "eb69OLkBRbIM",
        "outputId": "6418e70c-271c-4c3f-af16-b48f57e55d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predict that [[5. 3. 4. 2.]] is: ['Iris-virginica']\n"
          ]
        }
      ],
      "source": [
        "pred = np.argmax(pred, axis=1)\n",
        "print(\"Predict that {} is: {}\".format(sample_flower,species[pred]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUdPfFe4RbIN"
      },
      "source": [
        "Notice that the argmax in the second prediction requires **axis=1**?  Since we have a 2D array now, we must specify which axis to take the argmax over.  The value **axis=1** specifies we want the max column index for each row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ngdl9MqBRbIO",
        "outputId": "c2f15c13-ee21-406d-88af-f9c993664ddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 12ms/step\n",
            "[[2.4255989e-03 3.8138175e-01 6.1619270e-01]\n",
            " [9.9882799e-01 1.1619200e-03 1.0162803e-05]]\n"
          ]
        }
      ],
      "source": [
        "# predict two sample flowers\n",
        "sample_flower = np.array( [[5.0,3.0,4.0,2.0],[5.2,3.5,1.5,0.8]], dtype=float)\n",
        "pred = model.predict(sample_flower)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "wMiFLHTmRbIO",
        "outputId": "8deeefa3-dbcc-4401-c8b5-22e736b22cf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predict that [[5.  3.  4.  2. ]\n",
            " [5.2 3.5 1.5 0.8]] is: ['Iris-virginica' 'Iris-setosa']\n"
          ]
        }
      ],
      "source": [
        "pred = np.argmax(pred, axis=1)\n",
        "print(\"Predict that {} is: {}\".format(sample_flower,species[pred]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "3JHSzlrbRbIP"
      },
      "source": [
        "# Load/Save Trained Network\n",
        "\n",
        "Complex neural networks will take a long time to fit/train.  It is helpful to be able to save these neural networks so that they can be reloaded later.  A reloaded neural network will not require retraining.  Keras provides three formats for neural network saving.\n",
        "\n",
        "* **YAML** - Stores the neural network structure (no weights) in the [YAML file format](https://en.wikipedia.org/wiki/YAML).\n",
        "* **JSON** - Stores the neural network structure (no weights) in the [JSON file format](https://en.wikipedia.org/wiki/JSON).\n",
        "* **HDF5** - Stores the complete neural network (with weights) in the [HDF5 file format](https://en.wikipedia.org/wiki/Hierarchical_Data_Format).\n",
        "\n",
        "Usually you will want to save in HDF5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "nXArrw2ZRbIP",
        "outputId": "03d5a245-636a-4fe1-8753-2f06fb1bc746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 0s 303us/step\n",
            "Before save score (RMSE): 5.135066032409668\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "path = \"./data/\"\n",
        "save_path = \"./dnn/\"\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "\n",
        "cars = df['name']\n",
        "df.drop('name',axis=1,inplace=True)\n",
        "missing_median(df, 'horsepower')\n",
        "x,y = to_xy(df,\"mpg\")\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
        "model.add(Dense(25, activation='relu')) # Hidden 2\n",
        "model.add(Dense(1)) # Output\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(x,y,verbose=0,epochs=100)\n",
        "\n",
        "# Predict\n",
        "pred = model.predict(x)\n",
        "\n",
        "# Measure RMSE error.  RMSE is common for regression.\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
        "print(\"Before save score (RMSE): {}\".format(score))\n",
        "\n",
        "\n",
        "# save entire network to HDF5 (save everything)\n",
        "model.save(os.path.join(save_path,\"network.hdf5\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZCkU9C8RbIQ"
      },
      "source": [
        "Now we reload the network and perform another prediction.  The RMSE should match the previous one exactly if the neural network was really saved and reloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "t00yWN_5RbIQ",
        "outputId": "4b9fcf9a-89c6-4814-f327-4c7b3788ce7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 0s 343us/step\n",
            "After load score (RMSE): 5.135066032409668\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model2 = load_model(os.path.join(save_path,\"network.hdf5\"))\n",
        "pred = model2.predict(x)\n",
        "# Measure RMSE error.  RMSE is common for regression.\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
        "print(\"After load score (RMSE): {}\".format(score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EricpGl9RbIR"
      },
      "source": [
        "### References:\n",
        "\n",
        "* [Google Colab](https://colab.research.google.com/) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow with free GPU support.  No setup needed.\n",
        "* [IBM Cognitive Class Labs](https://www.datascientistworkbench.com) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow.  No setup needed.\n",
        "* [Python Anaconda](https://www.continuum.io/downloads) - Python distribution that includes many data science packages, such as Numpy, Scipy, Scikit-Learn, Pandas, and much more.\n",
        "* [TensorFlow](https://www.tensorflow.org/) - Google's mathematics package for deep learning.\n",
        "* [Kaggle](https://www.kaggle.com/) - Competitive data science.  Good source of sample data.\n",
        "* T81-558: Applications of Deep Neural Networks. Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "cea39816bfa6bd3c0a1f6664bad4835e3a909c2e2cb41a9f2c8a2752fd725301"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
