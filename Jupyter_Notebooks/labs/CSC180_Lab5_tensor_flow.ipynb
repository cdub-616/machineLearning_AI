{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ksna70NzRbHh"
      },
      "source": [
        "## Lab 5: Tensorflow Introduction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxStzmR3RbHd"
      },
      "source": [
        "#### CSC 180 Intelligent Systems\n",
        "\n",
        "#### California State University, Sacramento\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGXHHC1CRbHi"
      },
      "source": [
        "# Helpful Functions for Tensorflow (little gems)\n",
        "\n",
        "The following functions will be used with TensorFlow to help preprocess the data.  They allow you to build the feature vector for a neural network.\n",
        "\n",
        "* Predictors/Inputs\n",
        "    * Fill any missing inputs with the median for that column.  Use **missing_median**.\n",
        "    * Encode textual/categorical values with **encode_text_dummy**.\n",
        "    * Encode numeric values with **encode_numeric_zscore**.\n",
        "* Output\n",
        "    * Discard rows with missing outputs.\n",
        "    * Encode textual/categorical values with **encode_text_index**.\n",
        "    * Do not encode output numeric values.\n",
        "* Produce final feature vectors (x) and expected output (y) with **to_xy**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-daOZ9RWRbHk"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Sequence\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
        "def encode_text_dummy(df, name):\n",
        "    dummies = pd.get_dummies(df[name])\n",
        "    for x in dummies.columns:\n",
        "        dummy_name = \"{}-{}\".format(name, x)\n",
        "        df[dummy_name] = dummies[x]\n",
        "    df.drop(name, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
        "def encode_text_index(df, name):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    df[name] = le.fit_transform(df[name])\n",
        "    return le.classes_\n",
        "\n",
        "\n",
        "# Encode a numeric column as zscores\n",
        "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
        "    if mean is None:\n",
        "        mean = df[name].mean()\n",
        "\n",
        "    if sd is None:\n",
        "        sd = df[name].std()\n",
        "\n",
        "    df[name] = (df[name] - mean) / sd\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the median\n",
        "def missing_median(df, name):\n",
        "    med = df[name].median()\n",
        "    df[name] = df[name].fillna(med)\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the default\n",
        "def missing_default(df, name, default_value):\n",
        "    df[name] = df[name].fillna(default_value)\n",
        "\n",
        "\n",
        "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
        "def to_xy(df, target):\n",
        "    result = []\n",
        "    for x in df.columns:\n",
        "        if x != target:\n",
        "            result.append(x)\n",
        "    # find out the type of the target column.\n",
        "    target_type = df[target].dtypes\n",
        "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
        "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
        "    if target_type in (np.int64, np.int32):\n",
        "        # Classification\n",
        "        dummies = pd.get_dummies(df[target])\n",
        "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
        "    else:\n",
        "        # Regression\n",
        "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
        "\n",
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "\n",
        "# Regression chart.\n",
        "def chart_regression(pred,y,sort=True):\n",
        "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
        "    if sort:\n",
        "        t.sort_values(by=['y'],inplace=True)\n",
        "    a = plt.plot(t['y'].tolist(),label='expected')\n",
        "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
        "    plt.ylabel('output')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Remove all rows where the specified column is +/- sd standard deviations\n",
        "def remove_outliers(df, name, sd):\n",
        "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
        "    df.drop(drop_rows, axis=0, inplace=True)\n",
        "\n",
        "\n",
        "# Encode a column to a range between normalized_low and normalized_high.\n",
        "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
        "                         data_low=None, data_high=None):\n",
        "    if data_low is None:\n",
        "        data_low = min(df[name])\n",
        "        data_high = max(df[name])\n",
        "\n",
        "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
        "               * (normalized_high - normalized_low) + normalized_low\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj0LiOULRbHm"
      },
      "source": [
        "# Classification or Regression\n",
        "\n",
        "Neural networks can function in *** classification or regression***:\n",
        "\n",
        "* **Regression** - You expect a number as your neural network's prediction.\n",
        "* **Classification** - You expect a class/category as your neural network's prediction.\n",
        "\n",
        "Regression networks always have a single output neuron.  Classification neural networks have an output neuron for each class.\n",
        "\n",
        "These neurons are grouped into layers:\n",
        "\n",
        "* **Input Layer** - The input layer accepts feature vectors from the dataset.  Input layers usually have a bias neuron.\n",
        "* **Output Layer** - The output from the neural network.  The output layer does not have a bias neuron.\n",
        "* **Hidden Layers** - Layers that occur between the input and output layers.  Each hidden layer will usually have a bias neuron.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AihrYLwERbHm"
      },
      "source": [
        "# What version of TensorFlow do you have?\n",
        "\n",
        "TensorFlow is very new and changing rapidly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WqEBeNJBRbHn",
        "outputId": "8d2dfeb9-bc38-441c-b589-ad5ca5640554"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "Tensor Flow Version: 2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensor Flow Version: {}\".format(tf.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_L_-phiRbHo"
      },
      "source": [
        "# Why TensorFlow\n",
        "\n",
        "* Supported by Google\n",
        "* Works well on Linux/Mac\n",
        "* Excellent GPU support\n",
        "* Most popular today"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_JqloZERbHp"
      },
      "source": [
        "# Example of TensorFlow Regression: MPG Prediction\n",
        "\n",
        "This example shows how to encode the MPG dataset for regression.  Notice that:\n",
        "\n",
        "* Input has both numeric and categorical\n",
        "* Input has missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YvyXVPPqRbHp",
        "outputId": "c5f40255-5986-4b3f-f7bf-da21198bdf3e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>year</th>\n",
              "      <th>origin</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>307.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>3504</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>chevrolet chevelle malibu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>3693</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>buick skylark 320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>318.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3436</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>plymouth satellite</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0</td>\n",
              "      <td>8</td>\n",
              "      <td>304.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3433</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>amc rebel sst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>3449</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>ford torino</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
              "0  18.0          8         307.0       130.0    3504          12.0    70   \n",
              "1  15.0          8         350.0       165.0    3693          11.5    70   \n",
              "2  18.0          8         318.0       150.0    3436          11.0    70   \n",
              "3  16.0          8         304.0       150.0    3433          12.0    70   \n",
              "4  17.0          8         302.0       140.0    3449          10.5    70   \n",
              "\n",
              "   origin                       name  \n",
              "0       1  chevrolet chevelle malibu  \n",
              "1       1          buick skylark 320  \n",
              "2       1         plymouth satellite  \n",
              "3       1              amc rebel sst  \n",
              "4       1                ford torino  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "path = \"./data/\"\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "\n",
        "df[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4jcKgegnRbHp"
      },
      "outputs": [],
      "source": [
        "cars = df['name']\n",
        "\n",
        "df.drop('name',axis=1,inplace=True)\n",
        "\n",
        "missing_median(df, 'horsepower')\n",
        "\n",
        "encode_text_dummy(df, 'origin')\n",
        "\n",
        "x,y = to_xy(df,\"mpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XJ1IocJmRbHq",
        "outputId": "5e24b888-aed3-4c3b-b4d8-8b8020a43042"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(398, 9)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4N85aX57RbHq",
        "outputId": "387c7125-853f-418c-f16d-54953ecca93c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(398,)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WPS3uv9wRbHr",
        "outputId": "2c2e8080-411a-43da-ad71-112e313352a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  8., 307., 130., ...,   1.,   0.,   0.],\n",
              "       [  8., 350., 165., ...,   1.,   0.,   0.],\n",
              "       [  8., 318., 150., ...,   1.,   0.,   0.],\n",
              "       ...,\n",
              "       [  4., 135.,  84., ...,   1.,   0.,   0.],\n",
              "       [  4., 120.,  79., ...,   1.,   0.,   0.],\n",
              "       [  4., 119.,  82., ...,   1.,   0.,   0.]], dtype=float32)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rN3a746zRbHr",
        "outputId": "a3c42e1c-3b74-4285-b348-cdf2e8f99bed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([18. , 15. , 18. , 16. , 17. , 15. , 14. , 14. , 14. , 15. , 15. ,\n",
              "       14. , 15. , 14. , 24. , 22. , 18. , 21. , 27. , 26. , 25. , 24. ,\n",
              "       25. , 26. , 21. , 10. , 10. , 11. ,  9. , 27. , 28. , 25. , 25. ,\n",
              "       19. , 16. , 17. , 19. , 18. , 14. , 14. , 14. , 14. , 12. , 13. ,\n",
              "       13. , 18. , 22. , 19. , 18. , 23. , 28. , 30. , 30. , 31. , 35. ,\n",
              "       27. , 26. , 24. , 25. , 23. , 20. , 21. , 13. , 14. , 15. , 14. ,\n",
              "       17. , 11. , 13. , 12. , 13. , 19. , 15. , 13. , 13. , 14. , 18. ,\n",
              "       22. , 21. , 26. , 22. , 28. , 23. , 28. , 27. , 13. , 14. , 13. ,\n",
              "       14. , 15. , 12. , 13. , 13. , 14. , 13. , 12. , 13. , 18. , 16. ,\n",
              "       18. , 18. , 23. , 26. , 11. , 12. , 13. , 12. , 18. , 20. , 21. ,\n",
              "       22. , 18. , 19. , 21. , 26. , 15. , 16. , 29. , 24. , 20. , 19. ,\n",
              "       15. , 24. , 20. , 11. , 20. , 21. , 19. , 15. , 31. , 26. , 32. ,\n",
              "       25. , 16. , 16. , 18. , 16. , 13. , 14. , 14. , 14. , 29. , 26. ,\n",
              "       26. , 31. , 32. , 28. , 24. , 26. , 24. , 26. , 31. , 19. , 18. ,\n",
              "       15. , 15. , 16. , 15. , 16. , 14. , 17. , 16. , 15. , 18. , 21. ,\n",
              "       20. , 13. , 29. , 23. , 20. , 23. , 24. , 25. , 24. , 18. , 29. ,\n",
              "       19. , 23. , 23. , 22. , 25. , 33. , 28. , 25. , 25. , 26. , 27. ,\n",
              "       17.5, 16. , 15.5, 14.5, 22. , 22. , 24. , 22.5, 29. , 24.5, 29. ,\n",
              "       33. , 20. , 18. , 18.5, 17.5, 29.5, 32. , 28. , 26.5, 20. , 13. ,\n",
              "       19. , 19. , 16.5, 16.5, 13. , 13. , 13. , 31.5, 30. , 36. , 25.5,\n",
              "       33.5, 17.5, 17. , 15.5, 15. , 17.5, 20.5, 19. , 18.5, 16. , 15.5,\n",
              "       15.5, 16. , 29. , 24.5, 26. , 25.5, 30.5, 33.5, 30. , 30.5, 22. ,\n",
              "       21.5, 21.5, 43.1, 36.1, 32.8, 39.4, 36.1, 19.9, 19.4, 20.2, 19.2,\n",
              "       20.5, 20.2, 25.1, 20.5, 19.4, 20.6, 20.8, 18.6, 18.1, 19.2, 17.7,\n",
              "       18.1, 17.5, 30. , 27.5, 27.2, 30.9, 21.1, 23.2, 23.8, 23.9, 20.3,\n",
              "       17. , 21.6, 16.2, 31.5, 29.5, 21.5, 19.8, 22.3, 20.2, 20.6, 17. ,\n",
              "       17.6, 16.5, 18.2, 16.9, 15.5, 19.2, 18.5, 31.9, 34.1, 35.7, 27.4,\n",
              "       25.4, 23. , 27.2, 23.9, 34.2, 34.5, 31.8, 37.3, 28.4, 28.8, 26.8,\n",
              "       33.5, 41.5, 38.1, 32.1, 37.2, 28. , 26.4, 24.3, 19.1, 34.3, 29.8,\n",
              "       31.3, 37. , 32.2, 46.6, 27.9, 40.8, 44.3, 43.4, 36.4, 30. , 44.6,\n",
              "       40.9, 33.8, 29.8, 32.7, 23.7, 35. , 23.6, 32.4, 27.2, 26.6, 25.8,\n",
              "       23.5, 30. , 39.1, 39. , 35.1, 32.3, 37. , 37.7, 34.1, 34.7, 34.4,\n",
              "       29.9, 33. , 34.5, 33.7, 32.4, 32.9, 31.6, 28.1, 30.7, 25.4, 24.2,\n",
              "       22.4, 26.6, 20.2, 17.6, 28. , 27. , 34. , 31. , 29. , 27. , 24. ,\n",
              "       23. , 36. , 37. , 31. , 38. , 36. , 36. , 36. , 34. , 38. , 32. ,\n",
              "       38. , 25. , 38. , 26. , 22. , 32. , 36. , 27. , 27. , 44. , 32. ,\n",
              "       28. , 31. ], dtype=float32)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TwsF2z7HRbHs",
        "outputId": "e0fa2ca2-a300-4604-e974-c959c83ed482"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "13/13 - 1s - loss: 264451.1250 - 511ms/epoch - 39ms/step\n",
            "Epoch 2/100\n",
            "13/13 - 0s - loss: 83104.7422 - 12ms/epoch - 930us/step\n",
            "Epoch 3/100\n",
            "13/13 - 0s - loss: 11965.4521 - 11ms/epoch - 846us/step\n",
            "Epoch 4/100\n",
            "13/13 - 0s - loss: 822.3130 - 12ms/epoch - 923us/step\n",
            "Epoch 5/100\n",
            "13/13 - 0s - loss: 1535.4890 - 10ms/epoch - 769us/step\n",
            "Epoch 6/100\n",
            "13/13 - 0s - loss: 810.8687 - 11ms/epoch - 846us/step\n",
            "Epoch 7/100\n",
            "13/13 - 0s - loss: 528.9394 - 11ms/epoch - 846us/step\n",
            "Epoch 8/100\n",
            "13/13 - 0s - loss: 548.6523 - 10ms/epoch - 769us/step\n",
            "Epoch 9/100\n",
            "13/13 - 0s - loss: 523.7934 - 10ms/epoch - 770us/step\n",
            "Epoch 10/100\n",
            "13/13 - 0s - loss: 520.5030 - 10ms/epoch - 801us/step\n",
            "Epoch 11/100\n",
            "13/13 - 0s - loss: 515.5961 - 10ms/epoch - 769us/step\n",
            "Epoch 12/100\n",
            "13/13 - 0s - loss: 510.8153 - 11ms/epoch - 846us/step\n",
            "Epoch 13/100\n",
            "13/13 - 0s - loss: 506.0955 - 10ms/epoch - 769us/step\n",
            "Epoch 14/100\n",
            "13/13 - 0s - loss: 501.0658 - 9ms/epoch - 692us/step\n",
            "Epoch 15/100\n",
            "13/13 - 0s - loss: 496.3858 - 10ms/epoch - 769us/step\n",
            "Epoch 16/100\n",
            "13/13 - 0s - loss: 491.2409 - 10ms/epoch - 769us/step\n",
            "Epoch 17/100\n",
            "13/13 - 0s - loss: 486.3117 - 12ms/epoch - 923us/step\n",
            "Epoch 18/100\n",
            "13/13 - 0s - loss: 481.6702 - 13ms/epoch - 1ms/step\n",
            "Epoch 19/100\n",
            "13/13 - 0s - loss: 476.5872 - 11ms/epoch - 809us/step\n",
            "Epoch 20/100\n",
            "13/13 - 0s - loss: 469.9900 - 10ms/epoch - 769us/step\n",
            "Epoch 21/100\n",
            "13/13 - 0s - loss: 465.6332 - 10ms/epoch - 769us/step\n",
            "Epoch 22/100\n",
            "13/13 - 0s - loss: 459.7393 - 11ms/epoch - 846us/step\n",
            "Epoch 23/100\n",
            "13/13 - 0s - loss: 454.9744 - 11ms/epoch - 846us/step\n",
            "Epoch 24/100\n",
            "13/13 - 0s - loss: 450.0828 - 10ms/epoch - 769us/step\n",
            "Epoch 25/100\n",
            "13/13 - 0s - loss: 442.8258 - 11ms/epoch - 846us/step\n",
            "Epoch 26/100\n",
            "13/13 - 0s - loss: 437.6725 - 10ms/epoch - 770us/step\n",
            "Epoch 27/100\n",
            "13/13 - 0s - loss: 431.6028 - 10ms/epoch - 772us/step\n",
            "Epoch 28/100\n",
            "13/13 - 0s - loss: 429.7230 - 10ms/epoch - 769us/step\n",
            "Epoch 29/100\n",
            "13/13 - 0s - loss: 419.0920 - 9ms/epoch - 692us/step\n",
            "Epoch 30/100\n",
            "13/13 - 0s - loss: 415.4234 - 10ms/epoch - 769us/step\n",
            "Epoch 31/100\n",
            "13/13 - 0s - loss: 407.4060 - 10ms/epoch - 769us/step\n",
            "Epoch 32/100\n",
            "13/13 - 0s - loss: 402.6417 - 10ms/epoch - 769us/step\n",
            "Epoch 33/100\n",
            "13/13 - 0s - loss: 395.8609 - 11ms/epoch - 846us/step\n",
            "Epoch 34/100\n",
            "13/13 - 0s - loss: 391.6911 - 9ms/epoch - 692us/step\n",
            "Epoch 35/100\n",
            "13/13 - 0s - loss: 385.0711 - 10ms/epoch - 770us/step\n",
            "Epoch 36/100\n",
            "13/13 - 0s - loss: 380.1371 - 10ms/epoch - 769us/step\n",
            "Epoch 37/100\n",
            "13/13 - 0s - loss: 372.3114 - 10ms/epoch - 769us/step\n",
            "Epoch 38/100\n",
            "13/13 - 0s - loss: 366.7158 - 10ms/epoch - 769us/step\n",
            "Epoch 39/100\n",
            "13/13 - 0s - loss: 360.0217 - 10ms/epoch - 769us/step\n",
            "Epoch 40/100\n",
            "13/13 - 0s - loss: 356.4031 - 9ms/epoch - 692us/step\n",
            "Epoch 41/100\n",
            "13/13 - 0s - loss: 348.8025 - 10ms/epoch - 769us/step\n",
            "Epoch 42/100\n",
            "13/13 - 0s - loss: 341.6836 - 10ms/epoch - 769us/step\n",
            "Epoch 43/100\n",
            "13/13 - 0s - loss: 337.1338 - 9ms/epoch - 692us/step\n",
            "Epoch 44/100\n",
            "13/13 - 0s - loss: 331.6996 - 9ms/epoch - 693us/step\n",
            "Epoch 45/100\n",
            "13/13 - 0s - loss: 326.4637 - 10ms/epoch - 769us/step\n",
            "Epoch 46/100\n",
            "13/13 - 0s - loss: 319.1997 - 10ms/epoch - 772us/step\n",
            "Epoch 47/100\n",
            "13/13 - 0s - loss: 312.0856 - 10ms/epoch - 769us/step\n",
            "Epoch 48/100\n",
            "13/13 - 0s - loss: 308.1111 - 10ms/epoch - 769us/step\n",
            "Epoch 49/100\n",
            "13/13 - 0s - loss: 300.4825 - 22ms/epoch - 2ms/step\n",
            "Epoch 50/100\n",
            "13/13 - 0s - loss: 293.7658 - 13ms/epoch - 1000us/step\n",
            "Epoch 51/100\n",
            "13/13 - 0s - loss: 290.2844 - 12ms/epoch - 923us/step\n",
            "Epoch 52/100\n",
            "13/13 - 0s - loss: 282.8464 - 12ms/epoch - 924us/step\n",
            "Epoch 53/100\n",
            "13/13 - 0s - loss: 277.1234 - 10ms/epoch - 784us/step\n",
            "Epoch 54/100\n",
            "13/13 - 0s - loss: 269.4460 - 10ms/epoch - 769us/step\n",
            "Epoch 55/100\n",
            "13/13 - 0s - loss: 264.2414 - 9ms/epoch - 692us/step\n",
            "Epoch 56/100\n",
            "13/13 - 0s - loss: 257.4865 - 10ms/epoch - 769us/step\n",
            "Epoch 57/100\n",
            "13/13 - 0s - loss: 252.6109 - 10ms/epoch - 769us/step\n",
            "Epoch 58/100\n",
            "13/13 - 0s - loss: 247.9784 - 10ms/epoch - 769us/step\n",
            "Epoch 59/100\n",
            "13/13 - 0s - loss: 242.5469 - 10ms/epoch - 769us/step\n",
            "Epoch 60/100\n",
            "13/13 - 0s - loss: 235.1409 - 10ms/epoch - 769us/step\n",
            "Epoch 61/100\n",
            "13/13 - 0s - loss: 230.8632 - 9ms/epoch - 693us/step\n",
            "Epoch 62/100\n",
            "13/13 - 0s - loss: 226.2295 - 10ms/epoch - 769us/step\n",
            "Epoch 63/100\n",
            "13/13 - 0s - loss: 221.2276 - 9ms/epoch - 692us/step\n",
            "Epoch 64/100\n",
            "13/13 - 0s - loss: 215.5692 - 10ms/epoch - 769us/step\n",
            "Epoch 65/100\n",
            "13/13 - 0s - loss: 210.1754 - 10ms/epoch - 769us/step\n",
            "Epoch 66/100\n",
            "13/13 - 0s - loss: 206.4417 - 10ms/epoch - 769us/step\n",
            "Epoch 67/100\n",
            "13/13 - 0s - loss: 200.7374 - 10ms/epoch - 769us/step\n",
            "Epoch 68/100\n",
            "13/13 - 0s - loss: 196.2581 - 10ms/epoch - 769us/step\n",
            "Epoch 69/100\n",
            "13/13 - 0s - loss: 192.5408 - 10ms/epoch - 769us/step\n",
            "Epoch 70/100\n",
            "13/13 - 0s - loss: 187.4777 - 10ms/epoch - 769us/step\n",
            "Epoch 71/100\n",
            "13/13 - 0s - loss: 184.1090 - 9ms/epoch - 692us/step\n",
            "Epoch 72/100\n",
            "13/13 - 0s - loss: 177.7742 - 10ms/epoch - 772us/step\n",
            "Epoch 73/100\n",
            "13/13 - 0s - loss: 173.5715 - 10ms/epoch - 769us/step\n",
            "Epoch 74/100\n",
            "13/13 - 0s - loss: 169.2682 - 9ms/epoch - 692us/step\n",
            "Epoch 75/100\n",
            "13/13 - 0s - loss: 165.6737 - 10ms/epoch - 769us/step\n",
            "Epoch 76/100\n",
            "13/13 - 0s - loss: 162.2668 - 10ms/epoch - 769us/step\n",
            "Epoch 77/100\n",
            "13/13 - 0s - loss: 156.9941 - 10ms/epoch - 769us/step\n",
            "Epoch 78/100\n",
            "13/13 - 0s - loss: 154.4695 - 9ms/epoch - 692us/step\n",
            "Epoch 79/100\n",
            "13/13 - 0s - loss: 149.5828 - 10ms/epoch - 769us/step\n",
            "Epoch 80/100\n",
            "13/13 - 0s - loss: 146.0746 - 10ms/epoch - 770us/step\n",
            "Epoch 81/100\n",
            "13/13 - 0s - loss: 140.8714 - 9ms/epoch - 703us/step\n",
            "Epoch 82/100\n",
            "13/13 - 0s - loss: 139.6146 - 10ms/epoch - 769us/step\n",
            "Epoch 83/100\n",
            "13/13 - 0s - loss: 134.5880 - 10ms/epoch - 769us/step\n",
            "Epoch 84/100\n",
            "13/13 - 0s - loss: 130.7069 - 9ms/epoch - 692us/step\n",
            "Epoch 85/100\n",
            "13/13 - 0s - loss: 127.6627 - 12ms/epoch - 923us/step\n",
            "Epoch 86/100\n",
            "13/13 - 0s - loss: 123.9115 - 10ms/epoch - 769us/step\n",
            "Epoch 87/100\n",
            "13/13 - 0s - loss: 120.8921 - 10ms/epoch - 769us/step\n",
            "Epoch 88/100\n",
            "13/13 - 0s - loss: 117.1124 - 9ms/epoch - 692us/step\n",
            "Epoch 89/100\n",
            "13/13 - 0s - loss: 113.9721 - 10ms/epoch - 770us/step\n",
            "Epoch 90/100\n",
            "13/13 - 0s - loss: 111.4105 - 9ms/epoch - 719us/step\n",
            "Epoch 91/100\n",
            "13/13 - 0s - loss: 107.9713 - 10ms/epoch - 769us/step\n",
            "Epoch 92/100\n",
            "13/13 - 0s - loss: 105.0483 - 9ms/epoch - 692us/step\n",
            "Epoch 93/100\n",
            "13/13 - 0s - loss: 102.1226 - 10ms/epoch - 769us/step\n",
            "Epoch 94/100\n",
            "13/13 - 0s - loss: 99.3191 - 10ms/epoch - 769us/step\n",
            "Epoch 95/100\n",
            "13/13 - 0s - loss: 96.6867 - 9ms/epoch - 692us/step\n",
            "Epoch 96/100\n",
            "13/13 - 0s - loss: 94.1050 - 10ms/epoch - 769us/step\n",
            "Epoch 97/100\n",
            "13/13 - 0s - loss: 91.5028 - 9ms/epoch - 692us/step\n",
            "Epoch 98/100\n",
            "13/13 - 0s - loss: 88.8674 - 10ms/epoch - 770us/step\n",
            "Epoch 99/100\n",
            "13/13 - 0s - loss: 86.7145 - 9ms/epoch - 692us/step\n",
            "Epoch 100/100\n",
            "13/13 - 0s - loss: 84.1114 - 9ms/epoch - 655us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x2073e3de390>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(25, input_dim=x.shape[1], activation='relu')) # Hidden 1     #  why input_dim=x.shape[1]?\n",
        "model.add(Dense(10, activation='relu')) # Hidden 2\n",
        "model.add(Dense(1)) # Output\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "model.fit(x,y,verbose=2,epochs=100)    # Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1UzvBhERbHt"
      },
      "source": [
        "### Monitor the loss at each epoch\n",
        "\n",
        "One line is produced for each training epoch.  You can eliminate this output by setting the verbose setting of the fit command:\n",
        "\n",
        "* **verbose=0** - No progress output (use with Juputer if you do not want output)\n",
        "* **verbose=1** - Display progress bar, does not work well with Jupyter\n",
        "* **verbose=2** - Summary progress output (use with Jupyter if you want to know the loss at each epoch)\n",
        "\n",
        "\n",
        "## Use Trained Model to Make Regression Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_H7WQHmRbHt"
      },
      "source": [
        "Next we will perform actual predictions.  These predictions are assigned to the **pred** variable. These are all MPG predictions from the neural network.  \n",
        "\n",
        "***Notice that the data to predict should be a 2D array!***  \n",
        "\n",
        "***Notice that the prediction result is also a 2D array!***\n",
        "\n",
        "Neural networks can return multiple values, so the result is always an array.  Here the neural network only returns 1 value per prediction (there are 398 cars, so 398 predictions).  However, a 2D array is needed because the neural network has the potential of returning more than one value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sdrY44nkRbHt",
        "outputId": "2c30eff9-6c85-49ef-f7f0-1e9e19fecb32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 0s 833us/step\n",
            "Shape: (398, 1)\n",
            "[[23.008747]\n",
            " [19.719746]\n",
            " [19.896122]\n",
            " [19.151508]\n",
            " [20.43143 ]\n",
            " [19.307835]\n",
            " [16.871601]\n",
            " [16.62363 ]\n",
            " [16.330418]\n",
            " [17.358585]\n",
            " [20.735767]\n",
            " [18.96117 ]\n",
            " [25.520557]\n",
            " [19.225971]\n",
            " [15.523631]\n",
            " [21.77338 ]\n",
            " [21.458546]\n",
            " [23.747135]\n",
            " [15.408046]\n",
            " [24.44637 ]\n",
            " [17.552303]\n",
            " [15.912738]\n",
            " [15.550448]\n",
            " [12.15861 ]\n",
            " [22.538914]\n",
            " [12.450473]\n",
            " [11.519671]\n",
            " [10.114657]\n",
            " [13.630343]\n",
            " [15.667491]\n",
            " [18.16792 ]\n",
            " [15.461719]\n",
            " [15.342517]\n",
            " [22.831272]\n",
            " [22.420673]\n",
            " [25.067738]\n",
            " [27.2233  ]\n",
            " [23.760609]\n",
            " [20.330036]\n",
            " [22.08562 ]\n",
            " [22.934788]\n",
            " [20.957691]\n",
            " [20.174824]\n",
            " [23.239155]\n",
            " [22.50478 ]\n",
            " [23.158314]\n",
            " [22.38947 ]\n",
            " [24.917759]\n",
            " [26.893848]\n",
            " [17.192196]\n",
            " [16.555752]\n",
            " [18.924503]\n",
            " [17.183117]\n",
            " [18.974537]\n",
            " [17.995548]\n",
            " [21.787457]\n",
            " [19.435719]\n",
            " [16.132252]\n",
            " [17.518986]\n",
            " [24.479221]\n",
            " [19.528065]\n",
            " [18.103657]\n",
            " [20.617207]\n",
            " [22.441029]\n",
            " [21.363758]\n",
            " [23.053791]\n",
            " [19.642933]\n",
            " [18.405506]\n",
            " [22.910465]\n",
            " [21.987736]\n",
            " [19.877934]\n",
            " [12.008616]\n",
            " [19.996967]\n",
            " [24.301655]\n",
            " [22.740818]\n",
            " [21.4688  ]\n",
            " [13.67699 ]\n",
            " [20.90691 ]\n",
            " [19.438618]\n",
            " [20.242146]\n",
            " [18.046177]\n",
            " [15.921588]\n",
            " [16.110386]\n",
            " [17.051594]\n",
            " [16.433712]\n",
            " [19.256062]\n",
            " [19.902561]\n",
            " [24.626148]\n",
            " [23.044636]\n",
            " [21.21027 ]\n",
            " [20.737385]\n",
            " [27.249348]\n",
            " [22.510456]\n",
            " [21.926685]\n",
            " [18.232594]\n",
            " [17.593708]\n",
            " [19.333607]\n",
            " [23.063358]\n",
            " [26.214191]\n",
            " [24.262577]\n",
            " [27.881733]\n",
            " [22.71207 ]\n",
            " [25.403965]\n",
            " [27.996967]\n",
            " [24.498219]\n",
            " [21.112598]\n",
            " [18.394123]\n",
            " [23.93607 ]\n",
            " [17.419132]\n",
            " [23.035305]\n",
            " [16.517078]\n",
            " [13.444118]\n",
            " [19.099201]\n",
            " [16.759754]\n",
            " [16.235546]\n",
            " [24.66631 ]\n",
            " [12.072528]\n",
            " [22.359272]\n",
            " [20.188297]\n",
            " [16.947323]\n",
            " [14.168384]\n",
            " [20.658817]\n",
            " [14.050845]\n",
            " [14.672259]\n",
            " [17.646976]\n",
            " [23.186207]\n",
            " [23.633183]\n",
            " [24.50336 ]\n",
            " [26.238789]\n",
            " [20.040768]\n",
            " [19.802532]\n",
            " [20.299473]\n",
            " [22.16396 ]\n",
            " [26.429325]\n",
            " [25.392445]\n",
            " [23.533405]\n",
            " [22.674793]\n",
            " [24.676655]\n",
            " [22.020527]\n",
            " [23.576221]\n",
            " [21.451405]\n",
            " [17.999317]\n",
            " [19.158245]\n",
            " [18.345768]\n",
            " [21.756527]\n",
            " [21.433605]\n",
            " [17.753803]\n",
            " [18.563618]\n",
            " [20.095844]\n",
            " [16.752018]\n",
            " [16.702534]\n",
            " [19.303936]\n",
            " [25.31963 ]\n",
            " [25.388264]\n",
            " [32.63509 ]\n",
            " [32.128254]\n",
            " [24.11385 ]\n",
            " [25.598286]\n",
            " [22.557407]\n",
            " [25.09113 ]\n",
            " [24.614536]\n",
            " [26.225147]\n",
            " [25.953602]\n",
            " [26.321827]\n",
            " [22.684528]\n",
            " [24.962711]\n",
            " [23.98528 ]\n",
            " [19.4604  ]\n",
            " [21.020199]\n",
            " [24.76839 ]\n",
            " [22.292736]\n",
            " [17.896687]\n",
            " [19.854527]\n",
            " [17.48331 ]\n",
            " [20.580082]\n",
            " [19.263279]\n",
            " [26.961231]\n",
            " [17.123264]\n",
            " [19.377766]\n",
            " [16.988941]\n",
            " [13.54172 ]\n",
            " [23.232388]\n",
            " [18.466404]\n",
            " [20.273426]\n",
            " [19.080189]\n",
            " [19.010487]\n",
            " [18.414234]\n",
            " [23.180653]\n",
            " [22.295353]\n",
            " [26.846577]\n",
            " [24.257221]\n",
            " [24.507069]\n",
            " [25.212727]\n",
            " [26.624043]\n",
            " [27.32265 ]\n",
            " [24.029888]\n",
            " [23.545742]\n",
            " [19.574757]\n",
            " [23.465923]\n",
            " [25.283375]\n",
            " [31.87186 ]\n",
            " [24.876347]\n",
            " [28.380634]\n",
            " [19.328197]\n",
            " [19.945454]\n",
            " [19.816967]\n",
            " [22.35149 ]\n",
            " [17.570332]\n",
            " [22.24033 ]\n",
            " [21.238453]\n",
            " [18.551243]\n",
            " [18.205555]\n",
            " [19.01772 ]\n",
            " [25.173496]\n",
            " [25.143497]\n",
            " [22.369022]\n",
            " [21.91064 ]\n",
            " [19.224636]\n",
            " [22.308231]\n",
            " [17.367039]\n",
            " [20.133762]\n",
            " [22.263828]\n",
            " [27.12621 ]\n",
            " [23.618229]\n",
            " [25.558842]\n",
            " [25.134266]\n",
            " [24.765186]\n",
            " [25.533894]\n",
            " [27.9789  ]\n",
            " [22.531147]\n",
            " [20.809254]\n",
            " [21.055912]\n",
            " [25.551426]\n",
            " [18.970173]\n",
            " [21.207813]\n",
            " [20.591145]\n",
            " [20.193562]\n",
            " [21.89037 ]\n",
            " [18.002995]\n",
            " [21.448421]\n",
            " [18.973255]\n",
            " [19.7719  ]\n",
            " [14.751452]\n",
            " [11.841754]\n",
            " [25.983616]\n",
            " [20.825275]\n",
            " [23.834988]\n",
            " [20.914272]\n",
            " [22.463093]\n",
            " [26.179035]\n",
            " [24.477497]\n",
            " [23.337193]\n",
            " [25.669193]\n",
            " [24.831837]\n",
            " [25.933033]\n",
            " [20.514774]\n",
            " [25.57793 ]\n",
            " [27.791248]\n",
            " [24.71973 ]\n",
            " [26.21172 ]\n",
            " [24.242878]\n",
            " [23.776173]\n",
            " [22.510395]\n",
            " [13.288257]\n",
            " [22.76537 ]\n",
            " [24.755024]\n",
            " [21.161518]\n",
            " [18.976788]\n",
            " [17.559498]\n",
            " [19.91148 ]\n",
            " [19.113407]\n",
            " [18.939335]\n",
            " [22.473972]\n",
            " [17.656406]\n",
            " [18.079762]\n",
            " [16.119068]\n",
            " [14.944781]\n",
            " [15.361224]\n",
            " [20.045994]\n",
            " [21.715206]\n",
            " [23.011524]\n",
            " [26.826694]\n",
            " [21.34055 ]\n",
            " [28.333927]\n",
            " [23.845509]\n",
            " [26.228077]\n",
            " [25.624866]\n",
            " [27.556568]\n",
            " [26.20026 ]\n",
            " [25.029758]\n",
            " [27.162373]\n",
            " [24.203938]\n",
            " [25.976002]\n",
            " [20.04388 ]\n",
            " [21.224598]\n",
            " [18.60564 ]\n",
            " [20.732464]\n",
            " [28.150959]\n",
            " [30.900074]\n",
            " [27.116291]\n",
            " [31.814259]\n",
            " [20.723377]\n",
            " [21.143597]\n",
            " [22.211208]\n",
            " [20.817905]\n",
            " [21.33562 ]\n",
            " [17.512943]\n",
            " [17.973454]\n",
            " [20.55952 ]\n",
            " [20.320751]\n",
            " [23.534138]\n",
            " [21.044567]\n",
            " [21.814594]\n",
            " [21.728443]\n",
            " [21.799366]\n",
            " [22.802662]\n",
            " [28.271442]\n",
            " [20.192486]\n",
            " [20.801075]\n",
            " [22.954136]\n",
            " [19.116764]\n",
            " [21.378437]\n",
            " [22.243198]\n",
            " [18.884495]\n",
            " [22.509281]\n",
            " [26.597324]\n",
            " [27.223858]\n",
            " [25.474201]\n",
            " [27.702747]\n",
            " [21.063984]\n",
            " [16.772053]\n",
            " [22.711025]\n",
            " [22.232151]\n",
            " [15.041095]\n",
            " [13.321521]\n",
            " [20.129429]\n",
            " [19.833958]\n",
            " [22.326832]\n",
            " [21.63686 ]\n",
            " [23.027096]\n",
            " [21.414707]\n",
            " [19.328144]\n",
            " [20.864635]\n",
            " [22.853626]\n",
            " [21.656818]\n",
            " [22.430096]\n",
            " [22.88435 ]\n",
            " [22.762852]\n",
            " [23.077831]\n",
            " [21.772045]\n",
            " [22.95457 ]\n",
            " [22.356731]\n",
            " [23.669033]\n",
            " [21.33279 ]\n",
            " [17.924198]\n",
            " [21.334911]\n",
            " [22.08994 ]\n",
            " [17.95702 ]\n",
            " [23.641827]\n",
            " [24.884144]\n",
            " [26.02422 ]\n",
            " [18.497562]\n",
            " [16.523457]\n",
            " [24.610188]\n",
            " [35.371815]\n",
            " [26.547993]\n",
            " [28.924412]\n",
            " [20.588444]\n",
            " [20.343624]\n",
            " [20.082905]\n",
            " [20.234241]\n",
            " [21.989307]\n",
            " [22.661442]\n",
            " [21.15221 ]\n",
            " [22.807194]\n",
            " [21.788143]\n",
            " [22.620174]\n",
            " [22.440784]\n",
            " [23.123547]\n",
            " [22.033245]\n",
            " [20.18259 ]\n",
            " [21.61829 ]\n",
            " [23.233486]\n",
            " [21.943874]\n",
            " [22.125721]\n",
            " [22.268436]\n",
            " [21.242085]\n",
            " [31.746128]\n",
            " [21.685154]\n",
            " [24.046162]\n",
            " [20.517704]\n",
            " [21.143696]\n",
            " [22.571705]\n",
            " [21.99593 ]\n",
            " [27.667973]\n",
            " [20.747913]\n",
            " [22.535786]\n",
            " [22.170795]]\n"
          ]
        }
      ],
      "source": [
        "pred = model.predict(x)\n",
        "print(\"Shape: {}\".format(pred.shape))\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXV416NaRbHu"
      },
      "source": [
        "We would like to see how good these predictions are.  We know what the correct MPG is for each car, so we can measure how close the neural network was."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IcEXD-wwRbHu",
        "outputId": "cb987b03-9891-4c49-eb85-d9426be12b32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final score (RMSE): 9.08936595916748\n"
          ]
        }
      ],
      "source": [
        "# Measure RMSE error.  RMSE is common for regression.\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
        "print(\"Final score (RMSE): {}\".format(score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIm7EhhTRbHu"
      },
      "source": [
        "We can also print out the first 10 cars, with predictions and actual MPG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6Xt0BiXWRbHv",
        "outputId": "84885482-9e84-4e6b-e3a4-0972599a1edf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Car name: chevrolet chevelle malibu, MPG: 18.0, predicted MPG: [23.008747]\n",
            "2. Car name: buick skylark 320, MPG: 15.0, predicted MPG: [19.719746]\n",
            "3. Car name: plymouth satellite, MPG: 18.0, predicted MPG: [19.896122]\n",
            "4. Car name: amc rebel sst, MPG: 16.0, predicted MPG: [19.151508]\n",
            "5. Car name: ford torino, MPG: 17.0, predicted MPG: [20.43143]\n",
            "6. Car name: ford galaxie 500, MPG: 15.0, predicted MPG: [19.307835]\n",
            "7. Car name: chevrolet impala, MPG: 14.0, predicted MPG: [16.871601]\n",
            "8. Car name: plymouth fury iii, MPG: 14.0, predicted MPG: [16.62363]\n",
            "9. Car name: pontiac catalina, MPG: 14.0, predicted MPG: [16.330418]\n",
            "10. Car name: amc ambassador dpl, MPG: 15.0, predicted MPG: [17.358585]\n"
          ]
        }
      ],
      "source": [
        "# Sample predictions\n",
        "for i in range(10):\n",
        "    print(\"{}. Car name: {}, MPG: {}, predicted MPG: {}\".format(i+1,cars[i],y[i],pred[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_DNYSnBRbHv"
      },
      "source": [
        "# Example of TensorFlow Classification: Iris\n",
        "\n",
        "This is a very simple example of how to perform the Iris classification using TensorFlow. The iris.csv file is used.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jEJcv0YCRbHv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "df=pd.read_csv(\"data/iris.csv\",na_values=['NA','?'])\n",
        "\n",
        "species = encode_text_index(df,\"species\")\n",
        "\n",
        "x,y = to_xy(df,\"species\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "X6A6pIU4RbHw",
        "outputId": "ff9c3ae1-579e-4f5e-eddd-e65705d77ab1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]], dtype=float32)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RkPBgt_1RbHw",
        "outputId": "0ba6c63d-dce5-44bb-e3a9-921bc82b24f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rUU2dZ2dRbHw",
        "outputId": "ebf1ff2f-a97d-4c5b-ae1f-6da79a801e61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y  #  This is one-hot encoding.  Only one value is 1.0 (hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YzupSu4-RbHx",
        "outputId": "64c88411-c852-4a84-b833-85a0209a2bda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VosGucWWRbHx",
        "outputId": "8e37b565-658f-411d-f53d-4672cfabea84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 - 0s - loss: 1.6897 - 438ms/epoch - 88ms/step\n",
            "Epoch 2/100\n",
            "5/5 - 0s - loss: 1.4340 - 5ms/epoch - 1ms/step\n",
            "Epoch 3/100\n",
            "5/5 - 0s - loss: 1.2523 - 5ms/epoch - 1000us/step\n",
            "Epoch 4/100\n",
            "5/5 - 0s - loss: 1.0885 - 4ms/epoch - 800us/step\n",
            "Epoch 5/100\n",
            "5/5 - 0s - loss: 0.9603 - 5ms/epoch - 1000us/step\n",
            "Epoch 6/100\n",
            "5/5 - 0s - loss: 0.9074 - 5ms/epoch - 1000us/step\n",
            "Epoch 7/100\n",
            "5/5 - 0s - loss: 0.8491 - 5ms/epoch - 1ms/step\n",
            "Epoch 8/100\n",
            "5/5 - 0s - loss: 0.8067 - 4ms/epoch - 799us/step\n",
            "Epoch 9/100\n",
            "5/5 - 0s - loss: 0.7684 - 5ms/epoch - 1000us/step\n",
            "Epoch 10/100\n",
            "5/5 - 0s - loss: 0.7381 - 4ms/epoch - 800us/step\n",
            "Epoch 11/100\n",
            "5/5 - 0s - loss: 0.7117 - 5ms/epoch - 1ms/step\n",
            "Epoch 12/100\n",
            "5/5 - 0s - loss: 0.6862 - 4ms/epoch - 800us/step\n",
            "Epoch 13/100\n",
            "5/5 - 0s - loss: 0.6585 - 5ms/epoch - 999us/step\n",
            "Epoch 14/100\n",
            "5/5 - 0s - loss: 0.6383 - 5ms/epoch - 1ms/step\n",
            "Epoch 15/100\n",
            "5/5 - 0s - loss: 0.6099 - 4ms/epoch - 800us/step\n",
            "Epoch 16/100\n",
            "5/5 - 0s - loss: 0.5990 - 5ms/epoch - 1ms/step\n",
            "Epoch 17/100\n",
            "5/5 - 0s - loss: 0.5708 - 5ms/epoch - 1ms/step\n",
            "Epoch 18/100\n",
            "5/5 - 0s - loss: 0.5506 - 4ms/epoch - 800us/step\n",
            "Epoch 19/100\n",
            "5/5 - 0s - loss: 0.5317 - 4ms/epoch - 800us/step\n",
            "Epoch 20/100\n",
            "5/5 - 0s - loss: 0.5135 - 5ms/epoch - 999us/step\n",
            "Epoch 21/100\n",
            "5/5 - 0s - loss: 0.4965 - 4ms/epoch - 801us/step\n",
            "Epoch 22/100\n",
            "5/5 - 0s - loss: 0.4824 - 4ms/epoch - 800us/step\n",
            "Epoch 23/100\n",
            "5/5 - 0s - loss: 0.4653 - 4ms/epoch - 800us/step\n",
            "Epoch 24/100\n",
            "5/5 - 0s - loss: 0.4504 - 4ms/epoch - 800us/step\n",
            "Epoch 25/100\n",
            "5/5 - 0s - loss: 0.4363 - 5ms/epoch - 1ms/step\n",
            "Epoch 26/100\n",
            "5/5 - 0s - loss: 0.4226 - 5ms/epoch - 1ms/step\n",
            "Epoch 27/100\n",
            "5/5 - 0s - loss: 0.4091 - 5ms/epoch - 1000us/step\n",
            "Epoch 28/100\n",
            "5/5 - 0s - loss: 0.3958 - 4ms/epoch - 800us/step\n",
            "Epoch 29/100\n",
            "5/5 - 0s - loss: 0.3839 - 4ms/epoch - 799us/step\n",
            "Epoch 30/100\n",
            "5/5 - 0s - loss: 0.3740 - 4ms/epoch - 802us/step\n",
            "Epoch 31/100\n",
            "5/5 - 0s - loss: 0.3597 - 4ms/epoch - 799us/step\n",
            "Epoch 32/100\n",
            "5/5 - 0s - loss: 0.3528 - 5ms/epoch - 1ms/step\n",
            "Epoch 33/100\n",
            "5/5 - 0s - loss: 0.3368 - 4ms/epoch - 817us/step\n",
            "Epoch 34/100\n",
            "5/5 - 0s - loss: 0.3279 - 4ms/epoch - 800us/step\n",
            "Epoch 35/100\n",
            "5/5 - 0s - loss: 0.3175 - 4ms/epoch - 800us/step\n",
            "Epoch 36/100\n",
            "5/5 - 0s - loss: 0.3054 - 4ms/epoch - 800us/step\n",
            "Epoch 37/100\n",
            "5/5 - 0s - loss: 0.2992 - 5ms/epoch - 1ms/step\n",
            "Epoch 38/100\n",
            "5/5 - 0s - loss: 0.2880 - 5ms/epoch - 1000us/step\n",
            "Epoch 39/100\n",
            "5/5 - 0s - loss: 0.2797 - 4ms/epoch - 800us/step\n",
            "Epoch 40/100\n",
            "5/5 - 0s - loss: 0.2698 - 4ms/epoch - 800us/step\n",
            "Epoch 41/100\n",
            "5/5 - 0s - loss: 0.2617 - 5ms/epoch - 1ms/step\n",
            "Epoch 42/100\n",
            "5/5 - 0s - loss: 0.2537 - 4ms/epoch - 800us/step\n",
            "Epoch 43/100\n",
            "5/5 - 0s - loss: 0.2531 - 4ms/epoch - 800us/step\n",
            "Epoch 44/100\n",
            "5/5 - 0s - loss: 0.2393 - 5ms/epoch - 1ms/step\n",
            "Epoch 45/100\n",
            "5/5 - 0s - loss: 0.2365 - 5ms/epoch - 1ms/step\n",
            "Epoch 46/100\n",
            "5/5 - 0s - loss: 0.2246 - 4ms/epoch - 800us/step\n",
            "Epoch 47/100\n",
            "5/5 - 0s - loss: 0.2196 - 5ms/epoch - 1000us/step\n",
            "Epoch 48/100\n",
            "5/5 - 0s - loss: 0.2112 - 5ms/epoch - 1000us/step\n",
            "Epoch 49/100\n",
            "5/5 - 0s - loss: 0.2073 - 4ms/epoch - 801us/step\n",
            "Epoch 50/100\n",
            "5/5 - 0s - loss: 0.2037 - 5ms/epoch - 1ms/step\n",
            "Epoch 51/100\n",
            "5/5 - 0s - loss: 0.1948 - 4ms/epoch - 800us/step\n",
            "Epoch 52/100\n",
            "5/5 - 0s - loss: 0.1905 - 4ms/epoch - 828us/step\n",
            "Epoch 53/100\n",
            "5/5 - 0s - loss: 0.1860 - 4ms/epoch - 800us/step\n",
            "Epoch 54/100\n",
            "5/5 - 0s - loss: 0.1796 - 4ms/epoch - 800us/step\n",
            "Epoch 55/100\n",
            "5/5 - 0s - loss: 0.1755 - 4ms/epoch - 800us/step\n",
            "Epoch 56/100\n",
            "5/5 - 0s - loss: 0.1710 - 5ms/epoch - 1000us/step\n",
            "Epoch 57/100\n",
            "5/5 - 0s - loss: 0.1679 - 4ms/epoch - 800us/step\n",
            "Epoch 58/100\n",
            "5/5 - 0s - loss: 0.1635 - 4ms/epoch - 800us/step\n",
            "Epoch 59/100\n",
            "5/5 - 0s - loss: 0.1696 - 5ms/epoch - 1ms/step\n",
            "Epoch 60/100\n",
            "5/5 - 0s - loss: 0.1571 - 5ms/epoch - 1000us/step\n",
            "Epoch 61/100\n",
            "5/5 - 0s - loss: 0.1560 - 4ms/epoch - 800us/step\n",
            "Epoch 62/100\n",
            "5/5 - 0s - loss: 0.1483 - 4ms/epoch - 799us/step\n",
            "Epoch 63/100\n",
            "5/5 - 0s - loss: 0.1468 - 5ms/epoch - 1000us/step\n",
            "Epoch 64/100\n",
            "5/5 - 0s - loss: 0.1426 - 4ms/epoch - 800us/step\n",
            "Epoch 65/100\n",
            "5/5 - 0s - loss: 0.1403 - 6ms/epoch - 1ms/step\n",
            "Epoch 66/100\n",
            "5/5 - 0s - loss: 0.1379 - 8ms/epoch - 2ms/step\n",
            "Epoch 67/100\n",
            "5/5 - 0s - loss: 0.1352 - 6ms/epoch - 1ms/step\n",
            "Epoch 68/100\n",
            "5/5 - 0s - loss: 0.1317 - 9ms/epoch - 2ms/step\n",
            "Epoch 69/100\n",
            "5/5 - 0s - loss: 0.1312 - 6ms/epoch - 1ms/step\n",
            "Epoch 70/100\n",
            "5/5 - 0s - loss: 0.1271 - 5ms/epoch - 1000us/step\n",
            "Epoch 71/100\n",
            "5/5 - 0s - loss: 0.1252 - 5ms/epoch - 1ms/step\n",
            "Epoch 72/100\n",
            "5/5 - 0s - loss: 0.1240 - 4ms/epoch - 800us/step\n",
            "Epoch 73/100\n",
            "5/5 - 0s - loss: 0.1216 - 4ms/epoch - 800us/step\n",
            "Epoch 74/100\n",
            "5/5 - 0s - loss: 0.1187 - 5ms/epoch - 1000us/step\n",
            "Epoch 75/100\n",
            "5/5 - 0s - loss: 0.1186 - 5ms/epoch - 1ms/step\n",
            "Epoch 76/100\n",
            "5/5 - 0s - loss: 0.1165 - 5ms/epoch - 1000us/step\n",
            "Epoch 77/100\n",
            "5/5 - 0s - loss: 0.1139 - 5ms/epoch - 1000us/step\n",
            "Epoch 78/100\n",
            "5/5 - 0s - loss: 0.1132 - 4ms/epoch - 800us/step\n",
            "Epoch 79/100\n",
            "5/5 - 0s - loss: 0.1110 - 5ms/epoch - 1000us/step\n",
            "Epoch 80/100\n",
            "5/5 - 0s - loss: 0.1090 - 4ms/epoch - 800us/step\n",
            "Epoch 81/100\n",
            "5/5 - 0s - loss: 0.1076 - 5ms/epoch - 1ms/step\n",
            "Epoch 82/100\n",
            "5/5 - 0s - loss: 0.1055 - 4ms/epoch - 800us/step\n",
            "Epoch 83/100\n",
            "5/5 - 0s - loss: 0.1043 - 5ms/epoch - 1ms/step\n",
            "Epoch 84/100\n",
            "5/5 - 0s - loss: 0.1050 - 5ms/epoch - 1ms/step\n",
            "Epoch 85/100\n",
            "5/5 - 0s - loss: 0.1025 - 5ms/epoch - 1ms/step\n",
            "Epoch 86/100\n",
            "5/5 - 0s - loss: 0.1020 - 5ms/epoch - 902us/step\n",
            "Epoch 87/100\n",
            "5/5 - 0s - loss: 0.1017 - 4ms/epoch - 800us/step\n",
            "Epoch 88/100\n",
            "5/5 - 0s - loss: 0.1038 - 4ms/epoch - 800us/step\n",
            "Epoch 89/100\n",
            "5/5 - 0s - loss: 0.1038 - 5ms/epoch - 1ms/step\n",
            "Epoch 90/100\n",
            "5/5 - 0s - loss: 0.0970 - 5ms/epoch - 1000us/step\n",
            "Epoch 91/100\n",
            "5/5 - 0s - loss: 0.0956 - 4ms/epoch - 800us/step\n",
            "Epoch 92/100\n",
            "5/5 - 0s - loss: 0.0978 - 5ms/epoch - 1ms/step\n",
            "Epoch 93/100\n",
            "5/5 - 0s - loss: 0.0949 - 5ms/epoch - 1000us/step\n",
            "Epoch 94/100\n",
            "5/5 - 0s - loss: 0.0941 - 4ms/epoch - 800us/step\n",
            "Epoch 95/100\n",
            "5/5 - 0s - loss: 0.0917 - 5ms/epoch - 1ms/step\n",
            "Epoch 96/100\n",
            "5/5 - 0s - loss: 0.0919 - 4ms/epoch - 800us/step\n",
            "Epoch 97/100\n",
            "5/5 - 0s - loss: 0.0902 - 5ms/epoch - 1000us/step\n",
            "Epoch 98/100\n",
            "5/5 - 0s - loss: 0.0925 - 4ms/epoch - 800us/step\n",
            "Epoch 99/100\n",
            "5/5 - 0s - loss: 0.0905 - 5ms/epoch - 1000us/step\n",
            "Epoch 100/100\n",
            "5/5 - 0s - loss: 0.0901 - 5ms/epoch - 1000us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x2073f9a67d0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
        "model.add(Dense(25, activation='relu')) # Hidden 2\n",
        "model.add(Dense(y.shape[1], activation='softmax')) # Output\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model.fit(x,y,verbose=2,epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cAUdHKKxRbHx",
        "outputId": "e058907e-d662-4d07-a80f-58936ead9815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
          ]
        }
      ],
      "source": [
        "# Print out number of species found:\n",
        "print(species)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_OpnSADRbHy"
      },
      "source": [
        "Now that you have a neural network trained, we would like to be able to use it. There were 3 types of iris (Iris-setosa, Iris-versicolor, and Iris-virginica).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gVKEzSRORbHy",
        "outputId": "c1af99ef-fdaa-489e-b22e-e4f0d4504a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred = model.predict(x)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "dgRw2QDMRbHy",
        "outputId": "27fc346c-ba88-4e67-e72a-bcfa5f0971ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[9.95704234e-01, 4.29083407e-03, 5.02472676e-06],\n",
              "       [9.91692543e-01, 8.29269085e-03, 1.48178242e-05],\n",
              "       [9.93311644e-01, 6.67570066e-03, 1.27004614e-05],\n",
              "       [9.87650692e-01, 1.23216491e-02, 2.76529845e-05],\n",
              "       [9.95652914e-01, 4.34181467e-03, 5.26363374e-06],\n",
              "       [9.94657040e-01, 5.33728348e-03, 5.71655119e-06],\n",
              "       [9.91854906e-01, 8.12665746e-03, 1.84105847e-05],\n",
              "       [9.93847549e-01, 6.14403281e-03, 8.44435090e-06],\n",
              "       [9.85565126e-01, 1.43929087e-02, 4.19450334e-05],\n",
              "       [9.91827250e-01, 8.16075783e-03, 1.20145933e-05],\n",
              "       [9.96726274e-01, 3.27097485e-03, 2.71486579e-06],\n",
              "       [9.90839779e-01, 9.14511178e-03, 1.51609447e-05],\n",
              "       [9.92083073e-01, 7.90374633e-03, 1.31514698e-05],\n",
              "       [9.92624223e-01, 7.35795172e-03, 1.77759903e-05],\n",
              "       [9.98906374e-01, 1.09309389e-03, 5.03919068e-07],\n",
              "       [9.98254955e-01, 1.74401759e-03, 1.07133667e-06],\n",
              "       [9.97526586e-01, 2.47091940e-03, 2.44845296e-06],\n",
              "       [9.95239973e-01, 4.75353096e-03, 6.58151839e-06],\n",
              "       [9.96010661e-01, 3.98637401e-03, 2.91822812e-06],\n",
              "       [9.95590568e-01, 4.40407218e-03, 5.33341699e-06],\n",
              "       [9.92346168e-01, 7.64637766e-03, 7.49113178e-06],\n",
              "       [9.94708657e-01, 5.28343255e-03, 7.97831035e-06],\n",
              "       [9.96730089e-01, 3.26480437e-03, 5.07513914e-06],\n",
              "       [9.80077267e-01, 1.98806114e-02, 4.20794931e-05],\n",
              "       [9.76798654e-01, 2.31616888e-02, 3.96684118e-05],\n",
              "       [9.85701323e-01, 1.42748011e-02, 2.38509001e-05],\n",
              "       [9.88646686e-01, 1.13320155e-02, 2.13461408e-05],\n",
              "       [9.95359242e-01, 4.63563949e-03, 5.09330175e-06],\n",
              "       [9.95754838e-01, 4.24044160e-03, 4.79665005e-06],\n",
              "       [9.86644566e-01, 1.33290086e-02, 2.64055707e-05],\n",
              "       [9.85616446e-01, 1.43563570e-02, 2.73043479e-05],\n",
              "       [9.93912458e-01, 6.07946701e-03, 7.99865393e-06],\n",
              "       [9.97421503e-01, 2.57673208e-03, 1.74293280e-06],\n",
              "       [9.98298466e-01, 1.70060410e-03, 9.65719892e-07],\n",
              "       [9.90312934e-01, 9.67041124e-03, 1.66122009e-05],\n",
              "       [9.95680809e-01, 4.31295484e-03, 6.14467626e-06],\n",
              "       [9.97470856e-01, 2.52716825e-03, 2.02982005e-06],\n",
              "       [9.95700419e-01, 4.29473119e-03, 4.80794733e-06],\n",
              "       [9.89686549e-01, 1.02851475e-02, 2.83260724e-05],\n",
              "       [9.94363427e-01, 5.62950224e-03, 7.07929303e-06],\n",
              "       [9.95566666e-01, 4.42677829e-03, 6.52217295e-06],\n",
              "       [9.70624208e-01, 2.92565171e-02, 1.19329379e-04],\n",
              "       [9.91201401e-01, 8.77680909e-03, 2.17322086e-05],\n",
              "       [9.85637963e-01, 1.43269207e-02, 3.51842391e-05],\n",
              "       [9.85657990e-01, 1.43209696e-02, 2.10252911e-05],\n",
              "       [9.89097595e-01, 1.08776866e-02, 2.47799853e-05],\n",
              "       [9.95317221e-01, 4.67789033e-03, 4.91604624e-06],\n",
              "       [9.91357088e-01, 8.62458255e-03, 1.83677348e-05],\n",
              "       [9.96411979e-01, 3.58477258e-03, 3.24848884e-06],\n",
              "       [9.94478226e-01, 5.51398285e-03, 7.84139411e-06],\n",
              "       [2.13549589e-03, 9.91299212e-01, 6.56521879e-03],\n",
              "       [2.76473560e-03, 9.75408077e-01, 2.18271725e-02],\n",
              "       [1.79125008e-03, 9.59595799e-01, 3.86129580e-02],\n",
              "       [5.62760048e-03, 8.40237975e-01, 1.54134452e-01],\n",
              "       [2.68463558e-03, 9.13817704e-01, 8.34976882e-02],\n",
              "       [3.21255159e-03, 8.63443553e-01, 1.33343905e-01],\n",
              "       [2.42709555e-03, 9.23326731e-01, 7.42461681e-02],\n",
              "       [1.98354702e-02, 9.64191198e-01, 1.59733780e-02],\n",
              "       [2.38208752e-03, 9.81419981e-01, 1.61979236e-02],\n",
              "       [6.46977592e-03, 8.77432644e-01, 1.16097599e-01],\n",
              "       [1.00209359e-02, 9.47051406e-01, 4.29277122e-02],\n",
              "       [4.24396014e-03, 9.50409532e-01, 4.53464985e-02],\n",
              "       [5.69318654e-03, 9.79956985e-01, 1.43498089e-02],\n",
              "       [2.49065622e-03, 8.64178836e-01, 1.33330539e-01],\n",
              "       [1.69850551e-02, 9.71024871e-01, 1.19900815e-02],\n",
              "       [3.52248223e-03, 9.89352405e-01, 7.12516764e-03],\n",
              "       [3.04298755e-03, 7.50517130e-01, 2.46439904e-01],\n",
              "       [5.10720769e-03, 9.86366034e-01, 8.52674898e-03],\n",
              "       [2.26176134e-03, 5.23253441e-01, 4.74484831e-01],\n",
              "       [5.62698999e-03, 9.78123605e-01, 1.62493773e-02],\n",
              "       [1.37024873e-03, 4.13857579e-01, 5.84772229e-01],\n",
              "       [5.97196771e-03, 9.83604491e-01, 1.04235644e-02],\n",
              "       [1.25885906e-03, 4.40459937e-01, 5.58281243e-01],\n",
              "       [2.47240928e-03, 9.33896959e-01, 6.36305735e-02],\n",
              "       [3.62496567e-03, 9.86758769e-01, 9.61629860e-03],\n",
              "       [3.12726106e-03, 9.86597121e-01, 1.02755940e-02],\n",
              "       [2.05553183e-03, 9.48549151e-01, 4.93953638e-02],\n",
              "       [1.53433892e-03, 7.01300561e-01, 2.97165096e-01],\n",
              "       [3.11855250e-03, 8.57727170e-01, 1.39154240e-01],\n",
              "       [2.72690002e-02, 9.65412498e-01, 7.31849624e-03],\n",
              "       [6.42976211e-03, 9.74309146e-01, 1.92610621e-02],\n",
              "       [9.15713795e-03, 9.79698777e-01, 1.11441473e-02],\n",
              "       [6.60948502e-03, 9.81823325e-01, 1.15672443e-02],\n",
              "       [4.21381585e-04, 1.53205052e-01, 8.46373618e-01],\n",
              "       [2.80696922e-03, 6.44214272e-01, 3.52978736e-01],\n",
              "       [3.09865456e-03, 9.41306710e-01, 5.55946566e-02],\n",
              "       [2.22504418e-03, 9.67804730e-01, 2.99702566e-02],\n",
              "       [3.48707987e-03, 8.96163285e-01, 1.00349709e-01],\n",
              "       [5.11792535e-03, 9.70749915e-01, 2.41321977e-02],\n",
              "       [5.66081936e-03, 9.06479478e-01, 8.78596976e-02],\n",
              "       [3.62724322e-03, 8.38937402e-01, 1.57435402e-01],\n",
              "       [2.76082801e-03, 9.26662743e-01, 7.05764592e-02],\n",
              "       [4.98423167e-03, 9.76919234e-01, 1.80965383e-02],\n",
              "       [1.82512403e-02, 9.66265619e-01, 1.54830972e-02],\n",
              "       [4.49266611e-03, 9.16707993e-01, 7.87992924e-02],\n",
              "       [4.49918024e-03, 9.79280770e-01, 1.62200183e-02],\n",
              "       [4.24019713e-03, 9.61938620e-01, 3.38211358e-02],\n",
              "       [3.41066066e-03, 9.82398689e-01, 1.41906030e-02],\n",
              "       [5.75368069e-02, 9.29576099e-01, 1.28870979e-02],\n",
              "       [4.70933225e-03, 9.63636398e-01, 3.16542648e-02],\n",
              "       [4.83442136e-06, 2.11298768e-03, 9.97882068e-01],\n",
              "       [7.11592438e-05, 1.95162073e-02, 9.80412543e-01],\n",
              "       [2.65705021e-05, 2.03801803e-02, 9.79593158e-01],\n",
              "       [6.11033829e-05, 3.31064686e-02, 9.66832459e-01],\n",
              "       [9.22038998e-06, 4.45527025e-03, 9.95535493e-01],\n",
              "       [3.86761167e-06, 5.14302030e-03, 9.94853079e-01],\n",
              "       [2.30444828e-04, 3.21879797e-02, 9.67581570e-01],\n",
              "       [2.29052584e-05, 2.86665279e-02, 9.71310556e-01],\n",
              "       [2.15024575e-05, 1.24063995e-02, 9.87572074e-01],\n",
              "       [9.73969873e-06, 8.59107822e-03, 9.91399288e-01],\n",
              "       [6.08706789e-04, 2.48311564e-01, 7.51079798e-01],\n",
              "       [1.00891775e-04, 4.05575037e-02, 9.59341645e-01],\n",
              "       [8.28029733e-05, 4.34032418e-02, 9.56513941e-01],\n",
              "       [3.93950759e-05, 8.00697319e-03, 9.91953671e-01],\n",
              "       [1.96662204e-05, 4.13756492e-03, 9.95842755e-01],\n",
              "       [5.57817402e-05, 2.10149586e-02, 9.78929222e-01],\n",
              "       [1.84146367e-04, 1.03722051e-01, 8.96093786e-01],\n",
              "       [1.50563137e-05, 3.08137685e-02, 9.69171226e-01],\n",
              "       [5.27769998e-07, 6.21199200e-04, 9.99378324e-01],\n",
              "       [2.87797942e-04, 8.71210322e-02, 9.12591219e-01],\n",
              "       [2.72744255e-05, 1.61581300e-02, 9.83814538e-01],\n",
              "       [8.94927434e-05, 1.96871608e-02, 9.80223298e-01],\n",
              "       [3.04142691e-06, 4.30267025e-03, 9.95694280e-01],\n",
              "       [6.80846511e-04, 2.13424712e-01, 7.85894513e-01],\n",
              "       [6.28792768e-05, 4.04728912e-02, 9.59464192e-01],\n",
              "       [1.46025413e-04, 1.59592137e-01, 8.40261877e-01],\n",
              "       [1.02001091e-03, 2.98372179e-01, 7.00607777e-01],\n",
              "       [9.17806581e-04, 2.97356814e-01, 7.01725364e-01],\n",
              "       [1.49684338e-05, 6.08454458e-03, 9.93900537e-01],\n",
              "       [4.02853591e-04, 4.03835893e-01, 5.95761299e-01],\n",
              "       [3.19789797e-05, 3.29214595e-02, 9.67046618e-01],\n",
              "       [1.70884668e-04, 3.45353454e-01, 6.54475689e-01],\n",
              "       [1.11730278e-05, 4.25695209e-03, 9.95731890e-01],\n",
              "       [1.09110214e-03, 4.85969275e-01, 5.12939632e-01],\n",
              "       [1.23128732e-04, 7.10423663e-02, 9.28834498e-01],\n",
              "       [1.45797003e-05, 1.41086765e-02, 9.85876679e-01],\n",
              "       [1.59977571e-05, 6.87129423e-03, 9.93112743e-01],\n",
              "       [1.94994864e-04, 1.09722741e-01, 8.90082300e-01],\n",
              "       [1.11444690e-03, 3.25345904e-01, 6.73539698e-01],\n",
              "       [2.01874675e-04, 1.06116988e-01, 8.93681169e-01],\n",
              "       [1.36933613e-05, 6.03949651e-03, 9.93946731e-01],\n",
              "       [2.85420276e-04, 1.08461574e-01, 8.91252995e-01],\n",
              "       [7.11592438e-05, 1.95162073e-02, 9.80412543e-01],\n",
              "       [9.81838639e-06, 5.97377261e-03, 9.94016409e-01],\n",
              "       [9.94080619e-06, 4.70426725e-03, 9.95285809e-01],\n",
              "       [9.50574249e-05, 3.47469524e-02, 9.65157986e-01],\n",
              "       [1.77516369e-04, 5.23114875e-02, 9.47510958e-01],\n",
              "       [2.60372268e-04, 1.06020793e-01, 8.93718898e-01],\n",
              "       [4.12021218e-05, 1.66968722e-02, 9.83261824e-01],\n",
              "       [3.03338602e-04, 1.04809709e-01, 8.94886971e-01]], dtype=float32)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pVFVnoIJRbHy",
        "outputId": "1a95108f-0637-48ab-b2d2-e0c79437d52d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "# print y.\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcTE1KhARbHz"
      },
      "source": [
        "#### The column (pred) with the highest probability is  the prediction of the neural network.  \n",
        "\n",
        "#### Use argmax function to find the index of the maximum prediction for each row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NcpkLMSCRbHz",
        "outputId": "d072577d-cadb-47fc-a87f-b0b6a7786087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1\n",
            " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "True: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ]
        }
      ],
      "source": [
        "# Usually the column (pred) with the highest prediction is considered to be the prediction of the neural network.  It is easy\n",
        "# to convert the predictions to the expected iris species.  The argmax function finds the index of the maximum prediction\n",
        "# for each row.\n",
        "\n",
        "predict_classes = np.argmax(pred,axis=1)\n",
        "\n",
        "true_classes = np.argmax(y,axis=1)\n",
        "\n",
        "print(\"Predictions: {}\".format(predict_classes))\n",
        "print(\"True: {}\".format(true_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mmuzgbyeRbHz",
        "outputId": "bcff9af9-3ac2-40e1-bddb-c5b326eb2e97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
            " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa']\n"
          ]
        }
      ],
      "source": [
        "# Of course it is very easy to turn these indexes back into iris species.  We just use the species list that we created earlier.\n",
        "print(species[predict_classes[0:10]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6Vg-NCOVRbH0",
        "outputId": "db4d263e-0b1c-4390-ebe6-93ab8e02c89a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.98\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#For all of the iris predictions, what percent were correct?\n",
        "\n",
        "correct = metrics.accuracy_score(true_classes, predict_classes)\n",
        "print(\"Accuracy: {}\".format(correct))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YIaXdavRbIL"
      },
      "source": [
        "The code below performs two ad hoc predictions.  \n",
        "\n",
        "*** Remember x should be a 2D array! ***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-dEfKwMqRbIM",
        "outputId": "87154f53-79f8-4e81-e019-92a79a2322d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "[[0.00203846 0.2156131  0.78234845]]\n"
          ]
        }
      ],
      "source": [
        "# ad hoc prediction\n",
        "sample_flower = np.array( [[5.0,3.0,4.0,2.0]], dtype=float)\n",
        "pred = model.predict(sample_flower)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "eb69OLkBRbIM",
        "outputId": "6418e70c-271c-4c3f-af16-b48f57e55d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predict that [[5. 3. 4. 2.]] is: ['Iris-virginica']\n"
          ]
        }
      ],
      "source": [
        "pred = np.argmax(pred, axis=1)\n",
        "print(\"Predict that {} is: {}\".format(sample_flower,species[pred]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUdPfFe4RbIN"
      },
      "source": [
        "Notice that the argmax in the second prediction requires **axis=1**?  Since we have a 2D array now, we must specify which axis to take the argmax over.  The value **axis=1** specifies we want the max column index for each row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ngdl9MqBRbIO",
        "outputId": "c2f15c13-ee21-406d-88af-f9c993664ddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "[[2.03845976e-03 2.15613127e-01 7.82348394e-01]\n",
            " [9.86724555e-01 1.32385185e-02 3.69084191e-05]]\n"
          ]
        }
      ],
      "source": [
        "# predict two sample flowers\n",
        "sample_flower = np.array( [[5.0,3.0,4.0,2.0],[5.2,3.5,1.5,0.8]], dtype=float)\n",
        "pred = model.predict(sample_flower)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "wMiFLHTmRbIO",
        "outputId": "8deeefa3-dbcc-4401-c8b5-22e736b22cf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predict that [[5.  3.  4.  2. ]\n",
            " [5.2 3.5 1.5 0.8]] is: ['Iris-virginica' 'Iris-setosa']\n"
          ]
        }
      ],
      "source": [
        "pred = np.argmax(pred, axis=1)\n",
        "print(\"Predict that {} is: {}\".format(sample_flower,species[pred]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "3JHSzlrbRbIP"
      },
      "source": [
        "# Load/Save Trained Network\n",
        "\n",
        "Complex neural networks will take a long time to fit/train.  It is helpful to be able to save these neural networks so that they can be reloaded later.  A reloaded neural network will not require retraining.  Keras provides three formats for neural network saving.\n",
        "\n",
        "* **YAML** - Stores the neural network structure (no weights) in the [YAML file format](https://en.wikipedia.org/wiki/YAML).\n",
        "* **JSON** - Stores the neural network structure (no weights) in the [JSON file format](https://en.wikipedia.org/wiki/JSON).\n",
        "* **HDF5** - Stores the complete neural network (with weights) in the [HDF5 file format](https://en.wikipedia.org/wiki/Hierarchical_Data_Format).\n",
        "\n",
        "Usually you will want to save in HDF5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nXArrw2ZRbIP",
        "outputId": "03d5a245-636a-4fe1-8753-2f06fb1bc746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 0s 666us/step\n",
            "Before save score (RMSE): 4.176130771636963\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "path = \"./data/\"\n",
        "save_path = \"./dnn/\"\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "\n",
        "cars = df['name']\n",
        "df.drop('name',axis=1,inplace=True)\n",
        "missing_median(df, 'horsepower')\n",
        "x,y = to_xy(df,\"mpg\")\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
        "model.add(Dense(25, activation='relu')) # Hidden 2\n",
        "model.add(Dense(1)) # Output\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(x,y,verbose=0,epochs=100)\n",
        "\n",
        "# Predict\n",
        "pred = model.predict(x)\n",
        "\n",
        "# Measure RMSE error.  RMSE is common for regression.\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
        "print(\"Before save score (RMSE): {}\".format(score))\n",
        "\n",
        "\n",
        "# save entire network to HDF5 (save everything)\n",
        "model.save(os.path.join(save_path,\"network.hdf5\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZCkU9C8RbIQ"
      },
      "source": [
        "Now we reload the network and perform another prediction.  The RMSE should match the previous one exactly if the neural network was really saved and reloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "t00yWN_5RbIQ",
        "outputId": "4b9fcf9a-89c6-4814-f327-4c7b3788ce7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 0s 750us/step\n",
            "After load score (RMSE): 4.176130771636963\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model2 = load_model(os.path.join(save_path,\"network.hdf5\"))\n",
        "pred = model2.predict(x)\n",
        "# Measure RMSE error.  RMSE is common for regression.\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
        "print(\"After load score (RMSE): {}\".format(score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EricpGl9RbIR"
      },
      "source": [
        "### References:\n",
        "\n",
        "* [Google Colab](https://colab.research.google.com/) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow with free GPU support.  No setup needed.\n",
        "* [IBM Cognitive Class Labs](https://www.datascientistworkbench.com) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow.  No setup needed.\n",
        "* [Python Anaconda](https://www.continuum.io/downloads) - Python distribution that includes many data science packages, such as Numpy, Scipy, Scikit-Learn, Pandas, and much more.\n",
        "* [TensorFlow](https://www.tensorflow.org/) - Google's mathematics package for deep learning.\n",
        "* [Kaggle](https://www.kaggle.com/) - Competitive data science.  Good source of sample data.\n",
        "* T81-558: Applications of Deep Neural Networks. Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "cea39816bfa6bd3c0a1f6664bad4835e3a909c2e2cb41a9f2c8a2752fd725301"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
